14/05/12 21:16:41 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/12 21:16:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/12 21:16:43 INFO Slf4jLogger: Slf4jLogger started
14/05/12 21:16:43 INFO Remoting: Starting remoting
14/05/12 21:16:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu-3.local:37787]
14/05/12 21:16:43 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu-3.local:37787]
14/05/12 21:16:43 INFO SparkEnv: Registering BlockManagerMaster
14/05/12 21:16:43 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140512211643-7620
14/05/12 21:16:43 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/12 21:16:43 INFO ConnectionManager: Bound socket to port 46407 with id = ConnectionManagerId(ubuntu-3.local,46407)
14/05/12 21:16:43 INFO BlockManagerMaster: Trying to register BlockManager
14/05/12 21:16:43 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu-3.local:46407 with 640.2 MB RAM
14/05/12 21:16:43 INFO BlockManagerMaster: Registered BlockManager
14/05/12 21:16:44 INFO HttpServer: Starting HTTP Server
14/05/12 21:16:44 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:35428
14/05/12 21:16:44 INFO SparkEnv: Registering MapOutputTracker
14/05/12 21:16:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-d00754e8-e854-40fc-aeac-2c1504024027
14/05/12 21:16:44 INFO HttpServer: Starting HTTP Server
14/05/12 21:16:44 INFO SparkUI: Started Spark Web UI at http://ubuntu-3.local:4040
14/05/12 21:16:45 INFO NetworkInputTracker: NetworkInputTracker started
14/05/12 21:16:45 INFO SparkContext: Starting job: runJob at NetworkInputTracker.scala:182
14/05/12 21:16:45 INFO DAGScheduler: Got job 0 (runJob at NetworkInputTracker.scala:182) with 1 output partitions (allowLocal=false)
14/05/12 21:16:45 INFO DAGScheduler: Final stage: Stage 0 (runJob at NetworkInputTracker.scala:182)
14/05/12 21:16:45 INFO DAGScheduler: Parents of final stage: List()
14/05/12 21:16:45 INFO DAGScheduler: Missing parents: List()
14/05/12 21:16:45 INFO DAGScheduler: Submitting Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165), which has no missing parents
14/05/12 21:16:45 INFO DAGScheduler: Submitting 1 missing tasks from Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165)
14/05/12 21:16:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
14/05/12 21:16:45 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:16:45 INFO TaskSetManager: Serialized task 0.0:0 as 1978 bytes in 12 ms
14/05/12 21:16:45 INFO Executor: Running task ID 0
14/05/12 21:16:45 INFO SocketReceiver: Connecting to localhost:9999
14/05/12 21:16:45 INFO SocketReceiver: Attempting to register with tracker
14/05/12 21:16:45 INFO SocketReceiver: Connected to localhost:9999
14/05/12 21:16:45 INFO NetworkReceiver$BlockGenerator: Block pushing thread started
14/05/12 21:16:45 INFO NetworkReceiver$BlockGenerator: Data handler started
14/05/12 21:16:45 INFO NetworkInputTracker: Registered receiver for network stream 0 from akka://spark
14/05/12 21:16:46 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/12 21:16:46 INFO ShuffledDStream: metadataCleanupDelay = 3600
14/05/12 21:16:46 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/12 21:16:46 INFO FlatMappedDStream: metadataCleanupDelay = 3600
14/05/12 21:16:46 INFO SocketInputDStream: metadataCleanupDelay = 3600
14/05/12 21:16:46 INFO SocketInputDStream: Slide time = 10000 ms
14/05/12 21:16:46 INFO SocketInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:16:46 INFO SocketInputDStream: Checkpoint interval = null
14/05/12 21:16:46 INFO SocketInputDStream: Remember duration = 10000 ms
14/05/12 21:16:46 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@23684ed7
14/05/12 21:16:46 INFO FlatMappedDStream: Slide time = 10000 ms
14/05/12 21:16:46 INFO FlatMappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:16:46 INFO FlatMappedDStream: Checkpoint interval = null
14/05/12 21:16:46 INFO FlatMappedDStream: Remember duration = 10000 ms
14/05/12 21:16:46 INFO FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@1510176a
14/05/12 21:16:46 INFO MappedDStream: Slide time = 10000 ms
14/05/12 21:16:46 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:16:46 INFO MappedDStream: Checkpoint interval = null
14/05/12 21:16:46 INFO MappedDStream: Remember duration = 10000 ms
14/05/12 21:16:46 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@53713af3
14/05/12 21:16:46 INFO ShuffledDStream: Slide time = 10000 ms
14/05/12 21:16:46 INFO ShuffledDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:16:46 INFO ShuffledDStream: Checkpoint interval = null
14/05/12 21:16:46 INFO ShuffledDStream: Remember duration = 10000 ms
14/05/12 21:16:46 INFO ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@2ed55251
14/05/12 21:16:46 INFO ForEachDStream: Slide time = 10000 ms
14/05/12 21:16:46 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:16:46 INFO ForEachDStream: Checkpoint interval = null
14/05/12 21:16:46 INFO ForEachDStream: Remember duration = 10000 ms
14/05/12 21:16:46 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@370f5bdc
14/05/12 21:16:46 INFO JobGenerator: JobGenerator started at 1399909610000 ms
14/05/12 21:16:46 INFO JobScheduler: JobScheduler started
14/05/12 21:16:46 INFO MemoryStore: ensureFreeSpace(9) called with curMem=0, maxMem=671298355
14/05/12 21:16:46 INFO MemoryStore: Block input-0-1399909606200 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/12 21:16:46 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909606200 in memory on ubuntu-3.local:46407 (size: 9.0 B, free: 640.2 MB)
14/05/12 21:16:46 INFO BlockManagerMaster: Updated info of block input-0-1399909606200
14/05/12 21:16:46 INFO SendingConnection: Initiating connection to [ubuntu-3.local/10.8.7.208:46407]
14/05/12 21:16:46 INFO ConnectionManager: Accepted connection from [ubuntu-3.local/10.8.7.208]
14/05/12 21:16:46 INFO SendingConnection: Connected to [ubuntu-3.local/10.8.7.208:46407], 1 messages pending
14/05/12 21:16:46 WARN BlockManager: Block input-0-1399909606200 already exists on this machine; not re-adding it
14/05/12 21:16:46 INFO MemoryStore: ensureFreeSpace(9) called with curMem=9, maxMem=671298355
14/05/12 21:16:46 INFO MemoryStore: Block input-0-1399909606600 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/12 21:16:46 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909606600 in memory on ubuntu-3.local:46407 (size: 9.0 B, free: 640.2 MB)
14/05/12 21:16:46 INFO BlockManagerMaster: Updated info of block input-0-1399909606600
14/05/12 21:16:46 WARN BlockManager: Block input-0-1399909606600 already exists on this machine; not re-adding it
14/05/12 21:16:47 INFO MemoryStore: ensureFreeSpace(8) called with curMem=18, maxMem=671298355
14/05/12 21:16:47 INFO MemoryStore: Block input-0-1399909607200 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:16:47 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909607200 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:16:47 INFO BlockManagerMaster: Updated info of block input-0-1399909607200
14/05/12 21:16:47 WARN BlockManager: Block input-0-1399909607200 already exists on this machine; not re-adding it
14/05/12 21:16:48 INFO MemoryStore: ensureFreeSpace(8) called with curMem=26, maxMem=671298355
14/05/12 21:16:48 INFO MemoryStore: Block input-0-1399909607800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:16:48 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909607800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:16:48 INFO BlockManagerMaster: Updated info of block input-0-1399909607800
14/05/12 21:16:48 WARN BlockManager: Block input-0-1399909607800 already exists on this machine; not re-adding it
14/05/12 21:16:49 INFO MemoryStore: ensureFreeSpace(7) called with curMem=34, maxMem=671298355
14/05/12 21:16:49 INFO MemoryStore: Block input-0-1399909608000 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:16:49 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909608000 in memory on ubuntu-3.local:46407 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:16:49 INFO BlockManagerMaster: Updated info of block input-0-1399909608000
14/05/12 21:16:49 WARN BlockManager: Block input-0-1399909608000 already exists on this machine; not re-adding it
14/05/12 21:16:49 INFO MemoryStore: ensureFreeSpace(8) called with curMem=41, maxMem=671298355
14/05/12 21:16:49 INFO MemoryStore: Block input-0-1399909608400 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:16:49 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909608400 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:16:49 INFO BlockManagerMaster: Updated info of block input-0-1399909608400
14/05/12 21:16:49 WARN BlockManager: Block input-0-1399909608400 already exists on this machine; not re-adding it
14/05/12 21:16:50 INFO NetworkInputTracker: Stream 0 received 5 blocks
14/05/12 21:16:50 INFO JobScheduler: Added jobs for time 1399909610000 ms
14/05/12 21:16:50 INFO JobScheduler: Starting job streaming job 1399909610000 ms.0 from job set of time 1399909610000 ms
14/05/12 21:16:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:16:50 INFO DAGScheduler: Registering RDD 4 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:16:50 INFO DAGScheduler: Got job 1 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:16:50 INFO DAGScheduler: Final stage: Stage 1 (take at DStream.scala:586)
14/05/12 21:16:50 INFO DAGScheduler: Parents of final stage: List(Stage 2)
14/05/12 21:16:50 INFO DAGScheduler: Missing parents: List(Stage 2)
14/05/12 21:16:50 INFO DAGScheduler: Submitting Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:16:50 INFO DAGScheduler: Submitting 5 missing tasks from Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:16:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
14/05/12 21:16:50 INFO TaskSetManager: Starting task 2.0:0 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:16:50 INFO TaskSetManager: Serialized task 2.0:0 as 1517 bytes in 0 ms
14/05/12 21:16:50 INFO Executor: Running task ID 1
14/05/12 21:16:50 INFO BlockManager: Found block input-0-1399909606200 locally
14/05/12 21:16:50 INFO MemoryStore: ensureFreeSpace(7) called with curMem=49, maxMem=671298355
14/05/12 21:16:50 INFO MemoryStore: Block input-0-1399909608600 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:16:50 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909608600 in memory on ubuntu-3.local:46407 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:16:50 INFO BlockManagerMaster: Updated info of block input-0-1399909608600
14/05/12 21:16:50 INFO Executor: Serialized size of result for 1 is 751
14/05/12 21:16:50 INFO Executor: Sending result for 1 directly to driver
14/05/12 21:16:50 INFO Executor: Finished task ID 1
14/05/12 21:16:50 INFO TaskSetManager: Starting task 2.0:1 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:16:50 INFO TaskSetManager: Serialized task 2.0:1 as 1517 bytes in 1 ms
14/05/12 21:16:50 INFO Executor: Running task ID 2
14/05/12 21:16:50 INFO TaskSetManager: Finished TID 1 in 173 ms on localhost (progress: 0/5)
14/05/12 21:16:50 INFO DAGScheduler: Completed ShuffleMapTask(2, 0)
14/05/12 21:16:50 INFO BlockManager: Found block input-0-1399909606600 locally
14/05/12 21:16:50 INFO Executor: Serialized size of result for 2 is 751
14/05/12 21:16:50 INFO Executor: Sending result for 2 directly to driver
14/05/12 21:16:50 INFO Executor: Finished task ID 2
14/05/12 21:16:50 INFO TaskSetManager: Starting task 2.0:2 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:16:50 INFO TaskSetManager: Serialized task 2.0:2 as 1517 bytes in 1 ms
14/05/12 21:16:50 INFO Executor: Running task ID 3
14/05/12 21:16:50 INFO TaskSetManager: Finished TID 2 in 23 ms on localhost (progress: 1/5)
14/05/12 21:16:50 INFO DAGScheduler: Completed ShuffleMapTask(2, 1)
14/05/12 21:16:50 INFO BlockManager: Found block input-0-1399909607200 locally
14/05/12 21:16:50 INFO Executor: Serialized size of result for 3 is 751
14/05/12 21:16:50 INFO Executor: Sending result for 3 directly to driver
14/05/12 21:16:50 INFO Executor: Finished task ID 3
14/05/12 21:16:50 INFO TaskSetManager: Starting task 2.0:3 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:16:50 INFO TaskSetManager: Serialized task 2.0:3 as 1517 bytes in 0 ms
14/05/12 21:16:50 INFO Executor: Running task ID 4
14/05/12 21:16:50 INFO TaskSetManager: Finished TID 3 in 22 ms on localhost (progress: 2/5)
14/05/12 21:16:50 INFO DAGScheduler: Completed ShuffleMapTask(2, 2)
14/05/12 21:16:50 INFO BlockManager: Found block input-0-1399909607800 locally
14/05/12 21:16:50 INFO Executor: Serialized size of result for 4 is 751
14/05/12 21:16:50 INFO Executor: Sending result for 4 directly to driver
14/05/12 21:16:50 INFO Executor: Finished task ID 4
14/05/12 21:16:50 INFO TaskSetManager: Starting task 2.0:4 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:16:50 INFO TaskSetManager: Serialized task 2.0:4 as 1517 bytes in 1 ms
14/05/12 21:16:50 INFO Executor: Running task ID 5
14/05/12 21:16:50 INFO TaskSetManager: Finished TID 4 in 20 ms on localhost (progress: 3/5)
14/05/12 21:16:50 INFO DAGScheduler: Completed ShuffleMapTask(2, 3)
14/05/12 21:16:50 INFO BlockManager: Found block input-0-1399909608000 locally
14/05/12 21:16:50 INFO Executor: Serialized size of result for 5 is 751
14/05/12 21:16:50 INFO Executor: Sending result for 5 directly to driver
14/05/12 21:16:50 INFO Executor: Finished task ID 5
14/05/12 21:16:50 INFO TaskSetManager: Finished TID 5 in 15 ms on localhost (progress: 4/5)
14/05/12 21:16:50 INFO DAGScheduler: Completed ShuffleMapTask(2, 4)
14/05/12 21:16:50 INFO TaskSchedulerImpl: Remove TaskSet 2.0 from pool 
14/05/12 21:16:50 INFO DAGScheduler: Stage 2 (combineByKey at ShuffledDStream.scala:42) finished in 0.246 s
14/05/12 21:16:50 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:16:50 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:16:50 INFO DAGScheduler: waiting: Set(Stage 1)
14/05/12 21:16:50 INFO DAGScheduler: failed: Set()
14/05/12 21:16:50 INFO DAGScheduler: Missing parents for Stage 1: List()
14/05/12 21:16:50 INFO DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:16:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:16:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
14/05/12 21:16:50 INFO TaskSetManager: Starting task 1.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:16:50 INFO TaskSetManager: Serialized task 1.0:0 as 1562 bytes in 0 ms
14/05/12 21:16:50 INFO Executor: Running task ID 6
14/05/12 21:16:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 2 non-zero-bytes blocks out of 5 blocks
14/05/12 21:16:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  6 ms
14/05/12 21:16:50 INFO Executor: Serialized size of result for 6 is 978
14/05/12 21:16:50 INFO Executor: Sending result for 6 directly to driver
14/05/12 21:16:50 INFO Executor: Finished task ID 6
14/05/12 21:16:50 INFO TaskSetManager: Finished TID 6 in 55 ms on localhost (progress: 0/1)
14/05/12 21:16:50 INFO DAGScheduler: Completed ResultTask(1, 0)
14/05/12 21:16:50 INFO TaskSchedulerImpl: Remove TaskSet 1.0 from pool 
14/05/12 21:16:50 INFO DAGScheduler: Stage 1 (take at DStream.scala:586) finished in 0.061 s
14/05/12 21:16:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.455628647 s
14/05/12 21:16:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:16:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes
14/05/12 21:16:50 INFO DAGScheduler: Got job 2 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:16:50 INFO DAGScheduler: Final stage: Stage 3 (take at DStream.scala:586)
14/05/12 21:16:50 INFO DAGScheduler: Parents of final stage: List(Stage 4)
14/05/12 21:16:50 INFO DAGScheduler: Missing parents: List()
14/05/12 21:16:50 INFO DAGScheduler: Submitting Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:16:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:16:50 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
14/05/12 21:16:50 INFO TaskSetManager: Starting task 3.0:0 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:16:50 INFO TaskSetManager: Serialized task 3.0:0 as 1561 bytes in 1 ms
14/05/12 21:16:50 INFO Executor: Running task ID 7
14/05/12 21:16:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 3 non-zero-bytes blocks out of 5 blocks
14/05/12 21:16:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:16:50 INFO Executor: Serialized size of result for 7 is 980
14/05/12 21:16:50 INFO Executor: Sending result for 7 directly to driver
14/05/12 21:16:50 INFO Executor: Finished task ID 7
14/05/12 21:16:50 INFO TaskSetManager: Finished TID 7 in 30 ms on localhost (progress: 0/1)
14/05/12 21:16:50 INFO DAGScheduler: Completed ResultTask(3, 1)
14/05/12 21:16:50 INFO TaskSchedulerImpl: Remove TaskSet 3.0 from pool 
14/05/12 21:16:50 INFO DAGScheduler: Stage 3 (take at DStream.scala:586) finished in 0.034 s
14/05/12 21:16:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.050597611 s
14/05/12 21:16:50 INFO JobScheduler: Finished job streaming job 1399909610000 ms.0 from job set of time 1399909610000 ms
14/05/12 21:16:50 INFO JobScheduler: Total delay: 0.593 s for time 1399909610000 ms (execution: 0.525 s)
14/05/12 21:16:50 WARN BlockManager: Block input-0-1399909608600 already exists on this machine; not re-adding it
14/05/12 21:16:51 INFO MemoryStore: ensureFreeSpace(8) called with curMem=56, maxMem=671298355
14/05/12 21:16:51 INFO MemoryStore: Block input-0-1399909609000 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:16:51 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909609000 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:16:51 INFO BlockManagerMaster: Updated info of block input-0-1399909609000
14/05/12 21:16:51 WARN BlockManager: Block input-0-1399909609000 already exists on this machine; not re-adding it
14/05/12 21:16:51 INFO MemoryStore: ensureFreeSpace(8) called with curMem=64, maxMem=671298355
14/05/12 21:16:51 INFO MemoryStore: Block input-0-1399909609400 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:16:51 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909609400 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:16:51 INFO BlockManagerMaster: Updated info of block input-0-1399909609400
14/05/12 21:16:51 WARN BlockManager: Block input-0-1399909609400 already exists on this machine; not re-adding it
14/05/12 21:16:51 INFO MemoryStore: ensureFreeSpace(8) called with curMem=72, maxMem=671298355
14/05/12 21:16:51 INFO MemoryStore: Block input-0-1399909609600 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:16:51 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909609600 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:16:51 INFO BlockManagerMaster: Updated info of block input-0-1399909609600
14/05/12 21:16:52 WARN BlockManager: Block input-0-1399909609600 already exists on this machine; not re-adding it
14/05/12 21:16:56 INFO MemoryStore: ensureFreeSpace(13) called with curMem=80, maxMem=671298355
14/05/12 21:16:56 INFO MemoryStore: Block input-0-1399909616000 stored as bytes to memory (size 13.0 B, free 640.2 MB)
14/05/12 21:16:56 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909616000 in memory on ubuntu-3.local:46407 (size: 13.0 B, free: 640.2 MB)
14/05/12 21:16:56 INFO BlockManagerMaster: Updated info of block input-0-1399909616000
14/05/12 21:16:57 WARN BlockManager: Block input-0-1399909616000 already exists on this machine; not re-adding it
14/05/12 21:16:57 INFO MemoryStore: ensureFreeSpace(13) called with curMem=93, maxMem=671298355
14/05/12 21:16:57 INFO MemoryStore: Block input-0-1399909617400 stored as bytes to memory (size 13.0 B, free 640.2 MB)
14/05/12 21:16:57 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909617400 in memory on ubuntu-3.local:46407 (size: 13.0 B, free: 640.2 MB)
14/05/12 21:16:57 INFO BlockManagerMaster: Updated info of block input-0-1399909617400
14/05/12 21:16:57 WARN BlockManager: Block input-0-1399909617400 already exists on this machine; not re-adding it
14/05/12 21:17:00 INFO NetworkInputTracker: Stream 0 received 7 blocks
14/05/12 21:17:00 INFO JobScheduler: Added jobs for time 1399909620000 ms
14/05/12 21:17:00 INFO JobScheduler: Starting job streaming job 1399909620000 ms.0 from job set of time 1399909620000 ms
14/05/12 21:17:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:00 INFO DAGScheduler: Registering RDD 10 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:00 INFO DAGScheduler: Got job 3 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:00 INFO DAGScheduler: Final stage: Stage 5 (take at DStream.scala:586)
14/05/12 21:17:00 INFO DAGScheduler: Parents of final stage: List(Stage 6)
14/05/12 21:17:00 INFO DAGScheduler: Missing parents: List(Stage 6)
14/05/12 21:17:00 INFO DAGScheduler: Submitting Stage 6 (MapPartitionsRDD[10] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:00 INFO DAGScheduler: Submitting 7 missing tasks from Stage 6 (MapPartitionsRDD[10] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:00 INFO TaskSchedulerImpl: Adding task set 6.0 with 7 tasks
14/05/12 21:17:00 INFO TaskSetManager: Starting task 6.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:00 INFO TaskSetManager: Serialized task 6.0:0 as 1518 bytes in 1 ms
14/05/12 21:17:00 INFO Executor: Running task ID 8
14/05/12 21:17:00 INFO BlockManager: Found block input-0-1399909608400 locally
14/05/12 21:17:00 INFO Executor: Serialized size of result for 8 is 751
14/05/12 21:17:00 INFO Executor: Sending result for 8 directly to driver
14/05/12 21:17:00 INFO Executor: Finished task ID 8
14/05/12 21:17:00 INFO TaskSetManager: Starting task 6.0:1 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:00 INFO TaskSetManager: Serialized task 6.0:1 as 1518 bytes in 0 ms
14/05/12 21:17:00 INFO Executor: Running task ID 9
14/05/12 21:17:00 INFO TaskSetManager: Finished TID 8 in 20 ms on localhost (progress: 0/7)
14/05/12 21:17:00 INFO DAGScheduler: Completed ShuffleMapTask(6, 0)
14/05/12 21:17:00 INFO BlockManager: Found block input-0-1399909608600 locally
14/05/12 21:17:00 INFO Executor: Serialized size of result for 9 is 751
14/05/12 21:17:00 INFO Executor: Sending result for 9 directly to driver
14/05/12 21:17:00 INFO Executor: Finished task ID 9
14/05/12 21:17:00 INFO TaskSetManager: Starting task 6.0:2 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:00 INFO TaskSetManager: Serialized task 6.0:2 as 1518 bytes in 1 ms
14/05/12 21:17:00 INFO Executor: Running task ID 10
14/05/12 21:17:00 INFO TaskSetManager: Finished TID 9 in 18 ms on localhost (progress: 1/7)
14/05/12 21:17:00 INFO DAGScheduler: Completed ShuffleMapTask(6, 1)
14/05/12 21:17:00 INFO BlockManager: Found block input-0-1399909609000 locally
14/05/12 21:17:00 INFO Executor: Serialized size of result for 10 is 751
14/05/12 21:17:00 INFO Executor: Sending result for 10 directly to driver
14/05/12 21:17:00 INFO Executor: Finished task ID 10
14/05/12 21:17:00 INFO TaskSetManager: Starting task 6.0:3 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:00 INFO TaskSetManager: Serialized task 6.0:3 as 1518 bytes in 0 ms
14/05/12 21:17:00 INFO Executor: Running task ID 11
14/05/12 21:17:00 INFO TaskSetManager: Finished TID 10 in 25 ms on localhost (progress: 2/7)
14/05/12 21:17:00 INFO DAGScheduler: Completed ShuffleMapTask(6, 2)
14/05/12 21:17:00 INFO BlockManager: Found block input-0-1399909609400 locally
14/05/12 21:17:00 INFO Executor: Serialized size of result for 11 is 751
14/05/12 21:17:00 INFO Executor: Sending result for 11 directly to driver
14/05/12 21:17:00 INFO Executor: Finished task ID 11
14/05/12 21:17:00 INFO TaskSetManager: Starting task 6.0:4 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:00 INFO TaskSetManager: Serialized task 6.0:4 as 1518 bytes in 1 ms
14/05/12 21:17:00 INFO Executor: Running task ID 12
14/05/12 21:17:00 INFO TaskSetManager: Finished TID 11 in 18 ms on localhost (progress: 3/7)
14/05/12 21:17:00 INFO DAGScheduler: Completed ShuffleMapTask(6, 3)
14/05/12 21:17:00 INFO BlockManager: Found block input-0-1399909609600 locally
14/05/12 21:17:00 INFO Executor: Serialized size of result for 12 is 751
14/05/12 21:17:00 INFO Executor: Sending result for 12 directly to driver
14/05/12 21:17:00 INFO Executor: Finished task ID 12
14/05/12 21:17:00 INFO TaskSetManager: Starting task 6.0:5 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:00 INFO TaskSetManager: Serialized task 6.0:5 as 1518 bytes in 0 ms
14/05/12 21:17:00 INFO Executor: Running task ID 13
14/05/12 21:17:00 INFO TaskSetManager: Finished TID 12 in 20 ms on localhost (progress: 4/7)
14/05/12 21:17:00 INFO DAGScheduler: Completed ShuffleMapTask(6, 4)
14/05/12 21:17:00 INFO BlockManager: Found block input-0-1399909616000 locally
14/05/12 21:17:00 INFO Executor: Serialized size of result for 13 is 751
14/05/12 21:17:00 INFO Executor: Sending result for 13 directly to driver
14/05/12 21:17:00 INFO Executor: Finished task ID 13
14/05/12 21:17:00 INFO TaskSetManager: Starting task 6.0:6 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:00 INFO TaskSetManager: Serialized task 6.0:6 as 1518 bytes in 0 ms
14/05/12 21:17:00 INFO Executor: Running task ID 14
14/05/12 21:17:00 INFO TaskSetManager: Finished TID 13 in 18 ms on localhost (progress: 5/7)
14/05/12 21:17:00 INFO DAGScheduler: Completed ShuffleMapTask(6, 5)
14/05/12 21:17:00 INFO BlockManager: Found block input-0-1399909617400 locally
14/05/12 21:17:00 INFO Executor: Serialized size of result for 14 is 751
14/05/12 21:17:00 INFO Executor: Sending result for 14 directly to driver
14/05/12 21:17:00 INFO Executor: Finished task ID 14
14/05/12 21:17:00 INFO TaskSetManager: Finished TID 14 in 19 ms on localhost (progress: 6/7)
14/05/12 21:17:00 INFO DAGScheduler: Completed ShuffleMapTask(6, 6)
14/05/12 21:17:00 INFO TaskSchedulerImpl: Remove TaskSet 6.0 from pool 
14/05/12 21:17:00 INFO DAGScheduler: Stage 6 (combineByKey at ShuffledDStream.scala:42) finished in 0.126 s
14/05/12 21:17:00 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:17:00 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:17:00 INFO DAGScheduler: waiting: Set(Stage 5)
14/05/12 21:17:00 INFO DAGScheduler: failed: Set()
14/05/12 21:17:00 INFO DAGScheduler: Missing parents for Stage 5: List()
14/05/12 21:17:00 INFO DAGScheduler: Submitting Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:17:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:00 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
14/05/12 21:17:00 INFO TaskSetManager: Starting task 5.0:0 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:00 INFO TaskSetManager: Serialized task 5.0:0 as 1563 bytes in 1 ms
14/05/12 21:17:00 INFO Executor: Running task ID 15
14/05/12 21:17:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 2 non-zero-bytes blocks out of 7 blocks
14/05/12 21:17:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:00 INFO Executor: Serialized size of result for 15 is 978
14/05/12 21:17:00 INFO Executor: Sending result for 15 directly to driver
14/05/12 21:17:00 INFO Executor: Finished task ID 15
14/05/12 21:17:00 INFO TaskSetManager: Finished TID 15 in 24 ms on localhost (progress: 0/1)
14/05/12 21:17:00 INFO DAGScheduler: Completed ResultTask(5, 0)
14/05/12 21:17:00 INFO TaskSchedulerImpl: Remove TaskSet 5.0 from pool 
14/05/12 21:17:00 INFO DAGScheduler: Stage 5 (take at DStream.scala:586) finished in 0.029 s
14/05/12 21:17:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.194063547 s
14/05/12 21:17:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 158 bytes
14/05/12 21:17:00 INFO DAGScheduler: Got job 4 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:00 INFO DAGScheduler: Final stage: Stage 7 (take at DStream.scala:586)
14/05/12 21:17:00 INFO DAGScheduler: Parents of final stage: List(Stage 8)
14/05/12 21:17:00 INFO DAGScheduler: Missing parents: List()
14/05/12 21:17:00 INFO DAGScheduler: Submitting Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:00 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
14/05/12 21:17:00 INFO TaskSetManager: Starting task 7.0:0 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:00 INFO TaskSetManager: Serialized task 7.0:0 as 1563 bytes in 0 ms
14/05/12 21:17:00 INFO Executor: Running task ID 16
14/05/12 21:17:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 5 non-zero-bytes blocks out of 7 blocks
14/05/12 21:17:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:00 INFO Executor: Serialized size of result for 16 is 999
14/05/12 21:17:00 INFO Executor: Sending result for 16 directly to driver
14/05/12 21:17:00 INFO Executor: Finished task ID 16
14/05/12 21:17:00 INFO TaskSetManager: Finished TID 16 in 27 ms on localhost (progress: 0/1)
14/05/12 21:17:00 INFO DAGScheduler: Completed ResultTask(7, 1)
14/05/12 21:17:00 INFO TaskSchedulerImpl: Remove TaskSet 7.0 from pool 
14/05/12 21:17:00 INFO DAGScheduler: Stage 7 (take at DStream.scala:586) finished in 0.032 s
14/05/12 21:17:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.050189907 s
14/05/12 21:17:00 INFO JobScheduler: Finished job streaming job 1399909620000 ms.0 from job set of time 1399909620000 ms
14/05/12 21:17:00 INFO JobScheduler: Total delay: 0.279 s for time 1399909620000 ms (execution: 0.260 s)
14/05/12 21:17:00 INFO MemoryStore: ensureFreeSpace(17) called with curMem=106, maxMem=671298355
14/05/12 21:17:00 INFO MemoryStore: Block input-0-1399909620400 stored as bytes to memory (size 17.0 B, free 640.2 MB)
14/05/12 21:17:00 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909620400 in memory on ubuntu-3.local:46407 (size: 17.0 B, free: 640.2 MB)
14/05/12 21:17:00 INFO BlockManagerMaster: Updated info of block input-0-1399909620400
14/05/12 21:17:06 WARN BlockManager: Block input-0-1399909620400 already exists on this machine; not re-adding it
14/05/12 21:17:10 INFO NetworkInputTracker: Stream 0 received 1 blocks
14/05/12 21:17:10 INFO JobScheduler: Added jobs for time 1399909630000 ms
14/05/12 21:17:10 INFO JobScheduler: Starting job streaming job 1399909630000 ms.0 from job set of time 1399909630000 ms
14/05/12 21:17:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:10 INFO DAGScheduler: Registering RDD 16 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:10 INFO DAGScheduler: Got job 5 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:10 INFO DAGScheduler: Final stage: Stage 9 (take at DStream.scala:586)
14/05/12 21:17:10 INFO DAGScheduler: Parents of final stage: List(Stage 10)
14/05/12 21:17:10 INFO DAGScheduler: Missing parents: List(Stage 10)
14/05/12 21:17:10 INFO DAGScheduler: Submitting Stage 10 (MapPartitionsRDD[16] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 10 (MapPartitionsRDD[16] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:10 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
14/05/12 21:17:10 INFO TaskSetManager: Starting task 10.0:0 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:10 INFO TaskSetManager: Serialized task 10.0:0 as 1517 bytes in 1 ms
14/05/12 21:17:10 INFO Executor: Running task ID 17
14/05/12 21:17:10 INFO BlockManager: Found block input-0-1399909620400 locally
14/05/12 21:17:10 INFO Executor: Serialized size of result for 17 is 751
14/05/12 21:17:10 INFO Executor: Sending result for 17 directly to driver
14/05/12 21:17:10 INFO Executor: Finished task ID 17
14/05/12 21:17:10 INFO TaskSetManager: Finished TID 17 in 19 ms on localhost (progress: 0/1)
14/05/12 21:17:10 INFO TaskSchedulerImpl: Remove TaskSet 10.0 from pool 
14/05/12 21:17:10 INFO DAGScheduler: Completed ShuffleMapTask(10, 0)
14/05/12 21:17:10 INFO DAGScheduler: Stage 10 (combineByKey at ShuffledDStream.scala:42) finished in 0.022 s
14/05/12 21:17:10 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:17:10 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:17:10 INFO DAGScheduler: waiting: Set(Stage 9)
14/05/12 21:17:10 INFO DAGScheduler: failed: Set()
14/05/12 21:17:10 INFO DAGScheduler: Missing parents for Stage 9: List()
14/05/12 21:17:10 INFO DAGScheduler: Submitting Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:17:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:10 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
14/05/12 21:17:10 INFO TaskSetManager: Starting task 9.0:0 as TID 18 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:10 INFO TaskSetManager: Serialized task 9.0:0 as 1563 bytes in 0 ms
14/05/12 21:17:10 INFO Executor: Running task ID 18
14/05/12 21:17:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 1 blocks
14/05/12 21:17:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:10 INFO Executor: Serialized size of result for 18 is 813
14/05/12 21:17:10 INFO Executor: Sending result for 18 directly to driver
14/05/12 21:17:10 INFO Executor: Finished task ID 18
14/05/12 21:17:10 INFO TaskSetManager: Finished TID 18 in 15 ms on localhost (progress: 0/1)
14/05/12 21:17:10 INFO DAGScheduler: Completed ResultTask(9, 0)
14/05/12 21:17:10 INFO TaskSchedulerImpl: Remove TaskSet 9.0 from pool 
14/05/12 21:17:10 INFO DAGScheduler: Stage 9 (take at DStream.scala:586) finished in 0.016 s
14/05/12 21:17:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.068045861 s
14/05/12 21:17:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 140 bytes
14/05/12 21:17:10 INFO DAGScheduler: Got job 6 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:10 INFO DAGScheduler: Final stage: Stage 11 (take at DStream.scala:586)
14/05/12 21:17:10 INFO DAGScheduler: Parents of final stage: List(Stage 12)
14/05/12 21:17:10 INFO DAGScheduler: Missing parents: List()
14/05/12 21:17:10 INFO DAGScheduler: Submitting Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:10 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
14/05/12 21:17:10 INFO TaskSetManager: Starting task 11.0:0 as TID 19 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:10 INFO TaskSetManager: Serialized task 11.0:0 as 1563 bytes in 0 ms
14/05/12 21:17:10 INFO Executor: Running task ID 19
14/05/12 21:17:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 1 blocks
14/05/12 21:17:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:10 INFO Executor: Serialized size of result for 19 is 968
14/05/12 21:17:10 INFO Executor: Sending result for 19 directly to driver
14/05/12 21:17:10 INFO Executor: Finished task ID 19
14/05/12 21:17:10 INFO TaskSetManager: Finished TID 19 in 19 ms on localhost (progress: 0/1)
14/05/12 21:17:10 INFO DAGScheduler: Completed ResultTask(11, 1)
14/05/12 21:17:10 INFO TaskSchedulerImpl: Remove TaskSet 11.0 from pool 
14/05/12 21:17:10 INFO DAGScheduler: Stage 11 (take at DStream.scala:586) finished in 0.023 s
14/05/12 21:17:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.034691229 s
14/05/12 21:17:10 INFO JobScheduler: Finished job streaming job 1399909630000 ms.0 from job set of time 1399909630000 ms
14/05/12 21:17:10 INFO JobScheduler: Total delay: 0.132 s for time 1399909630000 ms (execution: 0.114 s)
14/05/12 21:17:20 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/12 21:17:20 INFO JobScheduler: Added jobs for time 1399909640000 ms
14/05/12 21:17:20 INFO JobScheduler: Starting job streaming job 1399909640000 ms.0 from job set of time 1399909640000 ms
14/05/12 21:17:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:20 INFO DAGScheduler: Registering RDD 22 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:20 INFO DAGScheduler: Got job 7 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:20 INFO DAGScheduler: Final stage: Stage 13 (take at DStream.scala:586)
14/05/12 21:17:20 INFO DAGScheduler: Parents of final stage: List(Stage 14)
14/05/12 21:17:20 INFO DAGScheduler: Missing parents: List()
14/05/12 21:17:20 INFO DAGScheduler: Submitting Stage 13 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 13 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:20 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
14/05/12 21:17:20 INFO TaskSetManager: Starting task 13.0:0 as TID 20 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:20 INFO TaskSetManager: Serialized task 13.0:0 as 1564 bytes in 1 ms
14/05/12 21:17:20 INFO Executor: Running task ID 20
14/05/12 21:17:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:17:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:20 INFO Executor: Serialized size of result for 20 is 813
14/05/12 21:17:20 INFO Executor: Sending result for 20 directly to driver
14/05/12 21:17:20 INFO Executor: Finished task ID 20
14/05/12 21:17:20 INFO TaskSetManager: Finished TID 20 in 15 ms on localhost (progress: 0/1)
14/05/12 21:17:20 INFO TaskSchedulerImpl: Remove TaskSet 13.0 from pool 
14/05/12 21:17:20 INFO DAGScheduler: Completed ResultTask(13, 0)
14/05/12 21:17:20 INFO DAGScheduler: Stage 13 (take at DStream.scala:586) finished in 0.017 s
14/05/12 21:17:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.030529755 s
14/05/12 21:17:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 82 bytes
14/05/12 21:17:20 INFO DAGScheduler: Got job 8 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:20 INFO DAGScheduler: Final stage: Stage 15 (take at DStream.scala:586)
14/05/12 21:17:20 INFO DAGScheduler: Parents of final stage: List(Stage 16)
14/05/12 21:17:20 INFO DAGScheduler: Missing parents: List()
14/05/12 21:17:20 INFO DAGScheduler: Submitting Stage 15 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 15 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:20 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
14/05/12 21:17:20 INFO TaskSetManager: Starting task 15.0:0 as TID 21 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:20 INFO TaskSetManager: Serialized task 15.0:0 as 1564 bytes in 0 ms
14/05/12 21:17:20 INFO Executor: Running task ID 21
14/05/12 21:17:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:17:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:20 INFO Executor: Serialized size of result for 21 is 813
14/05/12 21:17:20 INFO Executor: Sending result for 21 directly to driver
14/05/12 21:17:20 INFO Executor: Finished task ID 21
14/05/12 21:17:20 INFO TaskSetManager: Finished TID 21 in 16 ms on localhost (progress: 0/1)
14/05/12 21:17:20 INFO DAGScheduler: Completed ResultTask(15, 1)
14/05/12 21:17:20 INFO TaskSchedulerImpl: Remove TaskSet 15.0 from pool 
14/05/12 21:17:20 INFO DAGScheduler: Stage 15 (take at DStream.scala:586) finished in 0.019 s
14/05/12 21:17:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.030388292 s
14/05/12 21:17:20 INFO JobScheduler: Finished job streaming job 1399909640000 ms.0 from job set of time 1399909640000 ms
14/05/12 21:17:20 INFO JobScheduler: Total delay: 0.087 s for time 1399909640000 ms (execution: 0.069 s)
14/05/12 21:17:23 INFO MemoryStore: ensureFreeSpace(14) called with curMem=123, maxMem=671298355
14/05/12 21:17:23 INFO MemoryStore: Block input-0-1399909643000 stored as bytes to memory (size 14.0 B, free 640.2 MB)
14/05/12 21:17:23 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909643000 in memory on ubuntu-3.local:46407 (size: 14.0 B, free: 640.2 MB)
14/05/12 21:17:23 INFO BlockManagerMaster: Updated info of block input-0-1399909643000
14/05/12 21:17:23 WARN BlockManager: Block input-0-1399909643000 already exists on this machine; not re-adding it
14/05/12 21:17:30 INFO NetworkInputTracker: Stream 0 received 1 blocks
14/05/12 21:17:30 INFO JobScheduler: Added jobs for time 1399909650000 ms
14/05/12 21:17:30 INFO JobScheduler: Starting job streaming job 1399909650000 ms.0 from job set of time 1399909650000 ms
14/05/12 21:17:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:30 INFO DAGScheduler: Registering RDD 28 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:30 INFO DAGScheduler: Got job 9 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:30 INFO DAGScheduler: Final stage: Stage 17 (take at DStream.scala:586)
14/05/12 21:17:30 INFO DAGScheduler: Parents of final stage: List(Stage 18)
14/05/12 21:17:30 INFO DAGScheduler: Missing parents: List(Stage 18)
14/05/12 21:17:30 INFO DAGScheduler: Submitting Stage 18 (MapPartitionsRDD[28] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 18 (MapPartitionsRDD[28] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:30 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
14/05/12 21:17:30 INFO TaskSetManager: Starting task 18.0:0 as TID 22 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:30 INFO TaskSetManager: Serialized task 18.0:0 as 1518 bytes in 0 ms
14/05/12 21:17:30 INFO Executor: Running task ID 22
14/05/12 21:17:30 INFO BlockManager: Found block input-0-1399909643000 locally
14/05/12 21:17:30 INFO Executor: Serialized size of result for 22 is 751
14/05/12 21:17:30 INFO Executor: Sending result for 22 directly to driver
14/05/12 21:17:30 INFO Executor: Finished task ID 22
14/05/12 21:17:30 INFO TaskSetManager: Finished TID 22 in 18 ms on localhost (progress: 0/1)
14/05/12 21:17:30 INFO TaskSchedulerImpl: Remove TaskSet 18.0 from pool 
14/05/12 21:17:30 INFO DAGScheduler: Completed ShuffleMapTask(18, 0)
14/05/12 21:17:30 INFO DAGScheduler: Stage 18 (combineByKey at ShuffledDStream.scala:42) finished in 0.020 s
14/05/12 21:17:30 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:17:30 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:17:30 INFO DAGScheduler: waiting: Set(Stage 17)
14/05/12 21:17:30 INFO DAGScheduler: failed: Set()
14/05/12 21:17:30 INFO DAGScheduler: Missing parents for Stage 17: List()
14/05/12 21:17:30 INFO DAGScheduler: Submitting Stage 17 (MapPartitionsRDD[30] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:17:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 17 (MapPartitionsRDD[30] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:30 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
14/05/12 21:17:30 INFO TaskSetManager: Starting task 17.0:0 as TID 23 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:30 INFO TaskSetManager: Serialized task 17.0:0 as 1562 bytes in 0 ms
14/05/12 21:17:30 INFO Executor: Running task ID 23
14/05/12 21:17:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 1 blocks
14/05/12 21:17:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:30 INFO Executor: Serialized size of result for 23 is 965
14/05/12 21:17:30 INFO Executor: Sending result for 23 directly to driver
14/05/12 21:17:30 INFO Executor: Finished task ID 23
14/05/12 21:17:30 INFO TaskSetManager: Finished TID 23 in 16 ms on localhost (progress: 0/1)
14/05/12 21:17:30 INFO DAGScheduler: Completed ResultTask(17, 0)
14/05/12 21:17:30 INFO TaskSchedulerImpl: Remove TaskSet 17.0 from pool 
14/05/12 21:17:30 INFO DAGScheduler: Stage 17 (take at DStream.scala:586) finished in 0.019 s
14/05/12 21:17:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.063468402 s
14/05/12 21:17:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 140 bytes
14/05/12 21:17:30 INFO DAGScheduler: Got job 10 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:30 INFO DAGScheduler: Final stage: Stage 19 (take at DStream.scala:586)
14/05/12 21:17:30 INFO DAGScheduler: Parents of final stage: List(Stage 20)
14/05/12 21:17:30 INFO DAGScheduler: Missing parents: List()
14/05/12 21:17:30 INFO DAGScheduler: Submitting Stage 19 (MapPartitionsRDD[30] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 19 (MapPartitionsRDD[30] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:30 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
14/05/12 21:17:30 INFO TaskSetManager: Starting task 19.0:0 as TID 24 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:30 INFO TaskSetManager: Serialized task 19.0:0 as 1562 bytes in 0 ms
14/05/12 21:17:30 INFO Executor: Running task ID 24
14/05/12 21:17:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 1 blocks
14/05/12 21:17:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:30 INFO Executor: Serialized size of result for 24 is 813
14/05/12 21:17:30 INFO Executor: Sending result for 24 directly to driver
14/05/12 21:17:30 INFO Executor: Finished task ID 24
14/05/12 21:17:30 INFO TaskSetManager: Finished TID 24 in 15 ms on localhost (progress: 0/1)
14/05/12 21:17:30 INFO DAGScheduler: Completed ResultTask(19, 1)
14/05/12 21:17:30 INFO TaskSchedulerImpl: Remove TaskSet 19.0 from pool 
14/05/12 21:17:30 INFO DAGScheduler: Stage 19 (take at DStream.scala:586) finished in 0.017 s
14/05/12 21:17:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.030356988 s
14/05/12 21:17:30 INFO JobScheduler: Finished job streaming job 1399909650000 ms.0 from job set of time 1399909650000 ms
14/05/12 21:17:30 INFO JobScheduler: Total delay: 0.122 s for time 1399909650000 ms (execution: 0.101 s)
14/05/12 21:17:35 INFO MemoryStore: ensureFreeSpace(11) called with curMem=137, maxMem=671298355
14/05/12 21:17:35 INFO MemoryStore: Block input-0-1399909655200 stored as bytes to memory (size 11.0 B, free 640.2 MB)
14/05/12 21:17:35 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909655200 in memory on ubuntu-3.local:46407 (size: 11.0 B, free: 640.2 MB)
14/05/12 21:17:35 INFO BlockManagerMaster: Updated info of block input-0-1399909655200
14/05/12 21:17:35 WARN BlockManager: Block input-0-1399909655200 already exists on this machine; not re-adding it
14/05/12 21:17:36 INFO MemoryStore: ensureFreeSpace(11) called with curMem=148, maxMem=671298355
14/05/12 21:17:36 INFO MemoryStore: Block input-0-1399909656000 stored as bytes to memory (size 11.0 B, free 640.2 MB)
14/05/12 21:17:36 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909656000 in memory on ubuntu-3.local:46407 (size: 11.0 B, free: 640.2 MB)
14/05/12 21:17:36 INFO BlockManagerMaster: Updated info of block input-0-1399909656000
14/05/12 21:17:36 WARN BlockManager: Block input-0-1399909656000 already exists on this machine; not re-adding it
14/05/12 21:17:37 INFO MemoryStore: ensureFreeSpace(11) called with curMem=159, maxMem=671298355
14/05/12 21:17:37 INFO MemoryStore: Block input-0-1399909657200 stored as bytes to memory (size 11.0 B, free 640.2 MB)
14/05/12 21:17:37 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909657200 in memory on ubuntu-3.local:46407 (size: 11.0 B, free: 640.2 MB)
14/05/12 21:17:37 INFO BlockManagerMaster: Updated info of block input-0-1399909657200
14/05/12 21:17:40 INFO NetworkInputTracker: Stream 0 received 2 blocks
14/05/12 21:17:40 INFO JobScheduler: Added jobs for time 1399909660000 ms
14/05/12 21:17:40 INFO JobScheduler: Starting job streaming job 1399909660000 ms.0 from job set of time 1399909660000 ms
14/05/12 21:17:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:40 INFO DAGScheduler: Registering RDD 34 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:40 INFO DAGScheduler: Got job 11 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:40 INFO DAGScheduler: Final stage: Stage 21 (take at DStream.scala:586)
14/05/12 21:17:40 INFO DAGScheduler: Parents of final stage: List(Stage 22)
14/05/12 21:17:40 INFO DAGScheduler: Missing parents: List(Stage 22)
14/05/12 21:17:40 INFO DAGScheduler: Submitting Stage 22 (MapPartitionsRDD[34] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:40 INFO DAGScheduler: Submitting 2 missing tasks from Stage 22 (MapPartitionsRDD[34] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:40 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks
14/05/12 21:17:40 INFO TaskSetManager: Starting task 22.0:0 as TID 25 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:40 INFO TaskSetManager: Serialized task 22.0:0 as 1521 bytes in 0 ms
14/05/12 21:17:40 INFO Executor: Running task ID 25
14/05/12 21:17:40 INFO BlockManager: Found block input-0-1399909655200 locally
14/05/12 21:17:40 INFO Executor: Serialized size of result for 25 is 751
14/05/12 21:17:40 INFO Executor: Sending result for 25 directly to driver
14/05/12 21:17:40 INFO Executor: Finished task ID 25
14/05/12 21:17:40 INFO TaskSetManager: Starting task 22.0:1 as TID 26 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:40 INFO TaskSetManager: Serialized task 22.0:1 as 1521 bytes in 0 ms
14/05/12 21:17:40 INFO Executor: Running task ID 26
14/05/12 21:17:40 INFO TaskSetManager: Finished TID 25 in 17 ms on localhost (progress: 0/2)
14/05/12 21:17:40 INFO DAGScheduler: Completed ShuffleMapTask(22, 0)
14/05/12 21:17:40 INFO BlockManager: Found block input-0-1399909656000 locally
14/05/12 21:17:40 INFO Executor: Serialized size of result for 26 is 751
14/05/12 21:17:40 INFO Executor: Sending result for 26 directly to driver
14/05/12 21:17:40 INFO Executor: Finished task ID 26
14/05/12 21:17:40 INFO TaskSetManager: Finished TID 26 in 14 ms on localhost (progress: 1/2)
14/05/12 21:17:40 INFO TaskSchedulerImpl: Remove TaskSet 22.0 from pool 
14/05/12 21:17:40 INFO DAGScheduler: Completed ShuffleMapTask(22, 1)
14/05/12 21:17:40 INFO DAGScheduler: Stage 22 (combineByKey at ShuffledDStream.scala:42) finished in 0.032 s
14/05/12 21:17:40 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:17:40 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:17:40 INFO DAGScheduler: waiting: Set(Stage 21)
14/05/12 21:17:40 INFO DAGScheduler: failed: Set()
14/05/12 21:17:40 INFO DAGScheduler: Missing parents for Stage 21: List()
14/05/12 21:17:40 INFO DAGScheduler: Submitting Stage 21 (MapPartitionsRDD[36] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:17:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 21 (MapPartitionsRDD[36] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:40 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
14/05/12 21:17:40 INFO TaskSetManager: Starting task 21.0:0 as TID 27 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:40 INFO TaskSetManager: Serialized task 21.0:0 as 1564 bytes in 0 ms
14/05/12 21:17:40 INFO Executor: Running task ID 27
14/05/12 21:17:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 2 non-zero-bytes blocks out of 2 blocks
14/05/12 21:17:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:40 INFO Executor: Serialized size of result for 27 is 962
14/05/12 21:17:40 INFO Executor: Sending result for 27 directly to driver
14/05/12 21:17:40 INFO Executor: Finished task ID 27
14/05/12 21:17:40 INFO TaskSetManager: Finished TID 27 in 21 ms on localhost (progress: 0/1)
14/05/12 21:17:40 INFO DAGScheduler: Completed ResultTask(21, 0)
14/05/12 21:17:40 INFO DAGScheduler: Stage 21 (take at DStream.scala:586) finished in 0.024 s
14/05/12 21:17:40 INFO TaskSchedulerImpl: Remove TaskSet 21.0 from pool 
14/05/12 21:17:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.081546988 s
14/05/12 21:17:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 148 bytes
14/05/12 21:17:40 INFO DAGScheduler: Got job 12 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:40 INFO DAGScheduler: Final stage: Stage 23 (take at DStream.scala:586)
14/05/12 21:17:40 INFO DAGScheduler: Parents of final stage: List(Stage 24)
14/05/12 21:17:40 INFO DAGScheduler: Missing parents: List()
14/05/12 21:17:40 INFO DAGScheduler: Submitting Stage 23 (MapPartitionsRDD[36] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 23 (MapPartitionsRDD[36] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:40 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
14/05/12 21:17:40 INFO TaskSetManager: Starting task 23.0:0 as TID 28 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:40 INFO TaskSetManager: Serialized task 23.0:0 as 1564 bytes in 0 ms
14/05/12 21:17:40 INFO Executor: Running task ID 28
14/05/12 21:17:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 2 blocks
14/05/12 21:17:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:40 INFO Executor: Serialized size of result for 28 is 813
14/05/12 21:17:40 INFO Executor: Sending result for 28 directly to driver
14/05/12 21:17:40 INFO Executor: Finished task ID 28
14/05/12 21:17:40 INFO TaskSetManager: Finished TID 28 in 15 ms on localhost (progress: 0/1)
14/05/12 21:17:40 INFO DAGScheduler: Completed ResultTask(23, 1)
14/05/12 21:17:40 INFO TaskSchedulerImpl: Remove TaskSet 23.0 from pool 
14/05/12 21:17:40 INFO DAGScheduler: Stage 23 (take at DStream.scala:586) finished in 0.017 s
14/05/12 21:17:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.029224655 s
14/05/12 21:17:40 INFO JobScheduler: Finished job streaming job 1399909660000 ms.0 from job set of time 1399909660000 ms
14/05/12 21:17:40 INFO JobScheduler: Total delay: 0.138 s for time 1399909660000 ms (execution: 0.120 s)
14/05/12 21:17:42 WARN BlockManager: Block input-0-1399909657200 already exists on this machine; not re-adding it
14/05/12 21:17:42 INFO MemoryStore: ensureFreeSpace(12) called with curMem=170, maxMem=671298355
14/05/12 21:17:42 INFO MemoryStore: Block input-0-1399909658400 stored as bytes to memory (size 12.0 B, free 640.2 MB)
14/05/12 21:17:42 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909658400 in memory on ubuntu-3.local:46407 (size: 12.0 B, free: 640.2 MB)
14/05/12 21:17:42 INFO BlockManagerMaster: Updated info of block input-0-1399909658400
14/05/12 21:17:42 WARN BlockManager: Block input-0-1399909658400 already exists on this machine; not re-adding it
14/05/12 21:17:42 INFO MemoryStore: ensureFreeSpace(8) called with curMem=182, maxMem=671298355
14/05/12 21:17:42 INFO MemoryStore: Block input-0-1399909658600 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:17:42 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909658600 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:17:42 INFO BlockManagerMaster: Updated info of block input-0-1399909658600
14/05/12 21:17:42 WARN BlockManager: Block input-0-1399909658600 already exists on this machine; not re-adding it
14/05/12 21:17:42 INFO MemoryStore: ensureFreeSpace(8) called with curMem=190, maxMem=671298355
14/05/12 21:17:42 INFO MemoryStore: Block input-0-1399909658800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:17:42 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909658800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:17:42 INFO BlockManagerMaster: Updated info of block input-0-1399909658800
14/05/12 21:17:42 WARN BlockManager: Block input-0-1399909658800 already exists on this machine; not re-adding it
14/05/12 21:17:42 INFO MemoryStore: ensureFreeSpace(8) called with curMem=198, maxMem=671298355
14/05/12 21:17:42 INFO MemoryStore: Block input-0-1399909659000 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:17:42 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909659000 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:17:42 INFO BlockManagerMaster: Updated info of block input-0-1399909659000
14/05/12 21:17:43 WARN BlockManager: Block input-0-1399909659000 already exists on this machine; not re-adding it
14/05/12 21:17:43 INFO MemoryStore: ensureFreeSpace(8) called with curMem=206, maxMem=671298355
14/05/12 21:17:43 INFO MemoryStore: Block input-0-1399909659200 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:17:43 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909659200 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:17:43 INFO BlockManagerMaster: Updated info of block input-0-1399909659200
14/05/12 21:17:43 WARN BlockManager: Block input-0-1399909659200 already exists on this machine; not re-adding it
14/05/12 21:17:43 INFO MemoryStore: ensureFreeSpace(8) called with curMem=214, maxMem=671298355
14/05/12 21:17:43 INFO MemoryStore: Block input-0-1399909660600 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:17:43 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909660600 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:17:43 INFO BlockManagerMaster: Updated info of block input-0-1399909660600
14/05/12 21:17:43 WARN BlockManager: Block input-0-1399909660600 already exists on this machine; not re-adding it
14/05/12 21:17:43 INFO MemoryStore: ensureFreeSpace(8) called with curMem=222, maxMem=671298355
14/05/12 21:17:43 INFO MemoryStore: Block input-0-1399909662600 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:17:43 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909662600 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:17:43 INFO BlockManagerMaster: Updated info of block input-0-1399909662600
14/05/12 21:17:43 WARN BlockManager: Block input-0-1399909662600 already exists on this machine; not re-adding it
14/05/12 21:17:50 INFO NetworkInputTracker: Stream 0 received 8 blocks
14/05/12 21:17:50 INFO JobScheduler: Added jobs for time 1399909670000 ms
14/05/12 21:17:50 INFO JobScheduler: Starting job streaming job 1399909670000 ms.0 from job set of time 1399909670000 ms
14/05/12 21:17:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:50 INFO DAGScheduler: Registering RDD 40 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:50 INFO DAGScheduler: Got job 13 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:50 INFO DAGScheduler: Final stage: Stage 25 (take at DStream.scala:586)
14/05/12 21:17:50 INFO DAGScheduler: Parents of final stage: List(Stage 26)
14/05/12 21:17:50 INFO DAGScheduler: Missing parents: List(Stage 26)
14/05/12 21:17:50 INFO DAGScheduler: Submitting Stage 26 (MapPartitionsRDD[40] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:50 INFO DAGScheduler: Submitting 8 missing tasks from Stage 26 (MapPartitionsRDD[40] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:50 INFO TaskSchedulerImpl: Adding task set 26.0 with 8 tasks
14/05/12 21:17:50 INFO TaskSetManager: Starting task 26.0:0 as TID 29 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 26.0:0 as 1517 bytes in 0 ms
14/05/12 21:17:50 INFO Executor: Running task ID 29
14/05/12 21:17:50 INFO BlockManager: Found block input-0-1399909657200 locally
14/05/12 21:17:50 INFO Executor: Serialized size of result for 29 is 751
14/05/12 21:17:50 INFO Executor: Sending result for 29 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 29
14/05/12 21:17:50 INFO TaskSetManager: Starting task 26.0:1 as TID 30 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 26.0:1 as 1517 bytes in 1 ms
14/05/12 21:17:50 INFO Executor: Running task ID 30
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 29 in 19 ms on localhost (progress: 0/8)
14/05/12 21:17:50 INFO DAGScheduler: Completed ShuffleMapTask(26, 0)
14/05/12 21:17:50 INFO BlockManager: Found block input-0-1399909658400 locally
14/05/12 21:17:50 INFO Executor: Serialized size of result for 30 is 751
14/05/12 21:17:50 INFO Executor: Sending result for 30 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 30
14/05/12 21:17:50 INFO TaskSetManager: Starting task 26.0:2 as TID 31 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 26.0:2 as 1517 bytes in 0 ms
14/05/12 21:17:50 INFO Executor: Running task ID 31
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 30 in 20 ms on localhost (progress: 1/8)
14/05/12 21:17:50 INFO DAGScheduler: Completed ShuffleMapTask(26, 1)
14/05/12 21:17:50 INFO BlockManager: Found block input-0-1399909658600 locally
14/05/12 21:17:50 INFO Executor: Serialized size of result for 31 is 751
14/05/12 21:17:50 INFO Executor: Sending result for 31 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 31
14/05/12 21:17:50 INFO TaskSetManager: Starting task 26.0:3 as TID 32 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 26.0:3 as 1517 bytes in 0 ms
14/05/12 21:17:50 INFO Executor: Running task ID 32
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 31 in 14 ms on localhost (progress: 2/8)
14/05/12 21:17:50 INFO DAGScheduler: Completed ShuffleMapTask(26, 2)
14/05/12 21:17:50 INFO BlockManager: Found block input-0-1399909658800 locally
14/05/12 21:17:50 INFO Executor: Serialized size of result for 32 is 751
14/05/12 21:17:50 INFO Executor: Sending result for 32 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 32
14/05/12 21:17:50 INFO TaskSetManager: Starting task 26.0:4 as TID 33 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 26.0:4 as 1517 bytes in 0 ms
14/05/12 21:17:50 INFO Executor: Running task ID 33
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 32 in 14 ms on localhost (progress: 3/8)
14/05/12 21:17:50 INFO DAGScheduler: Completed ShuffleMapTask(26, 3)
14/05/12 21:17:50 INFO BlockManager: Found block input-0-1399909659000 locally
14/05/12 21:17:50 INFO Executor: Serialized size of result for 33 is 751
14/05/12 21:17:50 INFO Executor: Sending result for 33 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 33
14/05/12 21:17:50 INFO TaskSetManager: Starting task 26.0:5 as TID 34 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 26.0:5 as 1517 bytes in 1 ms
14/05/12 21:17:50 INFO Executor: Running task ID 34
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 33 in 16 ms on localhost (progress: 4/8)
14/05/12 21:17:50 INFO DAGScheduler: Completed ShuffleMapTask(26, 4)
14/05/12 21:17:50 INFO BlockManager: Found block input-0-1399909659200 locally
14/05/12 21:17:50 INFO Executor: Serialized size of result for 34 is 751
14/05/12 21:17:50 INFO Executor: Sending result for 34 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 34
14/05/12 21:17:50 INFO TaskSetManager: Starting task 26.0:6 as TID 35 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 26.0:6 as 1517 bytes in 0 ms
14/05/12 21:17:50 INFO Executor: Running task ID 35
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 34 in 18 ms on localhost (progress: 5/8)
14/05/12 21:17:50 INFO DAGScheduler: Completed ShuffleMapTask(26, 5)
14/05/12 21:17:50 INFO BlockManager: Found block input-0-1399909660600 locally
14/05/12 21:17:50 INFO Executor: Serialized size of result for 35 is 751
14/05/12 21:17:50 INFO Executor: Sending result for 35 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 35
14/05/12 21:17:50 INFO TaskSetManager: Starting task 26.0:7 as TID 36 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 26.0:7 as 1517 bytes in 0 ms
14/05/12 21:17:50 INFO Executor: Running task ID 36
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 35 in 15 ms on localhost (progress: 6/8)
14/05/12 21:17:50 INFO DAGScheduler: Completed ShuffleMapTask(26, 6)
14/05/12 21:17:50 INFO BlockManager: Found block input-0-1399909662600 locally
14/05/12 21:17:50 INFO Executor: Serialized size of result for 36 is 751
14/05/12 21:17:50 INFO Executor: Sending result for 36 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 36
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 36 in 10 ms on localhost (progress: 7/8)
14/05/12 21:17:50 INFO TaskSchedulerImpl: Remove TaskSet 26.0 from pool 
14/05/12 21:17:50 INFO DAGScheduler: Completed ShuffleMapTask(26, 7)
14/05/12 21:17:50 INFO DAGScheduler: Stage 26 (combineByKey at ShuffledDStream.scala:42) finished in 0.115 s
14/05/12 21:17:50 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:17:50 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:17:50 INFO DAGScheduler: waiting: Set(Stage 25)
14/05/12 21:17:50 INFO DAGScheduler: failed: Set()
14/05/12 21:17:50 INFO DAGScheduler: Missing parents for Stage 25: List()
14/05/12 21:17:50 INFO DAGScheduler: Submitting Stage 25 (MapPartitionsRDD[42] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:17:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 25 (MapPartitionsRDD[42] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:50 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
14/05/12 21:17:50 INFO TaskSetManager: Starting task 25.0:0 as TID 37 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 25.0:0 as 1565 bytes in 0 ms
14/05/12 21:17:50 INFO Executor: Running task ID 37
14/05/12 21:17:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 8 non-zero-bytes blocks out of 8 blocks
14/05/12 21:17:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:17:50 INFO Executor: Serialized size of result for 37 is 1002
14/05/12 21:17:50 INFO Executor: Sending result for 37 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 37
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 37 in 25 ms on localhost (progress: 0/1)
14/05/12 21:17:50 INFO DAGScheduler: Completed ResultTask(25, 0)
14/05/12 21:17:50 INFO TaskSchedulerImpl: Remove TaskSet 25.0 from pool 
14/05/12 21:17:50 INFO DAGScheduler: Stage 25 (take at DStream.scala:586) finished in 0.026 s
14/05/12 21:17:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.171798221 s
14/05/12 21:17:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:17:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 150 bytes
14/05/12 21:17:50 INFO DAGScheduler: Got job 14 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:17:50 INFO DAGScheduler: Final stage: Stage 27 (take at DStream.scala:586)
14/05/12 21:17:50 INFO DAGScheduler: Parents of final stage: List(Stage 28)
14/05/12 21:17:50 INFO DAGScheduler: Missing parents: List()
14/05/12 21:17:50 INFO DAGScheduler: Submitting Stage 27 (MapPartitionsRDD[42] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:17:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 27 (MapPartitionsRDD[42] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:17:50 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
14/05/12 21:17:50 INFO TaskSetManager: Starting task 27.0:0 as TID 38 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:17:50 INFO TaskSetManager: Serialized task 27.0:0 as 1565 bytes in 1 ms
14/05/12 21:17:50 INFO Executor: Running task ID 38
14/05/12 21:17:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 8 blocks
14/05/12 21:17:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:17:50 INFO Executor: Serialized size of result for 38 is 813
14/05/12 21:17:50 INFO Executor: Sending result for 38 directly to driver
14/05/12 21:17:50 INFO Executor: Finished task ID 38
14/05/12 21:17:50 INFO TaskSetManager: Finished TID 38 in 10 ms on localhost (progress: 0/1)
14/05/12 21:17:50 INFO TaskSchedulerImpl: Remove TaskSet 27.0 from pool 
14/05/12 21:17:50 INFO DAGScheduler: Completed ResultTask(27, 1)
14/05/12 21:17:50 INFO DAGScheduler: Stage 27 (take at DStream.scala:586) finished in 0.013 s
14/05/12 21:17:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.02212108 s
14/05/12 21:17:50 INFO JobScheduler: Finished job streaming job 1399909670000 ms.0 from job set of time 1399909670000 ms
14/05/12 21:17:50 INFO JobScheduler: Total delay: 0.217 s for time 1399909670000 ms (execution: 0.202 s)
14/05/12 21:18:00 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/12 21:18:00 INFO JobScheduler: Added jobs for time 1399909680000 ms
14/05/12 21:18:00 INFO JobScheduler: Starting job streaming job 1399909680000 ms.0 from job set of time 1399909680000 ms
14/05/12 21:18:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:00 INFO DAGScheduler: Registering RDD 46 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:00 INFO DAGScheduler: Got job 15 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:00 INFO DAGScheduler: Final stage: Stage 29 (take at DStream.scala:586)
14/05/12 21:18:00 INFO DAGScheduler: Parents of final stage: List(Stage 30)
14/05/12 21:18:00 INFO DAGScheduler: Missing parents: List()
14/05/12 21:18:00 INFO DAGScheduler: Submitting Stage 29 (MapPartitionsRDD[48] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 29 (MapPartitionsRDD[48] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:00 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
14/05/12 21:18:00 INFO TaskSetManager: Starting task 29.0:0 as TID 39 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:00 INFO TaskSetManager: Serialized task 29.0:0 as 1563 bytes in 0 ms
14/05/12 21:18:00 INFO Executor: Running task ID 39
14/05/12 21:18:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:18:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:18:00 INFO Executor: Serialized size of result for 39 is 813
14/05/12 21:18:00 INFO Executor: Sending result for 39 directly to driver
14/05/12 21:18:00 INFO Executor: Finished task ID 39
14/05/12 21:18:00 INFO TaskSetManager: Finished TID 39 in 13 ms on localhost (progress: 0/1)
14/05/12 21:18:00 INFO DAGScheduler: Completed ResultTask(29, 0)
14/05/12 21:18:00 INFO TaskSchedulerImpl: Remove TaskSet 29.0 from pool 
14/05/12 21:18:00 INFO DAGScheduler: Stage 29 (take at DStream.scala:586) finished in 0.015 s
14/05/12 21:18:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.023015067 s
14/05/12 21:18:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 82 bytes
14/05/12 21:18:00 INFO DAGScheduler: Got job 16 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:00 INFO DAGScheduler: Final stage: Stage 31 (take at DStream.scala:586)
14/05/12 21:18:00 INFO DAGScheduler: Parents of final stage: List(Stage 32)
14/05/12 21:18:00 INFO DAGScheduler: Missing parents: List()
14/05/12 21:18:00 INFO DAGScheduler: Submitting Stage 31 (MapPartitionsRDD[48] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 31 (MapPartitionsRDD[48] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:00 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
14/05/12 21:18:00 INFO TaskSetManager: Starting task 31.0:0 as TID 40 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:00 INFO TaskSetManager: Serialized task 31.0:0 as 1563 bytes in 0 ms
14/05/12 21:18:00 INFO Executor: Running task ID 40
14/05/12 21:18:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:18:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:18:00 INFO Executor: Serialized size of result for 40 is 813
14/05/12 21:18:00 INFO Executor: Sending result for 40 directly to driver
14/05/12 21:18:00 INFO Executor: Finished task ID 40
14/05/12 21:18:00 INFO TaskSetManager: Finished TID 40 in 13 ms on localhost (progress: 0/1)
14/05/12 21:18:00 INFO TaskSchedulerImpl: Remove TaskSet 31.0 from pool 
14/05/12 21:18:00 INFO DAGScheduler: Completed ResultTask(31, 1)
14/05/12 21:18:00 INFO DAGScheduler: Stage 31 (take at DStream.scala:586) finished in 0.014 s
14/05/12 21:18:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.024758014 s
14/05/12 21:18:00 INFO JobScheduler: Finished job streaming job 1399909680000 ms.0 from job set of time 1399909680000 ms
14/05/12 21:18:00 INFO JobScheduler: Total delay: 0.069 s for time 1399909680000 ms (execution: 0.057 s)
14/05/12 21:18:10 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/12 21:18:10 INFO MemoryStore: ensureFreeSpace(10) called with curMem=230, maxMem=671298355
14/05/12 21:18:10 INFO MemoryStore: Block input-0-1399909689800 stored as bytes to memory (size 10.0 B, free 640.2 MB)
14/05/12 21:18:10 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909689800 in memory on ubuntu-3.local:46407 (size: 10.0 B, free: 640.2 MB)
14/05/12 21:18:10 INFO BlockManagerMaster: Updated info of block input-0-1399909689800
14/05/12 21:18:10 INFO JobScheduler: Added jobs for time 1399909690000 ms
14/05/12 21:18:10 INFO JobScheduler: Starting job streaming job 1399909690000 ms.0 from job set of time 1399909690000 ms
14/05/12 21:18:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:10 INFO DAGScheduler: Registering RDD 52 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:10 INFO DAGScheduler: Got job 17 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:10 INFO DAGScheduler: Final stage: Stage 33 (take at DStream.scala:586)
14/05/12 21:18:10 INFO DAGScheduler: Parents of final stage: List(Stage 34)
14/05/12 21:18:10 INFO DAGScheduler: Missing parents: List()
14/05/12 21:18:10 INFO DAGScheduler: Submitting Stage 33 (MapPartitionsRDD[54] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 33 (MapPartitionsRDD[54] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:10 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
14/05/12 21:18:10 INFO TaskSetManager: Starting task 33.0:0 as TID 41 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:10 INFO TaskSetManager: Serialized task 33.0:0 as 1563 bytes in 1 ms
14/05/12 21:18:10 INFO Executor: Running task ID 41
14/05/12 21:18:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:18:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:18:10 INFO Executor: Serialized size of result for 41 is 813
14/05/12 21:18:10 INFO Executor: Sending result for 41 directly to driver
14/05/12 21:18:10 INFO Executor: Finished task ID 41
14/05/12 21:18:10 INFO TaskSetManager: Finished TID 41 in 17 ms on localhost (progress: 0/1)
14/05/12 21:18:10 INFO DAGScheduler: Completed ResultTask(33, 0)
14/05/12 21:18:10 INFO TaskSchedulerImpl: Remove TaskSet 33.0 from pool 
14/05/12 21:18:10 INFO DAGScheduler: Stage 33 (take at DStream.scala:586) finished in 0.021 s
14/05/12 21:18:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.030644704 s
14/05/12 21:18:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 82 bytes
14/05/12 21:18:10 INFO DAGScheduler: Got job 18 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:10 INFO DAGScheduler: Final stage: Stage 35 (take at DStream.scala:586)
14/05/12 21:18:10 INFO DAGScheduler: Parents of final stage: List(Stage 36)
14/05/12 21:18:10 INFO DAGScheduler: Missing parents: List()
14/05/12 21:18:10 INFO DAGScheduler: Submitting Stage 35 (MapPartitionsRDD[54] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 35 (MapPartitionsRDD[54] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:10 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
14/05/12 21:18:10 INFO TaskSetManager: Starting task 35.0:0 as TID 42 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:10 INFO TaskSetManager: Serialized task 35.0:0 as 1563 bytes in 0 ms
14/05/12 21:18:10 INFO Executor: Running task ID 42
14/05/12 21:18:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:18:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:18:10 INFO Executor: Serialized size of result for 42 is 813
14/05/12 21:18:10 INFO Executor: Sending result for 42 directly to driver
14/05/12 21:18:10 INFO Executor: Finished task ID 42
14/05/12 21:18:10 INFO TaskSetManager: Finished TID 42 in 13 ms on localhost (progress: 0/1)
14/05/12 21:18:10 INFO DAGScheduler: Completed ResultTask(35, 1)
14/05/12 21:18:10 INFO TaskSchedulerImpl: Remove TaskSet 35.0 from pool 
14/05/12 21:18:10 INFO DAGScheduler: Stage 35 (take at DStream.scala:586) finished in 0.016 s
14/05/12 21:18:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.029927674 s
14/05/12 21:18:10 INFO JobScheduler: Finished job streaming job 1399909690000 ms.0 from job set of time 1399909690000 ms
14/05/12 21:18:10 INFO JobScheduler: Total delay: 0.087 s for time 1399909690000 ms (execution: 0.067 s)
14/05/12 21:18:10 WARN BlockManager: Block input-0-1399909689800 already exists on this machine; not re-adding it
14/05/12 21:18:11 INFO MemoryStore: ensureFreeSpace(10) called with curMem=240, maxMem=671298355
14/05/12 21:18:11 INFO MemoryStore: Block input-0-1399909691200 stored as bytes to memory (size 10.0 B, free 640.2 MB)
14/05/12 21:18:11 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909691200 in memory on ubuntu-3.local:46407 (size: 10.0 B, free: 640.2 MB)
14/05/12 21:18:11 INFO BlockManagerMaster: Updated info of block input-0-1399909691200
14/05/12 21:18:11 WARN BlockManager: Block input-0-1399909691200 already exists on this machine; not re-adding it
14/05/12 21:18:14 INFO MemoryStore: ensureFreeSpace(9) called with curMem=250, maxMem=671298355
14/05/12 21:18:14 INFO MemoryStore: Block input-0-1399909693800 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/12 21:18:14 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909693800 in memory on ubuntu-3.local:46407 (size: 9.0 B, free: 640.2 MB)
14/05/12 21:18:14 INFO BlockManagerMaster: Updated info of block input-0-1399909693800
14/05/12 21:18:14 WARN BlockManager: Block input-0-1399909693800 already exists on this machine; not re-adding it
14/05/12 21:18:18 INFO MemoryStore: ensureFreeSpace(10) called with curMem=259, maxMem=671298355
14/05/12 21:18:18 INFO MemoryStore: Block input-0-1399909697800 stored as bytes to memory (size 10.0 B, free 640.2 MB)
14/05/12 21:18:18 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909697800 in memory on ubuntu-3.local:46407 (size: 10.0 B, free: 640.2 MB)
14/05/12 21:18:18 INFO BlockManagerMaster: Updated info of block input-0-1399909697800
14/05/12 21:18:18 WARN BlockManager: Block input-0-1399909697800 already exists on this machine; not re-adding it
14/05/12 21:18:18 INFO MemoryStore: ensureFreeSpace(9) called with curMem=269, maxMem=671298355
14/05/12 21:18:18 INFO MemoryStore: Block input-0-1399909698400 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/12 21:18:18 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909698400 in memory on ubuntu-3.local:46407 (size: 9.0 B, free: 640.2 MB)
14/05/12 21:18:18 INFO BlockManagerMaster: Updated info of block input-0-1399909698400
14/05/12 21:18:18 WARN BlockManager: Block input-0-1399909698400 already exists on this machine; not re-adding it
14/05/12 21:18:19 INFO MemoryStore: ensureFreeSpace(9) called with curMem=278, maxMem=671298355
14/05/12 21:18:19 INFO MemoryStore: Block input-0-1399909699000 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/12 21:18:19 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909699000 in memory on ubuntu-3.local:46407 (size: 9.0 B, free: 640.2 MB)
14/05/12 21:18:19 INFO BlockManagerMaster: Updated info of block input-0-1399909699000
14/05/12 21:18:19 WARN BlockManager: Block input-0-1399909699000 already exists on this machine; not re-adding it
14/05/12 21:18:19 INFO MemoryStore: ensureFreeSpace(7) called with curMem=287, maxMem=671298355
14/05/12 21:18:19 INFO MemoryStore: Block input-0-1399909699400 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:18:19 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909699400 in memory on ubuntu-3.local:46407 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:18:19 INFO BlockManagerMaster: Updated info of block input-0-1399909699400
14/05/12 21:18:19 WARN BlockManager: Block input-0-1399909699400 already exists on this machine; not re-adding it
14/05/12 21:18:19 INFO MemoryStore: ensureFreeSpace(7) called with curMem=294, maxMem=671298355
14/05/12 21:18:19 INFO MemoryStore: Block input-0-1399909699600 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:18:19 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909699600 in memory on ubuntu-3.local:46407 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:18:19 INFO BlockManagerMaster: Updated info of block input-0-1399909699600
14/05/12 21:18:19 WARN BlockManager: Block input-0-1399909699600 already exists on this machine; not re-adding it
14/05/12 21:18:20 INFO NetworkInputTracker: Stream 0 received 8 blocks
14/05/12 21:18:20 INFO MemoryStore: ensureFreeSpace(10) called with curMem=301, maxMem=671298355
14/05/12 21:18:20 INFO MemoryStore: Block input-0-1399909699800 stored as bytes to memory (size 10.0 B, free 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909699800 in memory on ubuntu-3.local:46407 (size: 10.0 B, free: 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMaster: Updated info of block input-0-1399909699800
14/05/12 21:18:20 INFO JobScheduler: Added jobs for time 1399909700000 ms
14/05/12 21:18:20 INFO JobScheduler: Starting job streaming job 1399909700000 ms.0 from job set of time 1399909700000 ms
14/05/12 21:18:20 WARN BlockManager: Block input-0-1399909699800 already exists on this machine; not re-adding it
14/05/12 21:18:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:20 INFO DAGScheduler: Registering RDD 58 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:20 INFO DAGScheduler: Got job 19 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:20 INFO DAGScheduler: Final stage: Stage 37 (take at DStream.scala:586)
14/05/12 21:18:20 INFO DAGScheduler: Parents of final stage: List(Stage 38)
14/05/12 21:18:20 INFO DAGScheduler: Missing parents: List(Stage 38)
14/05/12 21:18:20 INFO DAGScheduler: Submitting Stage 38 (MapPartitionsRDD[58] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:20 INFO DAGScheduler: Submitting 8 missing tasks from Stage 38 (MapPartitionsRDD[58] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:20 INFO TaskSchedulerImpl: Adding task set 38.0 with 8 tasks
14/05/12 21:18:20 INFO TaskSetManager: Starting task 38.0:0 as TID 43 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 38.0:0 as 1519 bytes in 1 ms
14/05/12 21:18:20 INFO Executor: Running task ID 43
14/05/12 21:18:20 INFO BlockManager: Found block input-0-1399909689800 locally
14/05/12 21:18:20 INFO Executor: Serialized size of result for 43 is 751
14/05/12 21:18:20 INFO Executor: Sending result for 43 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 43
14/05/12 21:18:20 INFO TaskSetManager: Starting task 38.0:1 as TID 44 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 38.0:1 as 1519 bytes in 0 ms
14/05/12 21:18:20 INFO Executor: Running task ID 44
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 43 in 12 ms on localhost (progress: 0/8)
14/05/12 21:18:20 INFO DAGScheduler: Completed ShuffleMapTask(38, 0)
14/05/12 21:18:20 INFO BlockManager: Found block input-0-1399909691200 locally
14/05/12 21:18:20 INFO Executor: Serialized size of result for 44 is 751
14/05/12 21:18:20 INFO Executor: Sending result for 44 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 44
14/05/12 21:18:20 INFO TaskSetManager: Starting task 38.0:2 as TID 45 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 38.0:2 as 1519 bytes in 1 ms
14/05/12 21:18:20 INFO Executor: Running task ID 45
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 44 in 20 ms on localhost (progress: 1/8)
14/05/12 21:18:20 INFO DAGScheduler: Completed ShuffleMapTask(38, 1)
14/05/12 21:18:20 INFO BlockManager: Found block input-0-1399909693800 locally
14/05/12 21:18:20 INFO Executor: Serialized size of result for 45 is 751
14/05/12 21:18:20 INFO Executor: Sending result for 45 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 45
14/05/12 21:18:20 INFO TaskSetManager: Starting task 38.0:3 as TID 46 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 38.0:3 as 1519 bytes in 0 ms
14/05/12 21:18:20 INFO Executor: Running task ID 46
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 45 in 21 ms on localhost (progress: 2/8)
14/05/12 21:18:20 INFO DAGScheduler: Completed ShuffleMapTask(38, 2)
14/05/12 21:18:20 INFO BlockManager: Found block input-0-1399909697800 locally
14/05/12 21:18:20 INFO Executor: Serialized size of result for 46 is 751
14/05/12 21:18:20 INFO Executor: Sending result for 46 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 46
14/05/12 21:18:20 INFO TaskSetManager: Starting task 38.0:4 as TID 47 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 38.0:4 as 1519 bytes in 0 ms
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 46 in 19 ms on localhost (progress: 3/8)
14/05/12 21:18:20 INFO Executor: Running task ID 47
14/05/12 21:18:20 INFO DAGScheduler: Completed ShuffleMapTask(38, 3)
14/05/12 21:18:20 INFO BlockManager: Found block input-0-1399909698400 locally
14/05/12 21:18:20 INFO Executor: Serialized size of result for 47 is 751
14/05/12 21:18:20 INFO Executor: Sending result for 47 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 47
14/05/12 21:18:20 INFO TaskSetManager: Starting task 38.0:5 as TID 48 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 38.0:5 as 1519 bytes in 1 ms
14/05/12 21:18:20 INFO Executor: Running task ID 48
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 47 in 16 ms on localhost (progress: 4/8)
14/05/12 21:18:20 INFO DAGScheduler: Completed ShuffleMapTask(38, 4)
14/05/12 21:18:20 INFO BlockManager: Found block input-0-1399909699000 locally
14/05/12 21:18:20 INFO Executor: Serialized size of result for 48 is 751
14/05/12 21:18:20 INFO Executor: Sending result for 48 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 48
14/05/12 21:18:20 INFO TaskSetManager: Starting task 38.0:6 as TID 49 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 38.0:6 as 1519 bytes in 0 ms
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 48 in 14 ms on localhost (progress: 5/8)
14/05/12 21:18:20 INFO Executor: Running task ID 49
14/05/12 21:18:20 INFO DAGScheduler: Completed ShuffleMapTask(38, 5)
14/05/12 21:18:20 INFO BlockManager: Found block input-0-1399909699400 locally
14/05/12 21:18:20 INFO Executor: Serialized size of result for 49 is 751
14/05/12 21:18:20 INFO Executor: Sending result for 49 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 49
14/05/12 21:18:20 INFO TaskSetManager: Starting task 38.0:7 as TID 50 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 38.0:7 as 1519 bytes in 0 ms
14/05/12 21:18:20 INFO Executor: Running task ID 50
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 49 in 14 ms on localhost (progress: 6/8)
14/05/12 21:18:20 INFO DAGScheduler: Completed ShuffleMapTask(38, 6)
14/05/12 21:18:20 INFO BlockManager: Found block input-0-1399909699600 locally
14/05/12 21:18:20 INFO Executor: Serialized size of result for 50 is 751
14/05/12 21:18:20 INFO Executor: Sending result for 50 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 50
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 50 in 12 ms on localhost (progress: 7/8)
14/05/12 21:18:20 INFO TaskSchedulerImpl: Remove TaskSet 38.0 from pool 
14/05/12 21:18:20 INFO DAGScheduler: Completed ShuffleMapTask(38, 7)
14/05/12 21:18:20 INFO DAGScheduler: Stage 38 (combineByKey at ShuffledDStream.scala:42) finished in 0.109 s
14/05/12 21:18:20 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:18:20 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:18:20 INFO DAGScheduler: waiting: Set(Stage 37)
14/05/12 21:18:20 INFO DAGScheduler: failed: Set()
14/05/12 21:18:20 INFO DAGScheduler: Missing parents for Stage 37: List()
14/05/12 21:18:20 INFO DAGScheduler: Submitting Stage 37 (MapPartitionsRDD[60] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:18:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 37 (MapPartitionsRDD[60] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:20 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
14/05/12 21:18:20 INFO TaskSetManager: Starting task 37.0:0 as TID 51 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 37.0:0 as 1565 bytes in 0 ms
14/05/12 21:18:20 INFO Executor: Running task ID 51
14/05/12 21:18:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 4 non-zero-bytes blocks out of 8 blocks
14/05/12 21:18:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:18:20 INFO Executor: Serialized size of result for 51 is 975
14/05/12 21:18:20 INFO Executor: Sending result for 51 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 51
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 51 in 20 ms on localhost (progress: 0/1)
14/05/12 21:18:20 INFO TaskSchedulerImpl: Remove TaskSet 37.0 from pool 
14/05/12 21:18:20 INFO DAGScheduler: Completed ResultTask(37, 0)
14/05/12 21:18:20 INFO DAGScheduler: Stage 37 (take at DStream.scala:586) finished in 0.023 s
14/05/12 21:18:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.159387761 s
14/05/12 21:18:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 156 bytes
14/05/12 21:18:20 INFO DAGScheduler: Got job 20 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:20 INFO DAGScheduler: Final stage: Stage 39 (take at DStream.scala:586)
14/05/12 21:18:20 INFO DAGScheduler: Parents of final stage: List(Stage 40)
14/05/12 21:18:20 INFO DAGScheduler: Missing parents: List()
14/05/12 21:18:20 INFO DAGScheduler: Submitting Stage 39 (MapPartitionsRDD[60] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 39 (MapPartitionsRDD[60] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:20 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
14/05/12 21:18:20 INFO TaskSetManager: Starting task 39.0:0 as TID 52 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:20 INFO TaskSetManager: Serialized task 39.0:0 as 1564 bytes in 1 ms
14/05/12 21:18:20 INFO Executor: Running task ID 52
14/05/12 21:18:20 INFO MemoryStore: ensureFreeSpace(7) called with curMem=311, maxMem=671298355
14/05/12 21:18:20 INFO MemoryStore: Block input-0-1399909700000 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909700000 in memory on ubuntu-3.local:46407 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMaster: Updated info of block input-0-1399909700000
14/05/12 21:18:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 4 non-zero-bytes blocks out of 8 blocks
14/05/12 21:18:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:18:20 INFO Executor: Serialized size of result for 52 is 981
14/05/12 21:18:20 INFO Executor: Sending result for 52 directly to driver
14/05/12 21:18:20 INFO Executor: Finished task ID 52
14/05/12 21:18:20 INFO TaskSetManager: Finished TID 52 in 19 ms on localhost (progress: 0/1)
14/05/12 21:18:20 INFO DAGScheduler: Completed ResultTask(39, 1)
14/05/12 21:18:20 INFO TaskSchedulerImpl: Remove TaskSet 39.0 from pool 
14/05/12 21:18:20 INFO DAGScheduler: Stage 39 (take at DStream.scala:586) finished in 0.022 s
14/05/12 21:18:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.03734578 s
14/05/12 21:18:20 INFO JobScheduler: Finished job streaming job 1399909700000 ms.0 from job set of time 1399909700000 ms
14/05/12 21:18:20 INFO JobScheduler: Total delay: 0.221 s for time 1399909700000 ms (execution: 0.202 s)
14/05/12 21:18:20 WARN BlockManager: Block input-0-1399909700000 already exists on this machine; not re-adding it
14/05/12 21:18:20 INFO MemoryStore: ensureFreeSpace(10) called with curMem=318, maxMem=671298355
14/05/12 21:18:20 INFO MemoryStore: Block input-0-1399909700200 stored as bytes to memory (size 10.0 B, free 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909700200 in memory on ubuntu-3.local:46407 (size: 10.0 B, free: 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMaster: Updated info of block input-0-1399909700200
14/05/12 21:18:20 WARN BlockManager: Block input-0-1399909700200 already exists on this machine; not re-adding it
14/05/12 21:18:20 INFO MemoryStore: ensureFreeSpace(7) called with curMem=328, maxMem=671298355
14/05/12 21:18:20 INFO MemoryStore: Block input-0-1399909700400 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909700400 in memory on ubuntu-3.local:46407 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMaster: Updated info of block input-0-1399909700400
14/05/12 21:18:20 WARN BlockManager: Block input-0-1399909700400 already exists on this machine; not re-adding it
14/05/12 21:18:20 INFO MemoryStore: ensureFreeSpace(7) called with curMem=335, maxMem=671298355
14/05/12 21:18:20 INFO MemoryStore: Block input-0-1399909700600 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909700600 in memory on ubuntu-3.local:46407 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:18:20 INFO BlockManagerMaster: Updated info of block input-0-1399909700600
14/05/12 21:18:20 WARN BlockManager: Block input-0-1399909700600 already exists on this machine; not re-adding it
14/05/12 21:18:21 INFO MemoryStore: ensureFreeSpace(7) called with curMem=342, maxMem=671298355
14/05/12 21:18:21 INFO MemoryStore: Block input-0-1399909700800 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:18:21 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909700800 in memory on ubuntu-3.local:46407 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:18:21 INFO BlockManagerMaster: Updated info of block input-0-1399909700800
14/05/12 21:18:21 WARN BlockManager: Block input-0-1399909700800 already exists on this machine; not re-adding it
14/05/12 21:18:30 INFO NetworkInputTracker: Stream 0 received 6 blocks
14/05/12 21:18:30 INFO JobScheduler: Added jobs for time 1399909710000 ms
14/05/12 21:18:30 INFO JobScheduler: Starting job streaming job 1399909710000 ms.0 from job set of time 1399909710000 ms
14/05/12 21:18:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:30 INFO DAGScheduler: Registering RDD 64 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:30 INFO DAGScheduler: Got job 21 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:30 INFO DAGScheduler: Final stage: Stage 41 (take at DStream.scala:586)
14/05/12 21:18:30 INFO DAGScheduler: Parents of final stage: List(Stage 42)
14/05/12 21:18:30 INFO DAGScheduler: Missing parents: List(Stage 42)
14/05/12 21:18:30 INFO DAGScheduler: Submitting Stage 42 (MapPartitionsRDD[64] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:30 INFO DAGScheduler: Submitting 6 missing tasks from Stage 42 (MapPartitionsRDD[64] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:30 INFO TaskSchedulerImpl: Adding task set 42.0 with 6 tasks
14/05/12 21:18:30 INFO TaskSetManager: Starting task 42.0:0 as TID 53 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:30 INFO TaskSetManager: Serialized task 42.0:0 as 1519 bytes in 1 ms
14/05/12 21:18:30 INFO Executor: Running task ID 53
14/05/12 21:18:30 INFO BlockManager: Found block input-0-1399909699800 locally
14/05/12 21:18:30 INFO Executor: Serialized size of result for 53 is 751
14/05/12 21:18:30 INFO Executor: Sending result for 53 directly to driver
14/05/12 21:18:30 INFO Executor: Finished task ID 53
14/05/12 21:18:30 INFO TaskSetManager: Starting task 42.0:1 as TID 54 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:30 INFO TaskSetManager: Serialized task 42.0:1 as 1519 bytes in 1 ms
14/05/12 21:18:30 INFO Executor: Running task ID 54
14/05/12 21:18:30 INFO TaskSetManager: Finished TID 53 in 18 ms on localhost (progress: 0/6)
14/05/12 21:18:30 INFO DAGScheduler: Completed ShuffleMapTask(42, 0)
14/05/12 21:18:30 INFO BlockManager: Found block input-0-1399909700000 locally
14/05/12 21:18:30 INFO Executor: Serialized size of result for 54 is 751
14/05/12 21:18:30 INFO Executor: Sending result for 54 directly to driver
14/05/12 21:18:30 INFO Executor: Finished task ID 54
14/05/12 21:18:30 INFO TaskSetManager: Starting task 42.0:2 as TID 55 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:30 INFO TaskSetManager: Serialized task 42.0:2 as 1519 bytes in 0 ms
14/05/12 21:18:30 INFO Executor: Running task ID 55
14/05/12 21:18:30 INFO TaskSetManager: Finished TID 54 in 11 ms on localhost (progress: 1/6)
14/05/12 21:18:30 INFO DAGScheduler: Completed ShuffleMapTask(42, 1)
14/05/12 21:18:30 INFO BlockManager: Found block input-0-1399909700200 locally
14/05/12 21:18:30 INFO Executor: Serialized size of result for 55 is 751
14/05/12 21:18:30 INFO Executor: Sending result for 55 directly to driver
14/05/12 21:18:30 INFO Executor: Finished task ID 55
14/05/12 21:18:30 INFO TaskSetManager: Starting task 42.0:3 as TID 56 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:30 INFO TaskSetManager: Serialized task 42.0:3 as 1519 bytes in 1 ms
14/05/12 21:18:30 INFO Executor: Running task ID 56
14/05/12 21:18:30 INFO TaskSetManager: Finished TID 55 in 12 ms on localhost (progress: 2/6)
14/05/12 21:18:30 INFO DAGScheduler: Completed ShuffleMapTask(42, 2)
14/05/12 21:18:30 INFO BlockManager: Found block input-0-1399909700400 locally
14/05/12 21:18:30 INFO Executor: Serialized size of result for 56 is 751
14/05/12 21:18:30 INFO Executor: Sending result for 56 directly to driver
14/05/12 21:18:30 INFO Executor: Finished task ID 56
14/05/12 21:18:30 INFO TaskSetManager: Starting task 42.0:4 as TID 57 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:30 INFO TaskSetManager: Serialized task 42.0:4 as 1519 bytes in 1 ms
14/05/12 21:18:30 INFO Executor: Running task ID 57
14/05/12 21:18:30 INFO TaskSetManager: Finished TID 56 in 17 ms on localhost (progress: 3/6)
14/05/12 21:18:30 INFO DAGScheduler: Completed ShuffleMapTask(42, 3)
14/05/12 21:18:30 INFO BlockManager: Found block input-0-1399909700600 locally
14/05/12 21:18:30 INFO Executor: Serialized size of result for 57 is 751
14/05/12 21:18:30 INFO Executor: Sending result for 57 directly to driver
14/05/12 21:18:30 INFO Executor: Finished task ID 57
14/05/12 21:18:30 INFO TaskSetManager: Starting task 42.0:5 as TID 58 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:30 INFO TaskSetManager: Serialized task 42.0:5 as 1519 bytes in 0 ms
14/05/12 21:18:30 INFO Executor: Running task ID 58
14/05/12 21:18:30 INFO TaskSetManager: Finished TID 57 in 17 ms on localhost (progress: 4/6)
14/05/12 21:18:30 INFO DAGScheduler: Completed ShuffleMapTask(42, 4)
14/05/12 21:18:30 INFO BlockManager: Found block input-0-1399909700800 locally
14/05/12 21:18:30 INFO Executor: Serialized size of result for 58 is 751
14/05/12 21:18:30 INFO Executor: Sending result for 58 directly to driver
14/05/12 21:18:30 INFO Executor: Finished task ID 58
14/05/12 21:18:30 INFO TaskSetManager: Finished TID 58 in 10 ms on localhost (progress: 5/6)
14/05/12 21:18:30 INFO TaskSchedulerImpl: Remove TaskSet 42.0 from pool 
14/05/12 21:18:30 INFO DAGScheduler: Completed ShuffleMapTask(42, 5)
14/05/12 21:18:30 INFO DAGScheduler: Stage 42 (combineByKey at ShuffledDStream.scala:42) finished in 0.077 s
14/05/12 21:18:30 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:18:30 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:18:30 INFO DAGScheduler: waiting: Set(Stage 41)
14/05/12 21:18:30 INFO DAGScheduler: failed: Set()
14/05/12 21:18:30 INFO DAGScheduler: Missing parents for Stage 41: List()
14/05/12 21:18:30 INFO DAGScheduler: Submitting Stage 41 (MapPartitionsRDD[66] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:18:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 41 (MapPartitionsRDD[66] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:30 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
14/05/12 21:18:30 INFO TaskSetManager: Starting task 41.0:0 as TID 59 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:30 INFO TaskSetManager: Serialized task 41.0:0 as 1565 bytes in 1 ms
14/05/12 21:18:30 INFO Executor: Running task ID 59
14/05/12 21:18:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 6 non-zero-bytes blocks out of 6 blocks
14/05/12 21:18:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:18:30 INFO Executor: Serialized size of result for 59 is 958
14/05/12 21:18:30 INFO Executor: Sending result for 59 directly to driver
14/05/12 21:18:30 INFO Executor: Finished task ID 59
14/05/12 21:18:30 INFO TaskSetManager: Finished TID 59 in 21 ms on localhost (progress: 0/1)
14/05/12 21:18:30 INFO TaskSchedulerImpl: Remove TaskSet 41.0 from pool 
14/05/12 21:18:30 INFO DAGScheduler: Completed ResultTask(41, 0)
14/05/12 21:18:30 INFO DAGScheduler: Stage 41 (take at DStream.scala:586) finished in 0.023 s
14/05/12 21:18:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.126928675 s
14/05/12 21:18:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 148 bytes
14/05/12 21:18:30 INFO DAGScheduler: Got job 22 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:30 INFO DAGScheduler: Final stage: Stage 43 (take at DStream.scala:586)
14/05/12 21:18:30 INFO DAGScheduler: Parents of final stage: List(Stage 44)
14/05/12 21:18:30 INFO DAGScheduler: Missing parents: List()
14/05/12 21:18:30 INFO DAGScheduler: Submitting Stage 43 (MapPartitionsRDD[66] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 43 (MapPartitionsRDD[66] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:30 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
14/05/12 21:18:30 INFO TaskSetManager: Starting task 43.0:0 as TID 60 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:30 INFO TaskSetManager: Serialized task 43.0:0 as 1565 bytes in 0 ms
14/05/12 21:18:30 INFO Executor: Running task ID 60
14/05/12 21:18:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 6 blocks
14/05/12 21:18:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:18:30 INFO Executor: Serialized size of result for 60 is 813
14/05/12 21:18:30 INFO Executor: Sending result for 60 directly to driver
14/05/12 21:18:30 INFO Executor: Finished task ID 60
14/05/12 21:18:30 INFO TaskSetManager: Finished TID 60 in 16 ms on localhost (progress: 0/1)
14/05/12 21:18:30 INFO DAGScheduler: Completed ResultTask(43, 1)
14/05/12 21:18:30 INFO TaskSchedulerImpl: Remove TaskSet 43.0 from pool 
14/05/12 21:18:30 INFO DAGScheduler: Stage 43 (take at DStream.scala:586) finished in 0.018 s
14/05/12 21:18:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.033165694 s
14/05/12 21:18:30 INFO JobScheduler: Finished job streaming job 1399909710000 ms.0 from job set of time 1399909710000 ms
14/05/12 21:18:30 INFO JobScheduler: Total delay: 0.186 s for time 1399909710000 ms (execution: 0.169 s)
14/05/12 21:18:37 INFO MemoryStore: ensureFreeSpace(10) called with curMem=349, maxMem=671298355
14/05/12 21:18:37 INFO MemoryStore: Block input-0-1399909717000 stored as bytes to memory (size 10.0 B, free 640.2 MB)
14/05/12 21:18:37 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909717000 in memory on ubuntu-3.local:46407 (size: 10.0 B, free: 640.2 MB)
14/05/12 21:18:37 INFO BlockManagerMaster: Updated info of block input-0-1399909717000
14/05/12 21:18:37 WARN BlockManager: Block input-0-1399909717000 already exists on this machine; not re-adding it
14/05/12 21:18:38 INFO MemoryStore: ensureFreeSpace(10) called with curMem=359, maxMem=671298355
14/05/12 21:18:38 INFO MemoryStore: Block input-0-1399909718000 stored as bytes to memory (size 10.0 B, free 640.2 MB)
14/05/12 21:18:38 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909718000 in memory on ubuntu-3.local:46407 (size: 10.0 B, free: 640.2 MB)
14/05/12 21:18:38 INFO BlockManagerMaster: Updated info of block input-0-1399909718000
14/05/12 21:18:38 WARN BlockManager: Block input-0-1399909718000 already exists on this machine; not re-adding it
14/05/12 21:18:38 INFO MemoryStore: ensureFreeSpace(10) called with curMem=369, maxMem=671298355
14/05/12 21:18:38 INFO MemoryStore: Block input-0-1399909718400 stored as bytes to memory (size 10.0 B, free 640.2 MB)
14/05/12 21:18:38 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909718400 in memory on ubuntu-3.local:46407 (size: 10.0 B, free: 640.2 MB)
14/05/12 21:18:38 INFO BlockManagerMaster: Updated info of block input-0-1399909718400
14/05/12 21:18:38 WARN BlockManager: Block input-0-1399909718400 already exists on this machine; not re-adding it
14/05/12 21:18:40 INFO NetworkInputTracker: Stream 0 received 2 blocks
14/05/12 21:18:40 INFO JobScheduler: Added jobs for time 1399909720000 ms
14/05/12 21:18:40 INFO JobScheduler: Starting job streaming job 1399909720000 ms.0 from job set of time 1399909720000 ms
14/05/12 21:18:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:40 INFO DAGScheduler: Registering RDD 70 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:40 INFO DAGScheduler: Got job 23 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:40 INFO DAGScheduler: Final stage: Stage 45 (take at DStream.scala:586)
14/05/12 21:18:40 INFO DAGScheduler: Parents of final stage: List(Stage 46)
14/05/12 21:18:40 INFO DAGScheduler: Missing parents: List(Stage 46)
14/05/12 21:18:40 INFO DAGScheduler: Submitting Stage 46 (MapPartitionsRDD[70] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:40 INFO DAGScheduler: Submitting 2 missing tasks from Stage 46 (MapPartitionsRDD[70] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:40 INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks
14/05/12 21:18:40 INFO TaskSetManager: Starting task 46.0:0 as TID 61 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:40 INFO TaskSetManager: Serialized task 46.0:0 as 1519 bytes in 1 ms
14/05/12 21:18:40 INFO Executor: Running task ID 61
14/05/12 21:18:40 INFO BlockManager: Found block input-0-1399909717000 locally
14/05/12 21:18:40 INFO Executor: Serialized size of result for 61 is 751
14/05/12 21:18:40 INFO Executor: Sending result for 61 directly to driver
14/05/12 21:18:40 INFO Executor: Finished task ID 61
14/05/12 21:18:40 INFO TaskSetManager: Starting task 46.0:1 as TID 62 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:40 INFO TaskSetManager: Serialized task 46.0:1 as 1519 bytes in 0 ms
14/05/12 21:18:40 INFO Executor: Running task ID 62
14/05/12 21:18:40 INFO TaskSetManager: Finished TID 61 in 15 ms on localhost (progress: 0/2)
14/05/12 21:18:40 INFO DAGScheduler: Completed ShuffleMapTask(46, 0)
14/05/12 21:18:40 INFO BlockManager: Found block input-0-1399909718000 locally
14/05/12 21:18:40 INFO Executor: Serialized size of result for 62 is 751
14/05/12 21:18:40 INFO Executor: Sending result for 62 directly to driver
14/05/12 21:18:40 INFO Executor: Finished task ID 62
14/05/12 21:18:40 INFO TaskSetManager: Finished TID 62 in 12 ms on localhost (progress: 1/2)
14/05/12 21:18:40 INFO TaskSchedulerImpl: Remove TaskSet 46.0 from pool 
14/05/12 21:18:40 INFO DAGScheduler: Completed ShuffleMapTask(46, 1)
14/05/12 21:18:40 INFO DAGScheduler: Stage 46 (combineByKey at ShuffledDStream.scala:42) finished in 0.029 s
14/05/12 21:18:40 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:18:40 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:18:40 INFO DAGScheduler: waiting: Set(Stage 45)
14/05/12 21:18:40 INFO DAGScheduler: failed: Set()
14/05/12 21:18:40 INFO DAGScheduler: Missing parents for Stage 45: List()
14/05/12 21:18:40 INFO DAGScheduler: Submitting Stage 45 (MapPartitionsRDD[72] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:18:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 45 (MapPartitionsRDD[72] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:40 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
14/05/12 21:18:40 INFO TaskSetManager: Starting task 45.0:0 as TID 63 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:40 INFO TaskSetManager: Serialized task 45.0:0 as 1564 bytes in 0 ms
14/05/12 21:18:40 INFO Executor: Running task ID 63
14/05/12 21:18:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 2 blocks
14/05/12 21:18:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:18:40 INFO Executor: Serialized size of result for 63 is 813
14/05/12 21:18:40 INFO Executor: Sending result for 63 directly to driver
14/05/12 21:18:40 INFO Executor: Finished task ID 63
14/05/12 21:18:40 INFO TaskSetManager: Finished TID 63 in 11 ms on localhost (progress: 0/1)
14/05/12 21:18:40 INFO TaskSchedulerImpl: Remove TaskSet 45.0 from pool 
14/05/12 21:18:40 INFO DAGScheduler: Completed ResultTask(45, 0)
14/05/12 21:18:40 INFO DAGScheduler: Stage 45 (take at DStream.scala:586) finished in 0.013 s
14/05/12 21:18:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.06875595 s
14/05/12 21:18:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 148 bytes
14/05/12 21:18:40 INFO DAGScheduler: Got job 24 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:40 INFO DAGScheduler: Final stage: Stage 47 (take at DStream.scala:586)
14/05/12 21:18:40 INFO DAGScheduler: Parents of final stage: List(Stage 48)
14/05/12 21:18:40 INFO DAGScheduler: Missing parents: List()
14/05/12 21:18:40 INFO DAGScheduler: Submitting Stage 47 (MapPartitionsRDD[72] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 47 (MapPartitionsRDD[72] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:40 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
14/05/12 21:18:40 INFO TaskSetManager: Starting task 47.0:0 as TID 64 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:40 INFO TaskSetManager: Serialized task 47.0:0 as 1564 bytes in 0 ms
14/05/12 21:18:40 INFO Executor: Running task ID 64
14/05/12 21:18:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 2 non-zero-bytes blocks out of 2 blocks
14/05/12 21:18:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:18:40 INFO Executor: Serialized size of result for 64 is 961
14/05/12 21:18:40 INFO Executor: Sending result for 64 directly to driver
14/05/12 21:18:40 INFO Executor: Finished task ID 64
14/05/12 21:18:40 INFO TaskSetManager: Finished TID 64 in 15 ms on localhost (progress: 0/1)
14/05/12 21:18:40 INFO DAGScheduler: Completed ResultTask(47, 1)
14/05/12 21:18:40 INFO TaskSchedulerImpl: Remove TaskSet 47.0 from pool 
14/05/12 21:18:40 INFO DAGScheduler: Stage 47 (take at DStream.scala:586) finished in 0.018 s
14/05/12 21:18:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.032876193 s
14/05/12 21:18:40 INFO JobScheduler: Finished job streaming job 1399909720000 ms.0 from job set of time 1399909720000 ms
14/05/12 21:18:40 INFO JobScheduler: Total delay: 0.126 s for time 1399909720000 ms (execution: 0.110 s)
14/05/12 21:18:48 INFO MemoryStore: ensureFreeSpace(12) called with curMem=379, maxMem=671298355
14/05/12 21:18:48 INFO MemoryStore: Block input-0-1399909728400 stored as bytes to memory (size 12.0 B, free 640.2 MB)
14/05/12 21:18:48 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909728400 in memory on ubuntu-3.local:46407 (size: 12.0 B, free: 640.2 MB)
14/05/12 21:18:48 INFO BlockManagerMaster: Updated info of block input-0-1399909728400
14/05/12 21:18:48 WARN BlockManager: Block input-0-1399909728400 already exists on this machine; not re-adding it
14/05/12 21:18:50 INFO NetworkInputTracker: Stream 0 received 2 blocks
14/05/12 21:18:50 INFO JobScheduler: Added jobs for time 1399909730000 ms
14/05/12 21:18:50 INFO JobScheduler: Starting job streaming job 1399909730000 ms.0 from job set of time 1399909730000 ms
14/05/12 21:18:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:50 INFO DAGScheduler: Registering RDD 76 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:50 INFO DAGScheduler: Got job 25 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:50 INFO DAGScheduler: Final stage: Stage 49 (take at DStream.scala:586)
14/05/12 21:18:50 INFO DAGScheduler: Parents of final stage: List(Stage 50)
14/05/12 21:18:50 INFO DAGScheduler: Missing parents: List(Stage 50)
14/05/12 21:18:50 INFO DAGScheduler: Submitting Stage 50 (MapPartitionsRDD[76] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:50 INFO DAGScheduler: Submitting 2 missing tasks from Stage 50 (MapPartitionsRDD[76] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:50 INFO TaskSchedulerImpl: Adding task set 50.0 with 2 tasks
14/05/12 21:18:50 INFO TaskSetManager: Starting task 50.0:0 as TID 65 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:50 INFO TaskSetManager: Serialized task 50.0:0 as 1517 bytes in 1 ms
14/05/12 21:18:50 INFO Executor: Running task ID 65
14/05/12 21:18:50 INFO BlockManager: Found block input-0-1399909718400 locally
14/05/12 21:18:50 INFO Executor: Serialized size of result for 65 is 751
14/05/12 21:18:50 INFO Executor: Sending result for 65 directly to driver
14/05/12 21:18:50 INFO Executor: Finished task ID 65
14/05/12 21:18:50 INFO TaskSetManager: Starting task 50.0:1 as TID 66 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:50 INFO TaskSetManager: Serialized task 50.0:1 as 1517 bytes in 0 ms
14/05/12 21:18:50 INFO Executor: Running task ID 66
14/05/12 21:18:50 INFO TaskSetManager: Finished TID 65 in 14 ms on localhost (progress: 0/2)
14/05/12 21:18:50 INFO DAGScheduler: Completed ShuffleMapTask(50, 0)
14/05/12 21:18:50 INFO BlockManager: Found block input-0-1399909728400 locally
14/05/12 21:18:50 INFO Executor: Serialized size of result for 66 is 751
14/05/12 21:18:50 INFO Executor: Sending result for 66 directly to driver
14/05/12 21:18:50 INFO Executor: Finished task ID 66
14/05/12 21:18:50 INFO TaskSetManager: Finished TID 66 in 11 ms on localhost (progress: 1/2)
14/05/12 21:18:50 INFO TaskSchedulerImpl: Remove TaskSet 50.0 from pool 
14/05/12 21:18:50 INFO DAGScheduler: Completed ShuffleMapTask(50, 1)
14/05/12 21:18:50 INFO DAGScheduler: Stage 50 (combineByKey at ShuffledDStream.scala:42) finished in 0.025 s
14/05/12 21:18:50 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:18:50 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:18:50 INFO DAGScheduler: waiting: Set(Stage 49)
14/05/12 21:18:50 INFO DAGScheduler: failed: Set()
14/05/12 21:18:50 INFO DAGScheduler: Missing parents for Stage 49: List()
14/05/12 21:18:50 INFO DAGScheduler: Submitting Stage 49 (MapPartitionsRDD[78] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:18:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 49 (MapPartitionsRDD[78] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:50 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
14/05/12 21:18:50 INFO TaskSetManager: Starting task 49.0:0 as TID 67 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:50 INFO TaskSetManager: Serialized task 49.0:0 as 1562 bytes in 1 ms
14/05/12 21:18:50 INFO Executor: Running task ID 67
14/05/12 21:18:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 2 blocks
14/05/12 21:18:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:18:50 INFO Executor: Serialized size of result for 67 is 813
14/05/12 21:18:50 INFO Executor: Sending result for 67 directly to driver
14/05/12 21:18:50 INFO Executor: Finished task ID 67
14/05/12 21:18:50 INFO TaskSetManager: Finished TID 67 in 12 ms on localhost (progress: 0/1)
14/05/12 21:18:50 INFO TaskSchedulerImpl: Remove TaskSet 49.0 from pool 
14/05/12 21:18:50 INFO DAGScheduler: Completed ResultTask(49, 0)
14/05/12 21:18:50 INFO DAGScheduler: Stage 49 (take at DStream.scala:586) finished in 0.014 s
14/05/12 21:18:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.063452314 s
14/05/12 21:18:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:18:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 148 bytes
14/05/12 21:18:50 INFO DAGScheduler: Got job 26 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:18:50 INFO DAGScheduler: Final stage: Stage 51 (take at DStream.scala:586)
14/05/12 21:18:50 INFO DAGScheduler: Parents of final stage: List(Stage 52)
14/05/12 21:18:50 INFO DAGScheduler: Missing parents: List()
14/05/12 21:18:50 INFO DAGScheduler: Submitting Stage 51 (MapPartitionsRDD[78] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:18:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 51 (MapPartitionsRDD[78] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:18:50 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
14/05/12 21:18:50 INFO TaskSetManager: Starting task 51.0:0 as TID 68 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:18:50 INFO TaskSetManager: Serialized task 51.0:0 as 1562 bytes in 0 ms
14/05/12 21:18:50 INFO Executor: Running task ID 68
14/05/12 21:18:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 2 non-zero-bytes blocks out of 2 blocks
14/05/12 21:18:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:18:50 INFO Executor: Serialized size of result for 68 is 985
14/05/12 21:18:50 INFO Executor: Sending result for 68 directly to driver
14/05/12 21:18:50 INFO Executor: Finished task ID 68
14/05/12 21:18:50 INFO TaskSetManager: Finished TID 68 in 19 ms on localhost (progress: 0/1)
14/05/12 21:18:50 INFO DAGScheduler: Completed ResultTask(51, 1)
14/05/12 21:18:50 INFO TaskSchedulerImpl: Remove TaskSet 51.0 from pool 
14/05/12 21:18:50 INFO DAGScheduler: Stage 51 (take at DStream.scala:586) finished in 0.022 s
14/05/12 21:18:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.037262101 s
14/05/12 21:18:50 INFO JobScheduler: Finished job streaming job 1399909730000 ms.0 from job set of time 1399909730000 ms
14/05/12 21:18:50 INFO JobScheduler: Total delay: 0.125 s for time 1399909730000 ms (execution: 0.108 s)
14/05/12 21:18:51 INFO MemoryStore: ensureFreeSpace(15) called with curMem=391, maxMem=671298355
14/05/12 21:18:51 INFO MemoryStore: Block input-0-1399909730800 stored as bytes to memory (size 15.0 B, free 640.2 MB)
14/05/12 21:18:51 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909730800 in memory on ubuntu-3.local:46407 (size: 15.0 B, free: 640.2 MB)
14/05/12 21:18:51 INFO BlockManagerMaster: Updated info of block input-0-1399909730800
14/05/12 21:18:51 WARN BlockManager: Block input-0-1399909730800 already exists on this machine; not re-adding it
14/05/12 21:19:00 INFO NetworkInputTracker: Stream 0 received 1 blocks
14/05/12 21:19:00 INFO JobScheduler: Added jobs for time 1399909740000 ms
14/05/12 21:19:00 INFO JobScheduler: Starting job streaming job 1399909740000 ms.0 from job set of time 1399909740000 ms
14/05/12 21:19:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:00 INFO DAGScheduler: Registering RDD 82 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:00 INFO DAGScheduler: Got job 27 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:00 INFO DAGScheduler: Final stage: Stage 53 (take at DStream.scala:586)
14/05/12 21:19:00 INFO DAGScheduler: Parents of final stage: List(Stage 54)
14/05/12 21:19:00 INFO DAGScheduler: Missing parents: List(Stage 54)
14/05/12 21:19:00 INFO DAGScheduler: Submitting Stage 54 (MapPartitionsRDD[82] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 54 (MapPartitionsRDD[82] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:00 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
14/05/12 21:19:00 INFO TaskSetManager: Starting task 54.0:0 as TID 69 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:00 INFO TaskSetManager: Serialized task 54.0:0 as 1518 bytes in 0 ms
14/05/12 21:19:00 INFO Executor: Running task ID 69
14/05/12 21:19:00 INFO BlockManager: Found block input-0-1399909730800 locally
14/05/12 21:19:00 INFO Executor: Serialized size of result for 69 is 751
14/05/12 21:19:00 INFO Executor: Sending result for 69 directly to driver
14/05/12 21:19:00 INFO Executor: Finished task ID 69
14/05/12 21:19:00 INFO TaskSetManager: Finished TID 69 in 16 ms on localhost (progress: 0/1)
14/05/12 21:19:00 INFO TaskSchedulerImpl: Remove TaskSet 54.0 from pool 
14/05/12 21:19:00 INFO DAGScheduler: Completed ShuffleMapTask(54, 0)
14/05/12 21:19:00 INFO DAGScheduler: Stage 54 (combineByKey at ShuffledDStream.scala:42) finished in 0.017 s
14/05/12 21:19:00 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:19:00 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:19:00 INFO DAGScheduler: waiting: Set(Stage 53)
14/05/12 21:19:00 INFO DAGScheduler: failed: Set()
14/05/12 21:19:00 INFO DAGScheduler: Missing parents for Stage 53: List()
14/05/12 21:19:00 INFO DAGScheduler: Submitting Stage 53 (MapPartitionsRDD[84] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:19:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 53 (MapPartitionsRDD[84] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:00 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
14/05/12 21:19:00 INFO TaskSetManager: Starting task 53.0:0 as TID 70 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:00 INFO TaskSetManager: Serialized task 53.0:0 as 1564 bytes in 1 ms
14/05/12 21:19:00 INFO Executor: Running task ID 70
14/05/12 21:19:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 1 blocks
14/05/12 21:19:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:19:00 INFO Executor: Serialized size of result for 70 is 813
14/05/12 21:19:00 INFO Executor: Sending result for 70 directly to driver
14/05/12 21:19:00 INFO Executor: Finished task ID 70
14/05/12 21:19:00 INFO TaskSetManager: Finished TID 70 in 11 ms on localhost (progress: 0/1)
14/05/12 21:19:00 INFO TaskSchedulerImpl: Remove TaskSet 53.0 from pool 
14/05/12 21:19:00 INFO DAGScheduler: Completed ResultTask(53, 0)
14/05/12 21:19:00 INFO DAGScheduler: Stage 53 (take at DStream.scala:586) finished in 0.012 s
14/05/12 21:19:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.051850564 s
14/05/12 21:19:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 140 bytes
14/05/12 21:19:00 INFO DAGScheduler: Got job 28 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:00 INFO DAGScheduler: Final stage: Stage 55 (take at DStream.scala:586)
14/05/12 21:19:00 INFO DAGScheduler: Parents of final stage: List(Stage 56)
14/05/12 21:19:00 INFO DAGScheduler: Missing parents: List()
14/05/12 21:19:00 INFO DAGScheduler: Submitting Stage 55 (MapPartitionsRDD[84] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 55 (MapPartitionsRDD[84] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:00 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
14/05/12 21:19:00 INFO TaskSetManager: Starting task 55.0:0 as TID 71 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:00 INFO TaskSetManager: Serialized task 55.0:0 as 1564 bytes in 1 ms
14/05/12 21:19:00 INFO Executor: Running task ID 71
14/05/12 21:19:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 1 blocks
14/05/12 21:19:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:19:00 INFO Executor: Serialized size of result for 71 is 966
14/05/12 21:19:00 INFO Executor: Sending result for 71 directly to driver
14/05/12 21:19:00 INFO Executor: Finished task ID 71
14/05/12 21:19:00 INFO TaskSetManager: Finished TID 71 in 12 ms on localhost (progress: 0/1)
14/05/12 21:19:00 INFO TaskSchedulerImpl: Remove TaskSet 55.0 from pool 
14/05/12 21:19:00 INFO DAGScheduler: Completed ResultTask(55, 1)
14/05/12 21:19:00 INFO DAGScheduler: Stage 55 (take at DStream.scala:586) finished in 0.014 s
14/05/12 21:19:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.02161808 s
14/05/12 21:19:00 INFO JobScheduler: Finished job streaming job 1399909740000 ms.0 from job set of time 1399909740000 ms
14/05/12 21:19:00 INFO JobScheduler: Total delay: 0.097 s for time 1399909740000 ms (execution: 0.080 s)
14/05/12 21:19:10 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/12 21:19:10 INFO JobScheduler: Added jobs for time 1399909750000 ms
14/05/12 21:19:10 INFO JobScheduler: Starting job streaming job 1399909750000 ms.0 from job set of time 1399909750000 ms
14/05/12 21:19:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:10 INFO DAGScheduler: Registering RDD 88 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:10 INFO DAGScheduler: Got job 29 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:10 INFO DAGScheduler: Final stage: Stage 57 (take at DStream.scala:586)
14/05/12 21:19:10 INFO DAGScheduler: Parents of final stage: List(Stage 58)
14/05/12 21:19:10 INFO DAGScheduler: Missing parents: List()
14/05/12 21:19:10 INFO DAGScheduler: Submitting Stage 57 (MapPartitionsRDD[90] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 57 (MapPartitionsRDD[90] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:10 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
14/05/12 21:19:10 INFO TaskSetManager: Starting task 57.0:0 as TID 72 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:10 INFO TaskSetManager: Serialized task 57.0:0 as 1565 bytes in 1 ms
14/05/12 21:19:10 INFO Executor: Running task ID 72
14/05/12 21:19:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:19:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:19:10 INFO Executor: Serialized size of result for 72 is 813
14/05/12 21:19:10 INFO Executor: Sending result for 72 directly to driver
14/05/12 21:19:10 INFO Executor: Finished task ID 72
14/05/12 21:19:10 INFO TaskSetManager: Finished TID 72 in 15 ms on localhost (progress: 0/1)
14/05/12 21:19:10 INFO TaskSchedulerImpl: Remove TaskSet 57.0 from pool 
14/05/12 21:19:10 INFO DAGScheduler: Completed ResultTask(57, 0)
14/05/12 21:19:10 INFO DAGScheduler: Stage 57 (take at DStream.scala:586) finished in 0.018 s
14/05/12 21:19:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.03001975 s
14/05/12 21:19:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 82 bytes
14/05/12 21:19:10 INFO DAGScheduler: Got job 30 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:10 INFO DAGScheduler: Final stage: Stage 59 (take at DStream.scala:586)
14/05/12 21:19:10 INFO DAGScheduler: Parents of final stage: List(Stage 60)
14/05/12 21:19:10 INFO DAGScheduler: Missing parents: List()
14/05/12 21:19:10 INFO DAGScheduler: Submitting Stage 59 (MapPartitionsRDD[90] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 59 (MapPartitionsRDD[90] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:10 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
14/05/12 21:19:10 INFO TaskSetManager: Starting task 59.0:0 as TID 73 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:10 INFO TaskSetManager: Serialized task 59.0:0 as 1565 bytes in 0 ms
14/05/12 21:19:10 INFO Executor: Running task ID 73
14/05/12 21:19:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:19:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:19:10 INFO Executor: Serialized size of result for 73 is 813
14/05/12 21:19:10 INFO Executor: Sending result for 73 directly to driver
14/05/12 21:19:10 INFO Executor: Finished task ID 73
14/05/12 21:19:10 INFO TaskSetManager: Finished TID 73 in 15 ms on localhost (progress: 0/1)
14/05/12 21:19:10 INFO DAGScheduler: Completed ResultTask(59, 1)
14/05/12 21:19:10 INFO TaskSchedulerImpl: Remove TaskSet 59.0 from pool 
14/05/12 21:19:10 INFO DAGScheduler: Stage 59 (take at DStream.scala:586) finished in 0.017 s
14/05/12 21:19:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.030260309 s
14/05/12 21:19:10 INFO JobScheduler: Finished job streaming job 1399909750000 ms.0 from job set of time 1399909750000 ms
14/05/12 21:19:10 INFO JobScheduler: Total delay: 0.086 s for time 1399909750000 ms (execution: 0.068 s)
14/05/12 21:19:20 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/12 21:19:20 INFO JobScheduler: Added jobs for time 1399909760000 ms
14/05/12 21:19:20 INFO JobScheduler: Starting job streaming job 1399909760000 ms.0 from job set of time 1399909760000 ms
14/05/12 21:19:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:20 INFO DAGScheduler: Registering RDD 94 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:20 INFO DAGScheduler: Got job 31 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:20 INFO DAGScheduler: Final stage: Stage 61 (take at DStream.scala:586)
14/05/12 21:19:20 INFO DAGScheduler: Parents of final stage: List(Stage 62)
14/05/12 21:19:20 INFO DAGScheduler: Missing parents: List()
14/05/12 21:19:20 INFO DAGScheduler: Submitting Stage 61 (MapPartitionsRDD[96] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 61 (MapPartitionsRDD[96] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:20 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
14/05/12 21:19:20 INFO TaskSetManager: Starting task 61.0:0 as TID 74 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:20 INFO TaskSetManager: Serialized task 61.0:0 as 1565 bytes in 0 ms
14/05/12 21:19:20 INFO Executor: Running task ID 74
14/05/12 21:19:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:19:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:19:20 INFO Executor: Serialized size of result for 74 is 813
14/05/12 21:19:20 INFO Executor: Sending result for 74 directly to driver
14/05/12 21:19:20 INFO Executor: Finished task ID 74
14/05/12 21:19:20 INFO TaskSetManager: Finished TID 74 in 9 ms on localhost (progress: 0/1)
14/05/12 21:19:20 INFO DAGScheduler: Completed ResultTask(61, 0)
14/05/12 21:19:20 INFO TaskSchedulerImpl: Remove TaskSet 61.0 from pool 
14/05/12 21:19:20 INFO DAGScheduler: Stage 61 (take at DStream.scala:586) finished in 0.011 s
14/05/12 21:19:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.025262977 s
14/05/12 21:19:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 82 bytes
14/05/12 21:19:20 INFO DAGScheduler: Got job 32 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:20 INFO DAGScheduler: Final stage: Stage 63 (take at DStream.scala:586)
14/05/12 21:19:20 INFO DAGScheduler: Parents of final stage: List(Stage 64)
14/05/12 21:19:20 INFO DAGScheduler: Missing parents: List()
14/05/12 21:19:20 INFO DAGScheduler: Submitting Stage 63 (MapPartitionsRDD[96] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 63 (MapPartitionsRDD[96] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:20 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
14/05/12 21:19:20 INFO TaskSetManager: Starting task 63.0:0 as TID 75 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:20 INFO TaskSetManager: Serialized task 63.0:0 as 1565 bytes in 0 ms
14/05/12 21:19:20 INFO Executor: Running task ID 75
14/05/12 21:19:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/12 21:19:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:19:20 INFO Executor: Serialized size of result for 75 is 813
14/05/12 21:19:20 INFO Executor: Sending result for 75 directly to driver
14/05/12 21:19:20 INFO Executor: Finished task ID 75
14/05/12 21:19:20 INFO TaskSetManager: Finished TID 75 in 15 ms on localhost (progress: 0/1)
14/05/12 21:19:20 INFO DAGScheduler: Completed ResultTask(63, 1)
14/05/12 21:19:20 INFO TaskSchedulerImpl: Remove TaskSet 63.0 from pool 
14/05/12 21:19:20 INFO DAGScheduler: Stage 63 (take at DStream.scala:586) finished in 0.017 s
14/05/12 21:19:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.027111965 s
14/05/12 21:19:20 INFO JobScheduler: Finished job streaming job 1399909760000 ms.0 from job set of time 1399909760000 ms
14/05/12 21:19:20 INFO JobScheduler: Total delay: 0.074 s for time 1399909760000 ms (execution: 0.060 s)
14/05/12 21:19:24 INFO MemoryStore: ensureFreeSpace(8) called with curMem=406, maxMem=671298355
14/05/12 21:19:24 INFO MemoryStore: Block input-0-1399909764600 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:24 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909764600 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:24 INFO BlockManagerMaster: Updated info of block input-0-1399909764600
14/05/12 21:19:24 WARN BlockManager: Block input-0-1399909764600 already exists on this machine; not re-adding it
14/05/12 21:19:28 INFO MemoryStore: ensureFreeSpace(8) called with curMem=414, maxMem=671298355
14/05/12 21:19:28 INFO MemoryStore: Block input-0-1399909764800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909764800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMaster: Updated info of block input-0-1399909764800
14/05/12 21:19:28 WARN BlockManager: Block input-0-1399909764800 already exists on this machine; not re-adding it
14/05/12 21:19:28 INFO MemoryStore: ensureFreeSpace(8) called with curMem=422, maxMem=671298355
14/05/12 21:19:28 INFO MemoryStore: Block input-0-1399909765200 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909765200 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMaster: Updated info of block input-0-1399909765200
14/05/12 21:19:28 WARN BlockManager: Block input-0-1399909765200 already exists on this machine; not re-adding it
14/05/12 21:19:28 INFO MemoryStore: ensureFreeSpace(8) called with curMem=430, maxMem=671298355
14/05/12 21:19:28 INFO MemoryStore: Block input-0-1399909765800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909765800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMaster: Updated info of block input-0-1399909765800
14/05/12 21:19:28 WARN BlockManager: Block input-0-1399909765800 already exists on this machine; not re-adding it
14/05/12 21:19:28 INFO MemoryStore: ensureFreeSpace(8) called with curMem=438, maxMem=671298355
14/05/12 21:19:28 INFO MemoryStore: Block input-0-1399909767200 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909767200 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMaster: Updated info of block input-0-1399909767200
14/05/12 21:19:28 WARN BlockManager: Block input-0-1399909767200 already exists on this machine; not re-adding it
14/05/12 21:19:28 INFO MemoryStore: ensureFreeSpace(8) called with curMem=446, maxMem=671298355
14/05/12 21:19:28 INFO MemoryStore: Block input-0-1399909767600 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909767600 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMaster: Updated info of block input-0-1399909767600
14/05/12 21:19:28 WARN BlockManager: Block input-0-1399909767600 already exists on this machine; not re-adding it
14/05/12 21:19:28 INFO MemoryStore: ensureFreeSpace(8) called with curMem=454, maxMem=671298355
14/05/12 21:19:28 INFO MemoryStore: Block input-0-1399909768000 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909768000 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:28 INFO BlockManagerMaster: Updated info of block input-0-1399909768000
14/05/12 21:19:28 WARN BlockManager: Block input-0-1399909768000 already exists on this machine; not re-adding it
14/05/12 21:19:30 INFO NetworkInputTracker: Stream 0 received 7 blocks
14/05/12 21:19:30 INFO JobScheduler: Added jobs for time 1399909770000 ms
14/05/12 21:19:30 INFO JobScheduler: Starting job streaming job 1399909770000 ms.0 from job set of time 1399909770000 ms
14/05/12 21:19:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:30 INFO DAGScheduler: Registering RDD 100 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:30 INFO DAGScheduler: Got job 33 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:30 INFO DAGScheduler: Final stage: Stage 65 (take at DStream.scala:586)
14/05/12 21:19:30 INFO DAGScheduler: Parents of final stage: List(Stage 66)
14/05/12 21:19:30 INFO DAGScheduler: Missing parents: List(Stage 66)
14/05/12 21:19:30 INFO DAGScheduler: Submitting Stage 66 (MapPartitionsRDD[100] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:30 INFO DAGScheduler: Submitting 7 missing tasks from Stage 66 (MapPartitionsRDD[100] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:30 INFO TaskSchedulerImpl: Adding task set 66.0 with 7 tasks
14/05/12 21:19:30 INFO TaskSetManager: Starting task 66.0:0 as TID 76 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:30 INFO TaskSetManager: Serialized task 66.0:0 as 1517 bytes in 0 ms
14/05/12 21:19:30 INFO Executor: Running task ID 76
14/05/12 21:19:30 INFO BlockManager: Found block input-0-1399909764600 locally
14/05/12 21:19:30 INFO Executor: Serialized size of result for 76 is 751
14/05/12 21:19:30 INFO Executor: Sending result for 76 directly to driver
14/05/12 21:19:30 INFO Executor: Finished task ID 76
14/05/12 21:19:30 INFO TaskSetManager: Starting task 66.0:1 as TID 77 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:30 INFO TaskSetManager: Serialized task 66.0:1 as 1517 bytes in 0 ms
14/05/12 21:19:30 INFO Executor: Running task ID 77
14/05/12 21:19:30 INFO TaskSetManager: Finished TID 76 in 18 ms on localhost (progress: 0/7)
14/05/12 21:19:30 INFO DAGScheduler: Completed ShuffleMapTask(66, 0)
14/05/12 21:19:30 INFO BlockManager: Found block input-0-1399909764800 locally
14/05/12 21:19:30 INFO Executor: Serialized size of result for 77 is 751
14/05/12 21:19:30 INFO Executor: Sending result for 77 directly to driver
14/05/12 21:19:30 INFO Executor: Finished task ID 77
14/05/12 21:19:30 INFO TaskSetManager: Starting task 66.0:2 as TID 78 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:30 INFO TaskSetManager: Serialized task 66.0:2 as 1517 bytes in 0 ms
14/05/12 21:19:30 INFO Executor: Running task ID 78
14/05/12 21:19:30 INFO TaskSetManager: Finished TID 77 in 16 ms on localhost (progress: 1/7)
14/05/12 21:19:30 INFO DAGScheduler: Completed ShuffleMapTask(66, 1)
14/05/12 21:19:30 INFO BlockManager: Found block input-0-1399909765200 locally
14/05/12 21:19:30 INFO Executor: Serialized size of result for 78 is 751
14/05/12 21:19:30 INFO Executor: Sending result for 78 directly to driver
14/05/12 21:19:30 INFO Executor: Finished task ID 78
14/05/12 21:19:30 INFO TaskSetManager: Starting task 66.0:3 as TID 79 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:30 INFO TaskSetManager: Serialized task 66.0:3 as 1517 bytes in 0 ms
14/05/12 21:19:30 INFO Executor: Running task ID 79
14/05/12 21:19:30 INFO TaskSetManager: Finished TID 78 in 14 ms on localhost (progress: 2/7)
14/05/12 21:19:30 INFO DAGScheduler: Completed ShuffleMapTask(66, 2)
14/05/12 21:19:30 INFO BlockManager: Found block input-0-1399909765800 locally
14/05/12 21:19:30 INFO Executor: Serialized size of result for 79 is 751
14/05/12 21:19:30 INFO Executor: Sending result for 79 directly to driver
14/05/12 21:19:30 INFO Executor: Finished task ID 79
14/05/12 21:19:30 INFO TaskSetManager: Starting task 66.0:4 as TID 80 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:30 INFO TaskSetManager: Serialized task 66.0:4 as 1517 bytes in 0 ms
14/05/12 21:19:30 INFO Executor: Running task ID 80
14/05/12 21:19:30 INFO TaskSetManager: Finished TID 79 in 16 ms on localhost (progress: 3/7)
14/05/12 21:19:30 INFO DAGScheduler: Completed ShuffleMapTask(66, 3)
14/05/12 21:19:30 INFO BlockManager: Found block input-0-1399909767200 locally
14/05/12 21:19:30 INFO Executor: Serialized size of result for 80 is 751
14/05/12 21:19:30 INFO Executor: Sending result for 80 directly to driver
14/05/12 21:19:30 INFO Executor: Finished task ID 80
14/05/12 21:19:30 INFO TaskSetManager: Starting task 66.0:5 as TID 81 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:30 INFO TaskSetManager: Serialized task 66.0:5 as 1517 bytes in 0 ms
14/05/12 21:19:30 INFO Executor: Running task ID 81
14/05/12 21:19:30 INFO TaskSetManager: Finished TID 80 in 12 ms on localhost (progress: 4/7)
14/05/12 21:19:30 INFO DAGScheduler: Completed ShuffleMapTask(66, 4)
14/05/12 21:19:30 INFO BlockManager: Found block input-0-1399909767600 locally
14/05/12 21:19:30 INFO Executor: Serialized size of result for 81 is 751
14/05/12 21:19:30 INFO Executor: Sending result for 81 directly to driver
14/05/12 21:19:30 INFO Executor: Finished task ID 81
14/05/12 21:19:30 INFO TaskSetManager: Starting task 66.0:6 as TID 82 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:30 INFO TaskSetManager: Serialized task 66.0:6 as 1517 bytes in 0 ms
14/05/12 21:19:30 INFO TaskSetManager: Finished TID 81 in 15 ms on localhost (progress: 5/7)
14/05/12 21:19:30 INFO Executor: Running task ID 82
14/05/12 21:19:30 INFO DAGScheduler: Completed ShuffleMapTask(66, 5)
14/05/12 21:19:30 INFO BlockManager: Found block input-0-1399909768000 locally
14/05/12 21:19:30 INFO Executor: Serialized size of result for 82 is 751
14/05/12 21:19:30 INFO Executor: Sending result for 82 directly to driver
14/05/12 21:19:30 INFO Executor: Finished task ID 82
14/05/12 21:19:30 INFO TaskSetManager: Finished TID 82 in 13 ms on localhost (progress: 6/7)
14/05/12 21:19:30 INFO TaskSchedulerImpl: Remove TaskSet 66.0 from pool 
14/05/12 21:19:30 INFO DAGScheduler: Completed ShuffleMapTask(66, 6)
14/05/12 21:19:30 INFO DAGScheduler: Stage 66 (combineByKey at ShuffledDStream.scala:42) finished in 0.095 s
14/05/12 21:19:30 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:19:30 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:19:30 INFO DAGScheduler: waiting: Set(Stage 65)
14/05/12 21:19:30 INFO DAGScheduler: failed: Set()
14/05/12 21:19:30 INFO DAGScheduler: Missing parents for Stage 65: List()
14/05/12 21:19:30 INFO DAGScheduler: Submitting Stage 65 (MapPartitionsRDD[102] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:19:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 65 (MapPartitionsRDD[102] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:30 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
14/05/12 21:19:30 INFO TaskSetManager: Starting task 65.0:0 as TID 83 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:30 INFO TaskSetManager: Serialized task 65.0:0 as 1563 bytes in 1 ms
14/05/12 21:19:30 INFO Executor: Running task ID 83
14/05/12 21:19:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 3 non-zero-bytes blocks out of 7 blocks
14/05/12 21:19:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:19:30 INFO Executor: Serialized size of result for 83 is 959
14/05/12 21:19:30 INFO Executor: Sending result for 83 directly to driver
14/05/12 21:19:30 INFO Executor: Finished task ID 83
14/05/12 21:19:30 INFO TaskSetManager: Finished TID 83 in 15 ms on localhost (progress: 0/1)
14/05/12 21:19:30 INFO TaskSchedulerImpl: Remove TaskSet 65.0 from pool 
14/05/12 21:19:30 INFO DAGScheduler: Completed ResultTask(65, 0)
14/05/12 21:19:30 INFO DAGScheduler: Stage 65 (take at DStream.scala:586) finished in 0.017 s
14/05/12 21:19:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.143297263 s
14/05/12 21:19:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 153 bytes
14/05/12 21:19:30 INFO DAGScheduler: Got job 34 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:30 INFO DAGScheduler: Final stage: Stage 67 (take at DStream.scala:586)
14/05/12 21:19:30 INFO DAGScheduler: Parents of final stage: List(Stage 68)
14/05/12 21:19:30 INFO DAGScheduler: Missing parents: List()
14/05/12 21:19:30 INFO DAGScheduler: Submitting Stage 67 (MapPartitionsRDD[102] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 67 (MapPartitionsRDD[102] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:30 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
14/05/12 21:19:30 INFO TaskSetManager: Starting task 67.0:0 as TID 84 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:30 INFO TaskSetManager: Serialized task 67.0:0 as 1563 bytes in 1 ms
14/05/12 21:19:30 INFO Executor: Running task ID 84
14/05/12 21:19:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 4 non-zero-bytes blocks out of 7 blocks
14/05/12 21:19:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:19:30 INFO Executor: Serialized size of result for 84 is 959
14/05/12 21:19:30 INFO Executor: Sending result for 84 directly to driver
14/05/12 21:19:30 INFO Executor: Finished task ID 84
14/05/12 21:19:30 INFO TaskSetManager: Finished TID 84 in 12 ms on localhost (progress: 0/1)
14/05/12 21:19:30 INFO TaskSchedulerImpl: Remove TaskSet 67.0 from pool 
14/05/12 21:19:30 INFO DAGScheduler: Completed ResultTask(67, 1)
14/05/12 21:19:30 INFO DAGScheduler: Stage 67 (take at DStream.scala:586) finished in 0.015 s
14/05/12 21:19:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.023053319 s
14/05/12 21:19:30 INFO JobScheduler: Finished job streaming job 1399909770000 ms.0 from job set of time 1399909770000 ms
14/05/12 21:19:30 INFO JobScheduler: Total delay: 0.191 s for time 1399909770000 ms (execution: 0.173 s)
14/05/12 21:19:33 INFO MemoryStore: ensureFreeSpace(8) called with curMem=462, maxMem=671298355
14/05/12 21:19:33 INFO MemoryStore: Block input-0-1399909772800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:33 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909772800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:33 INFO BlockManagerMaster: Updated info of block input-0-1399909772800
14/05/12 21:19:33 WARN BlockManager: Block input-0-1399909772800 already exists on this machine; not re-adding it
14/05/12 21:19:33 INFO MemoryStore: ensureFreeSpace(8) called with curMem=470, maxMem=671298355
14/05/12 21:19:33 INFO MemoryStore: Block input-0-1399909773400 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:33 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909773400 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:33 INFO BlockManagerMaster: Updated info of block input-0-1399909773400
14/05/12 21:19:33 WARN BlockManager: Block input-0-1399909773400 already exists on this machine; not re-adding it
14/05/12 21:19:40 INFO NetworkInputTracker: Stream 0 received 2 blocks
14/05/12 21:19:40 INFO JobScheduler: Added jobs for time 1399909780000 ms
14/05/12 21:19:40 INFO JobScheduler: Starting job streaming job 1399909780000 ms.0 from job set of time 1399909780000 ms
14/05/12 21:19:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:40 INFO DAGScheduler: Registering RDD 106 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:40 INFO DAGScheduler: Got job 35 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:40 INFO DAGScheduler: Final stage: Stage 69 (take at DStream.scala:586)
14/05/12 21:19:40 INFO DAGScheduler: Parents of final stage: List(Stage 70)
14/05/12 21:19:40 INFO DAGScheduler: Missing parents: List(Stage 70)
14/05/12 21:19:40 INFO DAGScheduler: Submitting Stage 70 (MapPartitionsRDD[106] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:40 INFO DAGScheduler: Submitting 2 missing tasks from Stage 70 (MapPartitionsRDD[106] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:40 INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks
14/05/12 21:19:40 INFO TaskSetManager: Starting task 70.0:0 as TID 85 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:40 INFO TaskSetManager: Serialized task 70.0:0 as 1518 bytes in 0 ms
14/05/12 21:19:40 INFO Executor: Running task ID 85
14/05/12 21:19:40 INFO BlockManager: Found block input-0-1399909772800 locally
14/05/12 21:19:40 INFO Executor: Serialized size of result for 85 is 751
14/05/12 21:19:40 INFO Executor: Sending result for 85 directly to driver
14/05/12 21:19:40 INFO Executor: Finished task ID 85
14/05/12 21:19:40 INFO TaskSetManager: Starting task 70.0:1 as TID 86 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:40 INFO TaskSetManager: Serialized task 70.0:1 as 1518 bytes in 1 ms
14/05/12 21:19:40 INFO Executor: Running task ID 86
14/05/12 21:19:40 INFO TaskSetManager: Finished TID 85 in 17 ms on localhost (progress: 0/2)
14/05/12 21:19:40 INFO DAGScheduler: Completed ShuffleMapTask(70, 0)
14/05/12 21:19:40 INFO BlockManager: Found block input-0-1399909773400 locally
14/05/12 21:19:40 INFO Executor: Serialized size of result for 86 is 751
14/05/12 21:19:40 INFO Executor: Sending result for 86 directly to driver
14/05/12 21:19:40 INFO Executor: Finished task ID 86
14/05/12 21:19:40 INFO TaskSetManager: Finished TID 86 in 9 ms on localhost (progress: 1/2)
14/05/12 21:19:40 INFO TaskSchedulerImpl: Remove TaskSet 70.0 from pool 
14/05/12 21:19:40 INFO DAGScheduler: Completed ShuffleMapTask(70, 1)
14/05/12 21:19:40 INFO DAGScheduler: Stage 70 (combineByKey at ShuffledDStream.scala:42) finished in 0.026 s
14/05/12 21:19:40 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:19:40 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:19:40 INFO DAGScheduler: waiting: Set(Stage 69)
14/05/12 21:19:40 INFO DAGScheduler: failed: Set()
14/05/12 21:19:40 INFO DAGScheduler: Missing parents for Stage 69: List()
14/05/12 21:19:40 INFO DAGScheduler: Submitting Stage 69 (MapPartitionsRDD[108] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:19:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 69 (MapPartitionsRDD[108] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:40 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
14/05/12 21:19:40 INFO TaskSetManager: Starting task 69.0:0 as TID 87 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:40 INFO TaskSetManager: Serialized task 69.0:0 as 1562 bytes in 0 ms
14/05/12 21:19:40 INFO Executor: Running task ID 87
14/05/12 21:19:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 2 non-zero-bytes blocks out of 2 blocks
14/05/12 21:19:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:19:40 INFO Executor: Serialized size of result for 87 is 959
14/05/12 21:19:40 INFO Executor: Sending result for 87 directly to driver
14/05/12 21:19:40 INFO Executor: Finished task ID 87
14/05/12 21:19:40 INFO TaskSetManager: Finished TID 87 in 17 ms on localhost (progress: 0/1)
14/05/12 21:19:40 INFO TaskSchedulerImpl: Remove TaskSet 69.0 from pool 
14/05/12 21:19:40 INFO DAGScheduler: Completed ResultTask(69, 0)
14/05/12 21:19:40 INFO DAGScheduler: Stage 69 (take at DStream.scala:586) finished in 0.020 s
14/05/12 21:19:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.07262412 s
14/05/12 21:19:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 148 bytes
14/05/12 21:19:40 INFO DAGScheduler: Got job 36 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:40 INFO DAGScheduler: Final stage: Stage 71 (take at DStream.scala:586)
14/05/12 21:19:40 INFO DAGScheduler: Parents of final stage: List(Stage 72)
14/05/12 21:19:40 INFO DAGScheduler: Missing parents: List()
14/05/12 21:19:40 INFO DAGScheduler: Submitting Stage 71 (MapPartitionsRDD[108] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 71 (MapPartitionsRDD[108] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:40 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
14/05/12 21:19:40 INFO TaskSetManager: Starting task 71.0:0 as TID 88 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:40 INFO TaskSetManager: Serialized task 71.0:0 as 1562 bytes in 0 ms
14/05/12 21:19:40 INFO Executor: Running task ID 88
14/05/12 21:19:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 2 blocks
14/05/12 21:19:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:19:40 INFO Executor: Serialized size of result for 88 is 813
14/05/12 21:19:40 INFO Executor: Sending result for 88 directly to driver
14/05/12 21:19:40 INFO Executor: Finished task ID 88
14/05/12 21:19:40 INFO TaskSetManager: Finished TID 88 in 12 ms on localhost (progress: 0/1)
14/05/12 21:19:40 INFO DAGScheduler: Completed ResultTask(71, 1)
14/05/12 21:19:40 INFO TaskSchedulerImpl: Remove TaskSet 71.0 from pool 
14/05/12 21:19:40 INFO DAGScheduler: Stage 71 (take at DStream.scala:586) finished in 0.014 s
14/05/12 21:19:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.026081884 s
14/05/12 21:19:40 INFO JobScheduler: Finished job streaming job 1399909780000 ms.0 from job set of time 1399909780000 ms
14/05/12 21:19:40 INFO JobScheduler: Total delay: 0.124 s for time 1399909780000 ms (execution: 0.108 s)
14/05/12 21:19:43 INFO MemoryStore: ensureFreeSpace(8) called with curMem=478, maxMem=671298355
14/05/12 21:19:43 INFO MemoryStore: Block input-0-1399909783400 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:43 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909783400 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:43 INFO BlockManagerMaster: Updated info of block input-0-1399909783400
14/05/12 21:19:43 WARN BlockManager: Block input-0-1399909783400 already exists on this machine; not re-adding it
14/05/12 21:19:44 INFO MemoryStore: ensureFreeSpace(8) called with curMem=486, maxMem=671298355
14/05/12 21:19:44 INFO MemoryStore: Block input-0-1399909783800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:44 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909783800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:44 INFO BlockManagerMaster: Updated info of block input-0-1399909783800
14/05/12 21:19:44 WARN BlockManager: Block input-0-1399909783800 already exists on this machine; not re-adding it
14/05/12 21:19:45 INFO MemoryStore: ensureFreeSpace(8) called with curMem=494, maxMem=671298355
14/05/12 21:19:45 INFO MemoryStore: Block input-0-1399909784800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:45 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909784800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:45 INFO BlockManagerMaster: Updated info of block input-0-1399909784800
14/05/12 21:19:45 WARN BlockManager: Block input-0-1399909784800 already exists on this machine; not re-adding it
14/05/12 21:19:46 INFO MemoryStore: ensureFreeSpace(8) called with curMem=502, maxMem=671298355
14/05/12 21:19:46 INFO MemoryStore: Block input-0-1399909786400 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:46 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909786400 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:46 INFO BlockManagerMaster: Updated info of block input-0-1399909786400
14/05/12 21:19:46 WARN BlockManager: Block input-0-1399909786400 already exists on this machine; not re-adding it
14/05/12 21:19:47 INFO MemoryStore: ensureFreeSpace(8) called with curMem=510, maxMem=671298355
14/05/12 21:19:47 INFO MemoryStore: Block input-0-1399909786800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:47 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909786800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:47 INFO BlockManagerMaster: Updated info of block input-0-1399909786800
14/05/12 21:19:47 WARN BlockManager: Block input-0-1399909786800 already exists on this machine; not re-adding it
14/05/12 21:19:49 INFO MemoryStore: ensureFreeSpace(8) called with curMem=518, maxMem=671298355
14/05/12 21:19:49 INFO MemoryStore: Block input-0-1399909788800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:49 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909788800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:49 INFO BlockManagerMaster: Updated info of block input-0-1399909788800
14/05/12 21:19:49 WARN BlockManager: Block input-0-1399909788800 already exists on this machine; not re-adding it
14/05/12 21:19:50 INFO NetworkInputTracker: Stream 0 received 6 blocks
14/05/12 21:19:50 INFO MemoryStore: ensureFreeSpace(8) called with curMem=526, maxMem=671298355
14/05/12 21:19:50 INFO MemoryStore: Block input-0-1399909789800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:50 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909789800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:50 INFO BlockManagerMaster: Updated info of block input-0-1399909789800
14/05/12 21:19:50 INFO JobScheduler: Added jobs for time 1399909790000 ms
14/05/12 21:19:50 INFO JobScheduler: Starting job streaming job 1399909790000 ms.0 from job set of time 1399909790000 ms
14/05/12 21:19:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:50 INFO DAGScheduler: Registering RDD 112 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:50 INFO DAGScheduler: Got job 37 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:50 INFO DAGScheduler: Final stage: Stage 73 (take at DStream.scala:586)
14/05/12 21:19:50 INFO DAGScheduler: Parents of final stage: List(Stage 74)
14/05/12 21:19:50 INFO DAGScheduler: Missing parents: List(Stage 74)
14/05/12 21:19:50 INFO DAGScheduler: Submitting Stage 74 (MapPartitionsRDD[112] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:50 INFO DAGScheduler: Submitting 6 missing tasks from Stage 74 (MapPartitionsRDD[112] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:50 INFO TaskSchedulerImpl: Adding task set 74.0 with 6 tasks
14/05/12 21:19:50 INFO TaskSetManager: Starting task 74.0:0 as TID 89 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:50 INFO TaskSetManager: Serialized task 74.0:0 as 1517 bytes in 0 ms
14/05/12 21:19:50 INFO Executor: Running task ID 89
14/05/12 21:19:50 INFO BlockManager: Found block input-0-1399909783400 locally
14/05/12 21:19:50 INFO Executor: Serialized size of result for 89 is 751
14/05/12 21:19:50 INFO Executor: Sending result for 89 directly to driver
14/05/12 21:19:50 INFO Executor: Finished task ID 89
14/05/12 21:19:50 INFO TaskSetManager: Starting task 74.0:1 as TID 90 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:50 INFO TaskSetManager: Serialized task 74.0:1 as 1517 bytes in 0 ms
14/05/12 21:19:50 INFO TaskSetManager: Finished TID 89 in 14 ms on localhost (progress: 0/6)
14/05/12 21:19:50 INFO DAGScheduler: Completed ShuffleMapTask(74, 0)
14/05/12 21:19:50 INFO Executor: Running task ID 90
14/05/12 21:19:50 INFO BlockManager: Found block input-0-1399909783800 locally
14/05/12 21:19:50 INFO Executor: Serialized size of result for 90 is 751
14/05/12 21:19:50 INFO Executor: Sending result for 90 directly to driver
14/05/12 21:19:50 INFO Executor: Finished task ID 90
14/05/12 21:19:50 INFO TaskSetManager: Starting task 74.0:2 as TID 91 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:50 INFO TaskSetManager: Serialized task 74.0:2 as 1517 bytes in 0 ms
14/05/12 21:19:50 INFO Executor: Running task ID 91
14/05/12 21:19:50 INFO TaskSetManager: Finished TID 90 in 12 ms on localhost (progress: 1/6)
14/05/12 21:19:50 INFO DAGScheduler: Completed ShuffleMapTask(74, 1)
14/05/12 21:19:50 INFO BlockManager: Found block input-0-1399909784800 locally
14/05/12 21:19:50 INFO Executor: Serialized size of result for 91 is 751
14/05/12 21:19:50 INFO Executor: Sending result for 91 directly to driver
14/05/12 21:19:50 INFO Executor: Finished task ID 91
14/05/12 21:19:50 WARN BlockManager: Block input-0-1399909789800 already exists on this machine; not re-adding it
14/05/12 21:19:50 INFO TaskSetManager: Starting task 74.0:3 as TID 92 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:50 INFO TaskSetManager: Serialized task 74.0:3 as 1517 bytes in 0 ms
14/05/12 21:19:50 INFO Executor: Running task ID 92
14/05/12 21:19:50 INFO TaskSetManager: Finished TID 91 in 15 ms on localhost (progress: 2/6)
14/05/12 21:19:50 INFO DAGScheduler: Completed ShuffleMapTask(74, 2)
14/05/12 21:19:50 INFO BlockManager: Found block input-0-1399909786400 locally
14/05/12 21:19:50 INFO Executor: Serialized size of result for 92 is 751
14/05/12 21:19:50 INFO Executor: Sending result for 92 directly to driver
14/05/12 21:19:50 INFO Executor: Finished task ID 92
14/05/12 21:19:50 INFO TaskSetManager: Starting task 74.0:4 as TID 93 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:50 INFO TaskSetManager: Serialized task 74.0:4 as 1517 bytes in 0 ms
14/05/12 21:19:50 INFO Executor: Running task ID 93
14/05/12 21:19:50 INFO TaskSetManager: Finished TID 92 in 17 ms on localhost (progress: 3/6)
14/05/12 21:19:50 INFO DAGScheduler: Completed ShuffleMapTask(74, 3)
14/05/12 21:19:50 INFO BlockManager: Found block input-0-1399909786800 locally
14/05/12 21:19:50 INFO Executor: Serialized size of result for 93 is 751
14/05/12 21:19:50 INFO Executor: Sending result for 93 directly to driver
14/05/12 21:19:50 INFO Executor: Finished task ID 93
14/05/12 21:19:50 INFO TaskSetManager: Starting task 74.0:5 as TID 94 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:50 INFO TaskSetManager: Serialized task 74.0:5 as 1517 bytes in 0 ms
14/05/12 21:19:50 INFO Executor: Running task ID 94
14/05/12 21:19:50 INFO TaskSetManager: Finished TID 93 in 17 ms on localhost (progress: 4/6)
14/05/12 21:19:50 INFO DAGScheduler: Completed ShuffleMapTask(74, 4)
14/05/12 21:19:50 INFO BlockManager: Found block input-0-1399909788800 locally
14/05/12 21:19:50 INFO Executor: Serialized size of result for 94 is 751
14/05/12 21:19:50 INFO Executor: Sending result for 94 directly to driver
14/05/12 21:19:50 INFO Executor: Finished task ID 94
14/05/12 21:19:50 INFO TaskSetManager: Finished TID 94 in 12 ms on localhost (progress: 5/6)
14/05/12 21:19:50 INFO TaskSchedulerImpl: Remove TaskSet 74.0 from pool 
14/05/12 21:19:50 INFO DAGScheduler: Completed ShuffleMapTask(74, 5)
14/05/12 21:19:50 INFO DAGScheduler: Stage 74 (combineByKey at ShuffledDStream.scala:42) finished in 0.078 s
14/05/12 21:19:50 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:19:50 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:19:50 INFO DAGScheduler: waiting: Set(Stage 73)
14/05/12 21:19:50 INFO DAGScheduler: failed: Set()
14/05/12 21:19:50 INFO DAGScheduler: Missing parents for Stage 73: List()
14/05/12 21:19:50 INFO DAGScheduler: Submitting Stage 73 (MapPartitionsRDD[114] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:19:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 73 (MapPartitionsRDD[114] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:50 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
14/05/12 21:19:50 INFO TaskSetManager: Starting task 73.0:0 as TID 95 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:50 INFO TaskSetManager: Serialized task 73.0:0 as 1562 bytes in 1 ms
14/05/12 21:19:50 INFO Executor: Running task ID 95
14/05/12 21:19:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 3 non-zero-bytes blocks out of 6 blocks
14/05/12 21:19:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:19:50 INFO Executor: Serialized size of result for 95 is 959
14/05/12 21:19:50 INFO Executor: Sending result for 95 directly to driver
14/05/12 21:19:50 INFO Executor: Finished task ID 95
14/05/12 21:19:50 INFO TaskSetManager: Finished TID 95 in 42 ms on localhost (progress: 0/1)
14/05/12 21:19:50 INFO DAGScheduler: Completed ResultTask(73, 0)
14/05/12 21:19:50 INFO TaskSchedulerImpl: Remove TaskSet 73.0 from pool 
14/05/12 21:19:50 INFO DAGScheduler: Stage 73 (take at DStream.scala:586) finished in 0.045 s
14/05/12 21:19:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.14314256 s
14/05/12 21:19:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:19:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 155 bytes
14/05/12 21:19:50 INFO DAGScheduler: Got job 38 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:19:50 INFO DAGScheduler: Final stage: Stage 75 (take at DStream.scala:586)
14/05/12 21:19:50 INFO DAGScheduler: Parents of final stage: List(Stage 76)
14/05/12 21:19:50 INFO DAGScheduler: Missing parents: List()
14/05/12 21:19:50 INFO DAGScheduler: Submitting Stage 75 (MapPartitionsRDD[114] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:19:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 75 (MapPartitionsRDD[114] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:19:50 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
14/05/12 21:19:50 INFO TaskSetManager: Starting task 75.0:0 as TID 96 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:19:50 INFO TaskSetManager: Serialized task 75.0:0 as 1562 bytes in 1 ms
14/05/12 21:19:50 INFO Executor: Running task ID 96
14/05/12 21:19:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 3 non-zero-bytes blocks out of 6 blocks
14/05/12 21:19:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:19:50 INFO Executor: Serialized size of result for 96 is 979
14/05/12 21:19:50 INFO Executor: Sending result for 96 directly to driver
14/05/12 21:19:50 INFO Executor: Finished task ID 96
14/05/12 21:19:50 INFO TaskSetManager: Finished TID 96 in 14 ms on localhost (progress: 0/1)
14/05/12 21:19:50 INFO TaskSchedulerImpl: Remove TaskSet 75.0 from pool 
14/05/12 21:19:50 INFO DAGScheduler: Completed ResultTask(75, 1)
14/05/12 21:19:50 INFO DAGScheduler: Stage 75 (take at DStream.scala:586) finished in 0.016 s
14/05/12 21:19:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.02793896 s
14/05/12 21:19:50 INFO JobScheduler: Finished job streaming job 1399909790000 ms.0 from job set of time 1399909790000 ms
14/05/12 21:19:50 INFO JobScheduler: Total delay: 0.194 s for time 1399909790000 ms (execution: 0.178 s)
14/05/12 21:19:50 INFO MemoryStore: ensureFreeSpace(8) called with curMem=534, maxMem=671298355
14/05/12 21:19:50 INFO MemoryStore: Block input-0-1399909790200 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:50 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909790200 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:50 INFO BlockManagerMaster: Updated info of block input-0-1399909790200
14/05/12 21:19:50 WARN BlockManager: Block input-0-1399909790200 already exists on this machine; not re-adding it
14/05/12 21:19:51 INFO MemoryStore: ensureFreeSpace(8) called with curMem=542, maxMem=671298355
14/05/12 21:19:51 INFO MemoryStore: Block input-0-1399909790800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:51 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909790800 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:51 INFO BlockManagerMaster: Updated info of block input-0-1399909790800
14/05/12 21:19:51 WARN BlockManager: Block input-0-1399909790800 already exists on this machine; not re-adding it
14/05/12 21:19:52 INFO MemoryStore: ensureFreeSpace(8) called with curMem=550, maxMem=671298355
14/05/12 21:19:52 INFO MemoryStore: Block input-0-1399909792400 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/12 21:19:52 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399909792400 in memory on ubuntu-3.local:46407 (size: 8.0 B, free: 640.2 MB)
14/05/12 21:19:52 INFO BlockManagerMaster: Updated info of block input-0-1399909792400
14/05/12 21:19:52 WARN BlockManager: Block input-0-1399909792400 already exists on this machine; not re-adding it
14/05/12 21:20:00 INFO NetworkInputTracker: Stream 0 received 4 blocks
14/05/12 21:20:00 INFO JobScheduler: Added jobs for time 1399909800000 ms
14/05/12 21:20:00 INFO JobScheduler: Starting job streaming job 1399909800000 ms.0 from job set of time 1399909800000 ms
14/05/12 21:20:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:20:00 INFO DAGScheduler: Registering RDD 118 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:20:00 INFO DAGScheduler: Got job 39 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:20:00 INFO DAGScheduler: Final stage: Stage 77 (take at DStream.scala:586)
14/05/12 21:20:00 INFO DAGScheduler: Parents of final stage: List(Stage 78)
14/05/12 21:20:00 INFO DAGScheduler: Missing parents: List(Stage 78)
14/05/12 21:20:00 INFO DAGScheduler: Submitting Stage 78 (MapPartitionsRDD[118] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:20:00 INFO DAGScheduler: Submitting 4 missing tasks from Stage 78 (MapPartitionsRDD[118] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:20:00 INFO TaskSchedulerImpl: Adding task set 78.0 with 4 tasks
14/05/12 21:20:00 INFO TaskSetManager: Starting task 78.0:0 as TID 97 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:20:00 INFO TaskSetManager: Serialized task 78.0:0 as 1517 bytes in 0 ms
14/05/12 21:20:00 INFO Executor: Running task ID 97
14/05/12 21:20:00 INFO BlockManager: Found block input-0-1399909789800 locally
14/05/12 21:20:00 INFO Executor: Serialized size of result for 97 is 751
14/05/12 21:20:00 INFO Executor: Sending result for 97 directly to driver
14/05/12 21:20:00 INFO Executor: Finished task ID 97
14/05/12 21:20:00 INFO TaskSetManager: Starting task 78.0:1 as TID 98 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:20:00 INFO TaskSetManager: Serialized task 78.0:1 as 1517 bytes in 1 ms
14/05/12 21:20:00 INFO Executor: Running task ID 98
14/05/12 21:20:00 INFO TaskSetManager: Finished TID 97 in 16 ms on localhost (progress: 0/4)
14/05/12 21:20:00 INFO DAGScheduler: Completed ShuffleMapTask(78, 0)
14/05/12 21:20:00 INFO BlockManager: Found block input-0-1399909790200 locally
14/05/12 21:20:00 INFO Executor: Serialized size of result for 98 is 751
14/05/12 21:20:00 INFO Executor: Sending result for 98 directly to driver
14/05/12 21:20:00 INFO Executor: Finished task ID 98
14/05/12 21:20:00 INFO TaskSetManager: Starting task 78.0:2 as TID 99 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:20:00 INFO TaskSetManager: Serialized task 78.0:2 as 1517 bytes in 0 ms
14/05/12 21:20:00 INFO Executor: Running task ID 99
14/05/12 21:20:00 INFO TaskSetManager: Finished TID 98 in 13 ms on localhost (progress: 1/4)
14/05/12 21:20:00 INFO DAGScheduler: Completed ShuffleMapTask(78, 1)
14/05/12 21:20:00 INFO BlockManager: Found block input-0-1399909790800 locally
14/05/12 21:20:00 INFO Executor: Serialized size of result for 99 is 751
14/05/12 21:20:00 INFO Executor: Sending result for 99 directly to driver
14/05/12 21:20:00 INFO Executor: Finished task ID 99
14/05/12 21:20:00 INFO TaskSetManager: Starting task 78.0:3 as TID 100 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:20:00 INFO TaskSetManager: Serialized task 78.0:3 as 1517 bytes in 0 ms
14/05/12 21:20:00 INFO Executor: Running task ID 100
14/05/12 21:20:00 INFO TaskSetManager: Finished TID 99 in 17 ms on localhost (progress: 2/4)
14/05/12 21:20:00 INFO DAGScheduler: Completed ShuffleMapTask(78, 2)
14/05/12 21:20:00 INFO BlockManager: Found block input-0-1399909792400 locally
14/05/12 21:20:00 INFO Executor: Serialized size of result for 100 is 751
14/05/12 21:20:00 INFO Executor: Sending result for 100 directly to driver
14/05/12 21:20:00 INFO Executor: Finished task ID 100
14/05/12 21:20:00 INFO TaskSetManager: Finished TID 100 in 11 ms on localhost (progress: 3/4)
14/05/12 21:20:00 INFO TaskSchedulerImpl: Remove TaskSet 78.0 from pool 
14/05/12 21:20:00 INFO DAGScheduler: Completed ShuffleMapTask(78, 3)
14/05/12 21:20:00 INFO DAGScheduler: Stage 78 (combineByKey at ShuffledDStream.scala:42) finished in 0.053 s
14/05/12 21:20:00 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:20:00 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:20:00 INFO DAGScheduler: waiting: Set(Stage 77)
14/05/12 21:20:00 INFO DAGScheduler: failed: Set()
14/05/12 21:20:00 INFO DAGScheduler: Missing parents for Stage 77: List()
14/05/12 21:20:00 INFO DAGScheduler: Submitting Stage 77 (MapPartitionsRDD[120] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:20:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 77 (MapPartitionsRDD[120] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:20:00 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
14/05/12 21:20:00 INFO TaskSetManager: Starting task 77.0:0 as TID 101 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:20:00 INFO TaskSetManager: Serialized task 77.0:0 as 1562 bytes in 0 ms
14/05/12 21:20:00 INFO Executor: Running task ID 101
14/05/12 21:20:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 4 blocks
14/05/12 21:20:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:20:00 INFO Executor: Serialized size of result for 101 is 813
14/05/12 21:20:00 INFO Executor: Sending result for 101 directly to driver
14/05/12 21:20:00 INFO Executor: Finished task ID 101
14/05/12 21:20:00 INFO TaskSetManager: Finished TID 101 in 10 ms on localhost (progress: 0/1)
14/05/12 21:20:00 INFO TaskSchedulerImpl: Remove TaskSet 77.0 from pool 
14/05/12 21:20:00 INFO DAGScheduler: Completed ResultTask(77, 0)
14/05/12 21:20:00 INFO DAGScheduler: Stage 77 (take at DStream.scala:586) finished in 0.012 s
14/05/12 21:20:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.087657255 s
14/05/12 21:20:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:20:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 148 bytes
14/05/12 21:20:00 INFO DAGScheduler: Got job 40 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:20:00 INFO DAGScheduler: Final stage: Stage 79 (take at DStream.scala:586)
14/05/12 21:20:00 INFO DAGScheduler: Parents of final stage: List(Stage 80)
14/05/12 21:20:00 INFO DAGScheduler: Missing parents: List()
14/05/12 21:20:00 INFO DAGScheduler: Submitting Stage 79 (MapPartitionsRDD[120] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:20:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 79 (MapPartitionsRDD[120] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:20:00 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
14/05/12 21:20:00 INFO TaskSetManager: Starting task 79.0:0 as TID 102 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:20:00 INFO TaskSetManager: Serialized task 79.0:0 as 1562 bytes in 0 ms
14/05/12 21:20:00 INFO Executor: Running task ID 102
14/05/12 21:20:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 4 non-zero-bytes blocks out of 4 blocks
14/05/12 21:20:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:20:00 INFO Executor: Serialized size of result for 102 is 979
14/05/12 21:20:00 INFO Executor: Sending result for 102 directly to driver
14/05/12 21:20:00 INFO Executor: Finished task ID 102
14/05/12 21:20:00 INFO TaskSetManager: Finished TID 102 in 16 ms on localhost (progress: 0/1)
14/05/12 21:20:00 INFO DAGScheduler: Completed ResultTask(79, 1)
14/05/12 21:20:00 INFO TaskSchedulerImpl: Remove TaskSet 79.0 from pool 
14/05/12 21:20:00 INFO DAGScheduler: Stage 79 (take at DStream.scala:586) finished in 0.018 s
14/05/12 21:20:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.029558492 s
14/05/12 21:20:00 INFO JobScheduler: Finished job streaming job 1399909800000 ms.0 from job set of time 1399909800000 ms
14/05/12 21:20:00 INFO JobScheduler: Total delay: 0.141 s for time 1399909800000 ms (execution: 0.124 s)
14/05/12 21:39:01 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/12 21:39:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/12 21:39:02 INFO Slf4jLogger: Slf4jLogger started
14/05/12 21:39:03 INFO Remoting: Starting remoting
14/05/12 21:39:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:39996]
14/05/12 21:39:03 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:39996]
14/05/12 21:39:03 INFO SparkEnv: Registering BlockManagerMaster
14/05/12 21:39:03 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140512213903-4b0c
14/05/12 21:39:03 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/12 21:39:03 INFO ConnectionManager: Bound socket to port 54077 with id = ConnectionManagerId(ubuntu,54077)
14/05/12 21:39:03 INFO BlockManagerMaster: Trying to register BlockManager
14/05/12 21:39:03 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:54077 with 640.2 MB RAM
14/05/12 21:39:03 INFO BlockManagerMaster: Registered BlockManager
14/05/12 21:39:03 INFO HttpServer: Starting HTTP Server
14/05/12 21:39:03 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:44805
14/05/12 21:39:03 INFO SparkEnv: Registering MapOutputTracker
14/05/12 21:39:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-dbad3b62-f579-4336-922e-c1db2694d978
14/05/12 21:39:03 INFO HttpServer: Starting HTTP Server
14/05/12 21:39:04 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/12 21:39:04 INFO NetworkInputTracker: NetworkInputTracker started
14/05/12 21:39:04 INFO SparkContext: Starting job: runJob at NetworkInputTracker.scala:182
14/05/12 21:39:04 INFO DAGScheduler: Got job 0 (runJob at NetworkInputTracker.scala:182) with 1 output partitions (allowLocal=false)
14/05/12 21:39:04 INFO DAGScheduler: Final stage: Stage 0 (runJob at NetworkInputTracker.scala:182)
14/05/12 21:39:04 INFO DAGScheduler: Parents of final stage: List()
14/05/12 21:39:04 INFO DAGScheduler: Missing parents: List()
14/05/12 21:39:04 INFO DAGScheduler: Submitting Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165), which has no missing parents
14/05/12 21:39:05 INFO DAGScheduler: Submitting 1 missing tasks from Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165)
14/05/12 21:39:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
14/05/12 21:39:05 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:05 INFO TaskSetManager: Serialized task 0.0:0 as 1978 bytes in 13 ms
14/05/12 21:39:05 INFO Executor: Running task ID 0
14/05/12 21:39:05 INFO SocketReceiver: Connecting to localhost:9999
14/05/12 21:39:05 INFO SocketReceiver: Attempting to register with tracker
14/05/12 21:39:05 INFO SocketReceiver: Connected to localhost:9999
14/05/12 21:39:05 INFO NetworkReceiver$BlockGenerator: Block pushing thread started
14/05/12 21:39:05 INFO NetworkReceiver$BlockGenerator: Data handler started
14/05/12 21:39:05 INFO NetworkInputTracker: Registered receiver for network stream 0 from akka://spark
14/05/12 21:39:05 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/12 21:39:05 INFO ShuffledDStream: metadataCleanupDelay = 3600
14/05/12 21:39:05 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/12 21:39:05 INFO FlatMappedDStream: metadataCleanupDelay = 3600
14/05/12 21:39:05 INFO SocketInputDStream: metadataCleanupDelay = 3600
14/05/12 21:39:05 INFO SocketInputDStream: Slide time = 10000 ms
14/05/12 21:39:05 INFO SocketInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:39:05 INFO SocketInputDStream: Checkpoint interval = null
14/05/12 21:39:05 INFO SocketInputDStream: Remember duration = 10000 ms
14/05/12 21:39:05 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@19a81722
14/05/12 21:39:05 INFO FlatMappedDStream: Slide time = 10000 ms
14/05/12 21:39:05 INFO FlatMappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:39:05 INFO FlatMappedDStream: Checkpoint interval = null
14/05/12 21:39:05 INFO FlatMappedDStream: Remember duration = 10000 ms
14/05/12 21:39:05 INFO FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@6a86c656
14/05/12 21:39:05 INFO MappedDStream: Slide time = 10000 ms
14/05/12 21:39:05 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:39:05 INFO MappedDStream: Checkpoint interval = null
14/05/12 21:39:05 INFO MappedDStream: Remember duration = 10000 ms
14/05/12 21:39:05 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@36476ebd
14/05/12 21:39:05 INFO ShuffledDStream: Slide time = 10000 ms
14/05/12 21:39:05 INFO ShuffledDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:39:05 INFO ShuffledDStream: Checkpoint interval = null
14/05/12 21:39:05 INFO ShuffledDStream: Remember duration = 10000 ms
14/05/12 21:39:05 INFO ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@bb75622
14/05/12 21:39:05 INFO ForEachDStream: Slide time = 10000 ms
14/05/12 21:39:05 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:39:05 INFO ForEachDStream: Checkpoint interval = null
14/05/12 21:39:05 INFO ForEachDStream: Remember duration = 10000 ms
14/05/12 21:39:05 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@3177d830
14/05/12 21:39:05 INFO JobGenerator: JobGenerator started at 1399910950000 ms
14/05/12 21:39:05 INFO JobScheduler: JobScheduler started
14/05/12 21:39:09 INFO MemoryStore: ensureFreeSpace(11) called with curMem=0, maxMem=671298355
14/05/12 21:39:09 INFO MemoryStore: Block input-0-1399910949000 stored as bytes to memory (size 11.0 B, free 640.2 MB)
14/05/12 21:39:09 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399910949000 in memory on ubuntu:54077 (size: 11.0 B, free: 640.2 MB)
14/05/12 21:39:09 INFO BlockManagerMaster: Updated info of block input-0-1399910949000
14/05/12 21:39:09 INFO SendingConnection: Initiating connection to [ubuntu/127.0.1.1:54077]
14/05/12 21:39:09 INFO SendingConnection: Connected to [ubuntu/127.0.1.1:54077], 1 messages pending
14/05/12 21:39:09 INFO ConnectionManager: Accepted connection from [localhost/127.0.0.1]
14/05/12 21:39:09 WARN BlockManager: Block input-0-1399910949000 already exists on this machine; not re-adding it
14/05/12 21:39:09 INFO MemoryStore: ensureFreeSpace(9) called with curMem=11, maxMem=671298355
14/05/12 21:39:09 INFO MemoryStore: Block input-0-1399910949200 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/12 21:39:09 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399910949200 in memory on ubuntu:54077 (size: 9.0 B, free: 640.2 MB)
14/05/12 21:39:09 INFO BlockManagerMaster: Updated info of block input-0-1399910949200
14/05/12 21:39:09 WARN BlockManager: Block input-0-1399910949200 already exists on this machine; not re-adding it
14/05/12 21:39:10 INFO NetworkInputTracker: Stream 0 received 2 blocks
14/05/12 21:39:10 INFO JobScheduler: Added jobs for time 1399910950000 ms
14/05/12 21:39:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:39:10 INFO JobScheduler: Starting job streaming job 1399910950000 ms.0 from job set of time 1399910950000 ms
14/05/12 21:39:10 INFO DAGScheduler: Registering RDD 4 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:39:10 INFO DAGScheduler: Got job 1 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:39:10 INFO DAGScheduler: Final stage: Stage 1 (take at DStream.scala:586)
14/05/12 21:39:10 INFO DAGScheduler: Parents of final stage: List(Stage 2)
14/05/12 21:39:10 INFO DAGScheduler: Missing parents: List(Stage 2)
14/05/12 21:39:10 INFO DAGScheduler: Submitting Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:39:10 INFO DAGScheduler: Submitting 2 missing tasks from Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:39:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
14/05/12 21:39:10 INFO TaskSetManager: Starting task 2.0:0 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:10 INFO TaskSetManager: Serialized task 2.0:0 as 1517 bytes in 0 ms
14/05/12 21:39:10 INFO Executor: Running task ID 1
14/05/12 21:39:10 INFO BlockManager: Found block input-0-1399910949000 locally
14/05/12 21:39:10 INFO Executor: Serialized size of result for 1 is 743
14/05/12 21:39:10 INFO Executor: Sending result for 1 directly to driver
14/05/12 21:39:10 INFO Executor: Finished task ID 1
14/05/12 21:39:10 INFO TaskSetManager: Starting task 2.0:1 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:10 INFO TaskSetManager: Serialized task 2.0:1 as 1517 bytes in 1 ms
14/05/12 21:39:10 INFO Executor: Running task ID 2
14/05/12 21:39:10 INFO TaskSetManager: Finished TID 1 in 187 ms on localhost (progress: 0/2)
14/05/12 21:39:10 INFO DAGScheduler: Completed ShuffleMapTask(2, 0)
14/05/12 21:39:10 INFO BlockManager: Found block input-0-1399910949200 locally
14/05/12 21:39:10 INFO Executor: Serialized size of result for 2 is 743
14/05/12 21:39:10 INFO Executor: Sending result for 2 directly to driver
14/05/12 21:39:10 INFO Executor: Finished task ID 2
14/05/12 21:39:10 INFO TaskSetManager: Finished TID 2 in 21 ms on localhost (progress: 1/2)
14/05/12 21:39:10 INFO DAGScheduler: Completed ShuffleMapTask(2, 1)
14/05/12 21:39:10 INFO TaskSchedulerImpl: Remove TaskSet 2.0 from pool 
14/05/12 21:39:10 INFO DAGScheduler: Stage 2 (combineByKey at ShuffledDStream.scala:42) finished in 0.208 s
14/05/12 21:39:10 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:39:10 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:39:10 INFO DAGScheduler: waiting: Set(Stage 1)
14/05/12 21:39:10 INFO DAGScheduler: failed: Set()
14/05/12 21:39:10 INFO DAGScheduler: Missing parents for Stage 1: List()
14/05/12 21:39:10 INFO DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:39:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:39:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
14/05/12 21:39:10 INFO TaskSetManager: Starting task 1.0:0 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:10 INFO TaskSetManager: Serialized task 1.0:0 as 1562 bytes in 1 ms
14/05/12 21:39:10 INFO Executor: Running task ID 3
14/05/12 21:39:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 2 blocks
14/05/12 21:39:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  10 ms
14/05/12 21:39:10 INFO Executor: Serialized size of result for 3 is 960
14/05/12 21:39:10 INFO Executor: Sending result for 3 directly to driver
14/05/12 21:39:10 INFO Executor: Finished task ID 3
14/05/12 21:39:10 INFO TaskSetManager: Finished TID 3 in 63 ms on localhost (progress: 0/1)
14/05/12 21:39:10 INFO TaskSchedulerImpl: Remove TaskSet 1.0 from pool 
14/05/12 21:39:10 INFO DAGScheduler: Completed ResultTask(1, 0)
14/05/12 21:39:10 INFO DAGScheduler: Stage 1 (take at DStream.scala:586) finished in 0.069 s
14/05/12 21:39:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.396636647 s
14/05/12 21:39:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:39:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 143 bytes
14/05/12 21:39:10 INFO DAGScheduler: Got job 2 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:39:10 INFO DAGScheduler: Final stage: Stage 3 (take at DStream.scala:586)
14/05/12 21:39:10 INFO DAGScheduler: Parents of final stage: List(Stage 4)
14/05/12 21:39:10 INFO DAGScheduler: Missing parents: List()
14/05/12 21:39:10 INFO DAGScheduler: Submitting Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:39:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:39:10 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
14/05/12 21:39:10 INFO TaskSetManager: Starting task 3.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:10 INFO TaskSetManager: Serialized task 3.0:0 as 1562 bytes in 0 ms
14/05/12 21:39:10 INFO Executor: Running task ID 4
14/05/12 21:39:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 2 blocks
14/05/12 21:39:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:39:10 INFO Executor: Serialized size of result for 4 is 962
14/05/12 21:39:10 INFO Executor: Sending result for 4 directly to driver
14/05/12 21:39:10 INFO Executor: Finished task ID 4
14/05/12 21:39:10 INFO TaskSetManager: Finished TID 4 in 23 ms on localhost (progress: 0/1)
14/05/12 21:39:10 INFO TaskSchedulerImpl: Remove TaskSet 3.0 from pool 
14/05/12 21:39:10 INFO DAGScheduler: Completed ResultTask(3, 1)
14/05/12 21:39:10 INFO DAGScheduler: Stage 3 (take at DStream.scala:586) finished in 0.027 s
14/05/12 21:39:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.044334641 s
14/05/12 21:39:10 INFO JobScheduler: Finished job streaming job 1399910950000 ms.0 from job set of time 1399910950000 ms
14/05/12 21:39:10 INFO JobScheduler: Total delay: 0.530 s for time 1399910950000 ms (execution: 0.456 s)
14/05/12 21:39:11 INFO MemoryStore: ensureFreeSpace(22) called with curMem=20, maxMem=671298355
14/05/12 21:39:11 INFO MemoryStore: Block input-0-1399910951200 stored as bytes to memory (size 22.0 B, free 640.2 MB)
14/05/12 21:39:11 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399910951200 in memory on ubuntu:54077 (size: 22.0 B, free: 640.2 MB)
14/05/12 21:39:11 INFO BlockManagerMaster: Updated info of block input-0-1399910951200
14/05/12 21:39:11 WARN BlockManager: Block input-0-1399910951200 already exists on this machine; not re-adding it
14/05/12 21:39:11 INFO MemoryStore: ensureFreeSpace(7) called with curMem=42, maxMem=671298355
14/05/12 21:39:11 INFO MemoryStore: Block input-0-1399910951400 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:39:11 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399910951400 in memory on ubuntu:54077 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:39:11 INFO BlockManagerMaster: Updated info of block input-0-1399910951400
14/05/12 21:39:11 WARN BlockManager: Block input-0-1399910951400 already exists on this machine; not re-adding it
14/05/12 21:39:12 INFO MemoryStore: ensureFreeSpace(9) called with curMem=49, maxMem=671298355
14/05/12 21:39:12 INFO MemoryStore: Block input-0-1399910951800 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/12 21:39:12 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399910951800 in memory on ubuntu:54077 (size: 9.0 B, free: 640.2 MB)
14/05/12 21:39:12 INFO BlockManagerMaster: Updated info of block input-0-1399910951800
14/05/12 21:39:12 WARN BlockManager: Block input-0-1399910951800 already exists on this machine; not re-adding it
14/05/12 21:39:12 INFO MemoryStore: ensureFreeSpace(7) called with curMem=58, maxMem=671298355
14/05/12 21:39:12 INFO MemoryStore: Block input-0-1399910952200 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:39:12 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399910952200 in memory on ubuntu:54077 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:39:12 INFO BlockManagerMaster: Updated info of block input-0-1399910952200
14/05/12 21:39:12 WARN BlockManager: Block input-0-1399910952200 already exists on this machine; not re-adding it
14/05/12 21:39:12 INFO MemoryStore: ensureFreeSpace(7) called with curMem=65, maxMem=671298355
14/05/12 21:39:12 INFO MemoryStore: Block input-0-1399910952400 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:39:12 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399910952400 in memory on ubuntu:54077 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:39:12 INFO BlockManagerMaster: Updated info of block input-0-1399910952400
14/05/12 21:39:12 WARN BlockManager: Block input-0-1399910952400 already exists on this machine; not re-adding it
14/05/12 21:39:12 INFO MemoryStore: ensureFreeSpace(7) called with curMem=72, maxMem=671298355
14/05/12 21:39:12 INFO MemoryStore: Block input-0-1399910952600 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/12 21:39:12 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399910952600 in memory on ubuntu:54077 (size: 7.0 B, free: 640.2 MB)
14/05/12 21:39:12 INFO BlockManagerMaster: Updated info of block input-0-1399910952600
14/05/12 21:39:12 WARN BlockManager: Block input-0-1399910952600 already exists on this machine; not re-adding it
14/05/12 21:39:20 INFO NetworkInputTracker: Stream 0 received 6 blocks
14/05/12 21:39:20 INFO JobScheduler: Added jobs for time 1399910960000 ms
14/05/12 21:39:20 INFO JobScheduler: Starting job streaming job 1399910960000 ms.0 from job set of time 1399910960000 ms
14/05/12 21:39:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:39:20 INFO DAGScheduler: Registering RDD 10 (combineByKey at ShuffledDStream.scala:42)
14/05/12 21:39:20 INFO DAGScheduler: Got job 3 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:39:20 INFO DAGScheduler: Final stage: Stage 5 (take at DStream.scala:586)
14/05/12 21:39:20 INFO DAGScheduler: Parents of final stage: List(Stage 6)
14/05/12 21:39:20 INFO DAGScheduler: Missing parents: List(Stage 6)
14/05/12 21:39:20 INFO DAGScheduler: Submitting Stage 6 (MapPartitionsRDD[10] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:39:20 INFO DAGScheduler: Submitting 6 missing tasks from Stage 6 (MapPartitionsRDD[10] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:39:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 6 tasks
14/05/12 21:39:20 INFO TaskSetManager: Starting task 6.0:0 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:20 INFO TaskSetManager: Serialized task 6.0:0 as 1518 bytes in 1 ms
14/05/12 21:39:20 INFO Executor: Running task ID 5
14/05/12 21:39:20 INFO BlockManager: Found block input-0-1399910951200 locally
14/05/12 21:39:20 INFO Executor: Serialized size of result for 5 is 743
14/05/12 21:39:20 INFO Executor: Sending result for 5 directly to driver
14/05/12 21:39:20 INFO Executor: Finished task ID 5
14/05/12 21:39:20 INFO TaskSetManager: Starting task 6.0:1 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:20 INFO TaskSetManager: Serialized task 6.0:1 as 1518 bytes in 1 ms
14/05/12 21:39:20 INFO Executor: Running task ID 6
14/05/12 21:39:20 INFO TaskSetManager: Finished TID 5 in 25 ms on localhost (progress: 0/6)
14/05/12 21:39:20 INFO DAGScheduler: Completed ShuffleMapTask(6, 0)
14/05/12 21:39:20 INFO BlockManager: Found block input-0-1399910951400 locally
14/05/12 21:39:20 INFO Executor: Serialized size of result for 6 is 743
14/05/12 21:39:20 INFO Executor: Sending result for 6 directly to driver
14/05/12 21:39:20 INFO Executor: Finished task ID 6
14/05/12 21:39:20 INFO TaskSetManager: Starting task 6.0:2 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:20 INFO TaskSetManager: Serialized task 6.0:2 as 1518 bytes in 1 ms
14/05/12 21:39:20 INFO Executor: Running task ID 7
14/05/12 21:39:20 INFO TaskSetManager: Finished TID 6 in 17 ms on localhost (progress: 1/6)
14/05/12 21:39:20 INFO DAGScheduler: Completed ShuffleMapTask(6, 1)
14/05/12 21:39:20 INFO BlockManager: Found block input-0-1399910951800 locally
14/05/12 21:39:20 INFO Executor: Serialized size of result for 7 is 743
14/05/12 21:39:20 INFO Executor: Sending result for 7 directly to driver
14/05/12 21:39:20 INFO Executor: Finished task ID 7
14/05/12 21:39:20 INFO TaskSetManager: Starting task 6.0:3 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:20 INFO TaskSetManager: Serialized task 6.0:3 as 1518 bytes in 0 ms
14/05/12 21:39:20 INFO Executor: Running task ID 8
14/05/12 21:39:20 INFO TaskSetManager: Finished TID 7 in 17 ms on localhost (progress: 2/6)
14/05/12 21:39:20 INFO DAGScheduler: Completed ShuffleMapTask(6, 2)
14/05/12 21:39:20 INFO BlockManager: Found block input-0-1399910952200 locally
14/05/12 21:39:20 INFO Executor: Serialized size of result for 8 is 743
14/05/12 21:39:20 INFO Executor: Sending result for 8 directly to driver
14/05/12 21:39:20 INFO Executor: Finished task ID 8
14/05/12 21:39:20 INFO TaskSetManager: Starting task 6.0:4 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:20 INFO TaskSetManager: Serialized task 6.0:4 as 1518 bytes in 0 ms
14/05/12 21:39:20 INFO Executor: Running task ID 9
14/05/12 21:39:20 INFO TaskSetManager: Finished TID 8 in 22 ms on localhost (progress: 3/6)
14/05/12 21:39:20 INFO DAGScheduler: Completed ShuffleMapTask(6, 3)
14/05/12 21:39:20 INFO BlockManager: Found block input-0-1399910952400 locally
14/05/12 21:39:20 INFO Executor: Serialized size of result for 9 is 743
14/05/12 21:39:20 INFO Executor: Sending result for 9 directly to driver
14/05/12 21:39:20 INFO Executor: Finished task ID 9
14/05/12 21:39:20 INFO TaskSetManager: Starting task 6.0:5 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:20 INFO TaskSetManager: Serialized task 6.0:5 as 1518 bytes in 0 ms
14/05/12 21:39:20 INFO Executor: Running task ID 10
14/05/12 21:39:20 INFO TaskSetManager: Finished TID 9 in 20 ms on localhost (progress: 4/6)
14/05/12 21:39:20 INFO DAGScheduler: Completed ShuffleMapTask(6, 4)
14/05/12 21:39:20 INFO BlockManager: Found block input-0-1399910952600 locally
14/05/12 21:39:20 INFO Executor: Serialized size of result for 10 is 743
14/05/12 21:39:20 INFO Executor: Sending result for 10 directly to driver
14/05/12 21:39:20 INFO Executor: Finished task ID 10
14/05/12 21:39:20 INFO TaskSetManager: Finished TID 10 in 18 ms on localhost (progress: 5/6)
14/05/12 21:39:20 INFO TaskSchedulerImpl: Remove TaskSet 6.0 from pool 
14/05/12 21:39:20 INFO DAGScheduler: Completed ShuffleMapTask(6, 5)
14/05/12 21:39:20 INFO DAGScheduler: Stage 6 (combineByKey at ShuffledDStream.scala:42) finished in 0.111 s
14/05/12 21:39:20 INFO DAGScheduler: looking for newly runnable stages
14/05/12 21:39:20 INFO DAGScheduler: running: Set(Stage 0)
14/05/12 21:39:20 INFO DAGScheduler: waiting: Set(Stage 5)
14/05/12 21:39:20 INFO DAGScheduler: failed: Set()
14/05/12 21:39:20 INFO DAGScheduler: Missing parents for Stage 5: List()
14/05/12 21:39:20 INFO DAGScheduler: Submitting Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/12 21:39:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:39:20 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
14/05/12 21:39:20 INFO TaskSetManager: Starting task 5.0:0 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:20 INFO TaskSetManager: Serialized task 5.0:0 as 1563 bytes in 1 ms
14/05/12 21:39:20 INFO Executor: Running task ID 11
14/05/12 21:39:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 6 non-zero-bytes blocks out of 6 blocks
14/05/12 21:39:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/12 21:39:20 INFO Executor: Serialized size of result for 11 is 1013
14/05/12 21:39:20 INFO Executor: Sending result for 11 directly to driver
14/05/12 21:39:20 INFO Executor: Finished task ID 11
14/05/12 21:39:20 INFO TaskSetManager: Finished TID 11 in 29 ms on localhost (progress: 0/1)
14/05/12 21:39:20 INFO DAGScheduler: Completed ResultTask(5, 0)
14/05/12 21:39:20 INFO TaskSchedulerImpl: Remove TaskSet 5.0 from pool 
14/05/12 21:39:20 INFO DAGScheduler: Stage 5 (take at DStream.scala:586) finished in 0.032 s
14/05/12 21:39:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.183866207 s
14/05/12 21:39:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:39:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 140 bytes
14/05/12 21:39:20 INFO DAGScheduler: Got job 4 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:39:20 INFO DAGScheduler: Final stage: Stage 7 (take at DStream.scala:586)
14/05/12 21:39:20 INFO DAGScheduler: Parents of final stage: List(Stage 8)
14/05/12 21:39:20 INFO DAGScheduler: Missing parents: List()
14/05/12 21:39:20 INFO DAGScheduler: Submitting Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/12 21:39:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/12 21:39:20 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
14/05/12 21:39:20 INFO TaskSetManager: Starting task 7.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
14/05/12 21:39:20 INFO TaskSetManager: Serialized task 7.0:0 as 1563 bytes in 0 ms
14/05/12 21:39:20 INFO Executor: Running task ID 12
14/05/12 21:39:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 6 blocks
14/05/12 21:39:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/12 21:39:20 INFO Executor: Serialized size of result for 12 is 813
14/05/12 21:39:20 INFO Executor: Sending result for 12 directly to driver
14/05/12 21:39:20 INFO Executor: Finished task ID 12
14/05/12 21:39:20 INFO TaskSetManager: Finished TID 12 in 23 ms on localhost (progress: 0/1)
14/05/12 21:39:20 INFO TaskSchedulerImpl: Remove TaskSet 7.0 from pool 
14/05/12 21:39:20 INFO DAGScheduler: Completed ResultTask(7, 1)
14/05/12 21:39:20 INFO DAGScheduler: Stage 7 (take at DStream.scala:586) finished in 0.026 s
14/05/12 21:39:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.046117578 s
14/05/12 21:39:20 INFO JobScheduler: Finished job streaming job 1399910960000 ms.0 from job set of time 1399910960000 ms
14/05/12 21:39:20 INFO JobScheduler: Total delay: 0.269 s for time 1399910960000 ms (execution: 0.246 s)
14/05/12 21:44:43 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/12 21:44:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/12 21:44:44 INFO Slf4jLogger: Slf4jLogger started
14/05/12 21:44:44 INFO Remoting: Starting remoting
14/05/12 21:44:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:43483]
14/05/12 21:44:44 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:43483]
14/05/12 21:44:44 INFO SparkEnv: Registering BlockManagerMaster
14/05/12 21:44:44 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140512214444-0881
14/05/12 21:44:44 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/12 21:44:44 INFO ConnectionManager: Bound socket to port 44953 with id = ConnectionManagerId(ubuntu,44953)
14/05/12 21:44:44 INFO BlockManagerMaster: Trying to register BlockManager
14/05/12 21:44:44 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:44953 with 640.2 MB RAM
14/05/12 21:44:44 INFO BlockManagerMaster: Registered BlockManager
14/05/12 21:44:44 INFO HttpServer: Starting HTTP Server
14/05/12 21:44:44 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:58513
14/05/12 21:44:44 INFO SparkEnv: Registering MapOutputTracker
14/05/12 21:44:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-a2dd163a-f73a-44de-8b59-87046bf7cc93
14/05/12 21:44:44 INFO HttpServer: Starting HTTP Server
14/05/12 21:44:45 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/12 21:44:46 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/12 21:44:46 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/12 21:44:46 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/12 21:44:46 INFO FileInputDStream: Slide time = 10000 ms
14/05/12 21:44:46 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:44:46 INFO FileInputDStream: Checkpoint interval = null
14/05/12 21:44:46 INFO FileInputDStream: Remember duration = 10000 ms
14/05/12 21:44:46 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@708a224d
14/05/12 21:44:46 INFO MappedDStream: Slide time = 10000 ms
14/05/12 21:44:46 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:44:46 INFO MappedDStream: Checkpoint interval = null
14/05/12 21:44:46 INFO MappedDStream: Remember duration = 10000 ms
14/05/12 21:44:46 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@7cd226f3
14/05/12 21:44:46 INFO ForEachDStream: Slide time = 10000 ms
14/05/12 21:44:46 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:44:46 INFO ForEachDStream: Checkpoint interval = null
14/05/12 21:44:46 INFO ForEachDStream: Remember duration = 10000 ms
14/05/12 21:44:46 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@48fb5b8a
14/05/12 21:44:46 INFO JobGenerator: JobGenerator started at 1399911290000 ms
14/05/12 21:44:46 INFO JobScheduler: JobScheduler started
14/05/12 21:44:50 INFO FileInputDStream: Finding new files took 214 ms
14/05/12 21:44:50 INFO FileInputDStream: New files at time 1399911290000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/reads/read.txt
14/05/12 21:44:50 INFO MemoryStore: ensureFreeSpace(33256) called with curMem=0, maxMem=671298355
14/05/12 21:44:50 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/12 21:44:50 INFO FileInputFormat: Total input paths to process : 1
14/05/12 21:44:50 INFO JobScheduler: Added jobs for time 1399911290000 ms
14/05/12 21:44:50 INFO JobScheduler: Starting job streaming job 1399911290000 ms.0 from job set of time 1399911290000 ms
14/05/12 21:44:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:44:50 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:44:50 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/12 21:44:50 INFO DAGScheduler: Parents of final stage: List()
14/05/12 21:44:50 INFO DAGScheduler: Missing parents: List()
14/05/12 21:44:50 INFO DAGScheduler: Computing the requested partition locally
14/05/12 21:44:50 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/reads/read.txt:0+0
14/05/12 21:44:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/12 21:44:50 WARN LoadSnappy: Snappy native library not loaded
14/05/12 21:44:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.141428225 s
14/05/12 21:44:50 INFO JobScheduler: Finished job streaming job 1399911290000 ms.0 from job set of time 1399911290000 ms
14/05/12 21:44:50 INFO JobScheduler: Total delay: 0.696 s for time 1399911290000 ms (execution: 0.169 s)
14/05/12 21:44:50 INFO FileInputDStream: Cleared 0 old files that were older than 1399911280000 ms: 
14/05/12 21:45:00 INFO FileInputDStream: Finding new files took 3 ms
14/05/12 21:45:00 INFO FileInputDStream: New files at time 1399911300000 ms:

14/05/12 21:45:00 INFO JobScheduler: Added jobs for time 1399911300000 ms
14/05/12 21:45:00 INFO JobScheduler: Starting job streaming job 1399911300000 ms.0 from job set of time 1399911300000 ms
14/05/12 21:45:00 INFO JobScheduler: Finished job streaming job 1399911300000 ms.0 from job set of time 1399911300000 ms
14/05/12 21:45:00 INFO FileInputDStream: Cleared 0 old files that were older than 1399911290000 ms: 
14/05/12 21:45:00 INFO JobScheduler: Total delay: 0.014 s for time 1399911300000 ms (execution: 0.001 s)
14/05/12 21:46:54 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/12 21:46:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/12 21:46:55 INFO Slf4jLogger: Slf4jLogger started
14/05/12 21:46:55 INFO Remoting: Starting remoting
14/05/12 21:46:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:54243]
14/05/12 21:46:55 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:54243]
14/05/12 21:46:55 INFO SparkEnv: Registering BlockManagerMaster
14/05/12 21:46:55 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140512214655-0cb1
14/05/12 21:46:55 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/12 21:46:55 INFO ConnectionManager: Bound socket to port 59079 with id = ConnectionManagerId(ubuntu,59079)
14/05/12 21:46:55 INFO BlockManagerMaster: Trying to register BlockManager
14/05/12 21:46:55 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:59079 with 640.2 MB RAM
14/05/12 21:46:55 INFO BlockManagerMaster: Registered BlockManager
14/05/12 21:46:55 INFO HttpServer: Starting HTTP Server
14/05/12 21:46:55 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:51921
14/05/12 21:46:55 INFO SparkEnv: Registering MapOutputTracker
14/05/12 21:46:55 INFO HttpFileServer: HTTP File server directory is /tmp/spark-8a5eedcf-e17b-4db6-b2c5-908d46c4a92c
14/05/12 21:46:55 INFO HttpServer: Starting HTTP Server
14/05/12 21:46:56 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/12 21:46:56 INFO AppClient$ClientActor: Connecting to master spark://localhost:7077...
14/05/12 21:46:57 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:46:57 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:46:57 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:46:57 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:46:58 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/12 21:46:58 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/12 21:46:58 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/12 21:46:58 INFO FileInputDStream: Slide time = 5000 ms
14/05/12 21:46:58 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:46:58 INFO FileInputDStream: Checkpoint interval = null
14/05/12 21:46:58 INFO FileInputDStream: Remember duration = 5000 ms
14/05/12 21:46:58 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@c7627d3
14/05/12 21:46:58 INFO MappedDStream: Slide time = 5000 ms
14/05/12 21:46:58 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:46:58 INFO MappedDStream: Checkpoint interval = null
14/05/12 21:46:58 INFO MappedDStream: Remember duration = 5000 ms
14/05/12 21:46:58 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@21309409
14/05/12 21:46:58 INFO ForEachDStream: Slide time = 5000 ms
14/05/12 21:46:58 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:46:58 INFO ForEachDStream: Checkpoint interval = null
14/05/12 21:46:58 INFO ForEachDStream: Remember duration = 5000 ms
14/05/12 21:46:58 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@7c46ebe4
14/05/12 21:46:58 INFO JobGenerator: JobGenerator started at 1399911420000 ms
14/05/12 21:46:58 INFO JobScheduler: JobScheduler started
14/05/12 21:47:00 INFO FileInputDStream: Finding new files took 95 ms
14/05/12 21:47:00 INFO FileInputDStream: New files at time 1399911420000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/reads/read.txt
14/05/12 21:47:00 INFO MemoryStore: ensureFreeSpace(33256) called with curMem=0, maxMem=671298355
14/05/12 21:47:00 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/12 21:47:00 INFO FileInputFormat: Total input paths to process : 1
14/05/12 21:47:00 INFO JobScheduler: Added jobs for time 1399911420000 ms
14/05/12 21:47:00 INFO JobScheduler: Starting job streaming job 1399911420000 ms.0 from job set of time 1399911420000 ms
14/05/12 21:47:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:47:00 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:47:00 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/12 21:47:00 INFO DAGScheduler: Parents of final stage: List()
14/05/12 21:47:00 INFO DAGScheduler: Missing parents: List()
14/05/12 21:47:00 INFO DAGScheduler: Computing the requested partition locally
14/05/12 21:47:00 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/reads/read.txt:0+0
14/05/12 21:47:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/12 21:47:00 WARN LoadSnappy: Snappy native library not loaded
14/05/12 21:47:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.078389352 s
14/05/12 21:47:00 INFO JobScheduler: Finished job streaming job 1399911420000 ms.0 from job set of time 1399911420000 ms
14/05/12 21:47:00 INFO JobScheduler: Total delay: 0.456 s for time 1399911420000 ms (execution: 0.110 s)
14/05/12 21:47:00 INFO FileInputDStream: Cleared 0 old files that were older than 1399911415000 ms: 
14/05/12 21:47:05 INFO FileInputDStream: Finding new files took 2 ms
14/05/12 21:47:05 INFO FileInputDStream: New files at time 1399911425000 ms:

14/05/12 21:47:05 INFO JobScheduler: Added jobs for time 1399911425000 ms
14/05/12 21:47:05 INFO JobScheduler: Starting job streaming job 1399911425000 ms.0 from job set of time 1399911425000 ms
14/05/12 21:47:05 INFO JobScheduler: Finished job streaming job 1399911425000 ms.0 from job set of time 1399911425000 ms
14/05/12 21:47:05 INFO FileInputDStream: Cleared 0 old files that were older than 1399911420000 ms: 
14/05/12 21:47:05 INFO JobScheduler: Total delay: 0.013 s for time 1399911425000 ms (execution: 0.001 s)
14/05/12 21:47:10 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:47:10 INFO FileInputDStream: New files at time 1399911430000 ms:

14/05/12 21:47:10 INFO JobScheduler: Added jobs for time 1399911430000 ms
14/05/12 21:47:10 INFO JobScheduler: Starting job streaming job 1399911430000 ms.0 from job set of time 1399911430000 ms
14/05/12 21:47:10 INFO JobScheduler: Finished job streaming job 1399911430000 ms.0 from job set of time 1399911430000 ms
14/05/12 21:47:10 INFO JobScheduler: Total delay: 0.021 s for time 1399911430000 ms (execution: 0.001 s)
14/05/12 21:47:10 INFO FileInputDStream: Cleared 1 old files that were older than 1399911425000 ms: 1399911420000 ms
14/05/12 21:47:15 INFO FileInputDStream: Finding new files took 0 ms
14/05/12 21:47:15 INFO FileInputDStream: New files at time 1399911435000 ms:

14/05/12 21:47:15 INFO JobScheduler: Added jobs for time 1399911435000 ms
14/05/12 21:47:15 INFO JobScheduler: Starting job streaming job 1399911435000 ms.0 from job set of time 1399911435000 ms
14/05/12 21:47:15 INFO JobScheduler: Finished job streaming job 1399911435000 ms.0 from job set of time 1399911435000 ms
14/05/12 21:47:15 INFO JobScheduler: Total delay: 0.012 s for time 1399911435000 ms (execution: 0.001 s)
14/05/12 21:47:15 INFO FileInputDStream: Cleared 1 old files that were older than 1399911430000 ms: 1399911425000 ms
14/05/12 21:47:16 INFO AppClient$ClientActor: Connecting to master spark://localhost:7077...
14/05/12 21:47:16 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:47:16 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:47:16 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:47:16 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:47:20 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:47:20 INFO FileInputDStream: New files at time 1399911440000 ms:

14/05/12 21:47:20 INFO JobScheduler: Added jobs for time 1399911440000 ms
14/05/12 21:47:20 INFO JobScheduler: Starting job streaming job 1399911440000 ms.0 from job set of time 1399911440000 ms
14/05/12 21:47:20 INFO JobScheduler: Finished job streaming job 1399911440000 ms.0 from job set of time 1399911440000 ms
14/05/12 21:47:20 INFO JobScheduler: Total delay: 0.010 s for time 1399911440000 ms (execution: 0.000 s)
14/05/12 21:47:20 INFO FileInputDStream: Cleared 1 old files that were older than 1399911435000 ms: 1399911430000 ms
14/05/12 21:47:25 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:47:25 INFO FileInputDStream: New files at time 1399911445000 ms:

14/05/12 21:47:25 INFO JobScheduler: Added jobs for time 1399911445000 ms
14/05/12 21:47:25 INFO JobScheduler: Starting job streaming job 1399911445000 ms.0 from job set of time 1399911445000 ms
14/05/12 21:47:25 INFO JobScheduler: Finished job streaming job 1399911445000 ms.0 from job set of time 1399911445000 ms
14/05/12 21:47:25 INFO JobScheduler: Total delay: 0.011 s for time 1399911445000 ms (execution: 0.000 s)
14/05/12 21:47:25 INFO FileInputDStream: Cleared 1 old files that were older than 1399911440000 ms: 1399911435000 ms
14/05/12 21:47:30 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:47:30 INFO FileInputDStream: New files at time 1399911450000 ms:

14/05/12 21:47:30 INFO JobScheduler: Added jobs for time 1399911450000 ms
14/05/12 21:47:30 INFO JobScheduler: Starting job streaming job 1399911450000 ms.0 from job set of time 1399911450000 ms
14/05/12 21:47:30 INFO JobScheduler: Finished job streaming job 1399911450000 ms.0 from job set of time 1399911450000 ms
14/05/12 21:47:30 INFO JobScheduler: Total delay: 0.017 s for time 1399911450000 ms (execution: 0.001 s)
14/05/12 21:47:30 INFO FileInputDStream: Cleared 1 old files that were older than 1399911445000 ms: 1399911440000 ms
14/05/12 21:48:36 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/12 21:48:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/12 21:48:37 INFO Slf4jLogger: Slf4jLogger started
14/05/12 21:48:37 INFO Remoting: Starting remoting
14/05/12 21:48:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:45601]
14/05/12 21:48:37 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:45601]
14/05/12 21:48:37 INFO SparkEnv: Registering BlockManagerMaster
14/05/12 21:48:37 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140512214837-6757
14/05/12 21:48:37 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/12 21:48:37 INFO ConnectionManager: Bound socket to port 50055 with id = ConnectionManagerId(ubuntu,50055)
14/05/12 21:48:37 INFO BlockManagerMaster: Trying to register BlockManager
14/05/12 21:48:37 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:50055 with 640.2 MB RAM
14/05/12 21:48:37 INFO BlockManagerMaster: Registered BlockManager
14/05/12 21:48:37 INFO HttpServer: Starting HTTP Server
14/05/12 21:48:37 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:52097
14/05/12 21:48:37 INFO SparkEnv: Registering MapOutputTracker
14/05/12 21:48:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-276335bb-42fb-40aa-8b30-5fd142e23266
14/05/12 21:48:37 INFO HttpServer: Starting HTTP Server
14/05/12 21:48:38 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/12 21:48:38 INFO AppClient$ClientActor: Connecting to master spark://localhost:7077...
14/05/12 21:48:38 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:48:38 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:48:38 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:48:38 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:48:39 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/12 21:48:39 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/12 21:48:39 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/12 21:48:39 INFO FileInputDStream: Slide time = 5000 ms
14/05/12 21:48:39 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:48:39 INFO FileInputDStream: Checkpoint interval = null
14/05/12 21:48:39 INFO FileInputDStream: Remember duration = 5000 ms
14/05/12 21:48:39 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@4e089ea3
14/05/12 21:48:39 INFO MappedDStream: Slide time = 5000 ms
14/05/12 21:48:39 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:48:39 INFO MappedDStream: Checkpoint interval = null
14/05/12 21:48:39 INFO MappedDStream: Remember duration = 5000 ms
14/05/12 21:48:39 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@17e7075b
14/05/12 21:48:39 INFO ForEachDStream: Slide time = 5000 ms
14/05/12 21:48:39 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:48:39 INFO ForEachDStream: Checkpoint interval = null
14/05/12 21:48:39 INFO ForEachDStream: Remember duration = 5000 ms
14/05/12 21:48:39 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@4093f39f
14/05/12 21:48:40 INFO JobGenerator: JobGenerator started at 1399911520000 ms
14/05/12 21:48:40 INFO JobScheduler: JobScheduler started
14/05/12 21:48:40 INFO FileInputDStream: Finding new files took 86 ms
14/05/12 21:48:40 INFO FileInputDStream: New files at time 1399911520000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log
14/05/12 21:48:40 INFO MemoryStore: ensureFreeSpace(33264) called with curMem=0, maxMem=671298355
14/05/12 21:48:40 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/12 21:48:40 INFO FileInputFormat: Total input paths to process : 1
14/05/12 21:48:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/12 21:48:40 WARN LoadSnappy: Snappy native library not loaded
14/05/12 21:48:40 INFO JobScheduler: Added jobs for time 1399911520000 ms
14/05/12 21:48:40 INFO JobScheduler: Starting job streaming job 1399911520000 ms.0 from job set of time 1399911520000 ms
14/05/12 21:48:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:48:40 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:48:40 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/12 21:48:40 INFO DAGScheduler: Parents of final stage: List()
14/05/12 21:48:40 INFO DAGScheduler: Missing parents: List()
14/05/12 21:48:40 INFO DAGScheduler: Computing the requested partition locally
14/05/12 21:48:40 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log:0+187296
14/05/12 21:48:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.067759915 s
14/05/12 21:48:40 INFO JobScheduler: Finished job streaming job 1399911520000 ms.0 from job set of time 1399911520000 ms
14/05/12 21:48:40 INFO JobScheduler: Total delay: 0.488 s for time 1399911520000 ms (execution: 0.092 s)
14/05/12 21:48:40 INFO FileInputDStream: Cleared 0 old files that were older than 1399911515000 ms: 
14/05/12 21:48:45 INFO FileInputDStream: Finding new files took 2 ms
14/05/12 21:48:45 INFO FileInputDStream: New files at time 1399911525000 ms:

14/05/12 21:48:45 INFO JobScheduler: Added jobs for time 1399911525000 ms
14/05/12 21:48:45 INFO JobScheduler: Starting job streaming job 1399911525000 ms.0 from job set of time 1399911525000 ms
14/05/12 21:48:45 INFO JobScheduler: Finished job streaming job 1399911525000 ms.0 from job set of time 1399911525000 ms
14/05/12 21:48:45 INFO FileInputDStream: Cleared 0 old files that were older than 1399911520000 ms: 
14/05/12 21:48:45 INFO JobScheduler: Total delay: 0.012 s for time 1399911525000 ms (execution: 0.001 s)
14/05/12 21:48:50 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:48:50 INFO FileInputDStream: New files at time 1399911530000 ms:

14/05/12 21:48:50 INFO JobScheduler: Added jobs for time 1399911530000 ms
14/05/12 21:48:50 INFO JobScheduler: Starting job streaming job 1399911530000 ms.0 from job set of time 1399911530000 ms
14/05/12 21:48:50 INFO JobScheduler: Finished job streaming job 1399911530000 ms.0 from job set of time 1399911530000 ms
14/05/12 21:48:50 INFO JobScheduler: Total delay: 0.011 s for time 1399911530000 ms (execution: 0.000 s)
14/05/12 21:48:50 INFO FileInputDStream: Cleared 1 old files that were older than 1399911525000 ms: 1399911520000 ms
14/05/12 21:48:55 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:48:55 INFO FileInputDStream: New files at time 1399911535000 ms:

14/05/12 21:48:55 INFO JobScheduler: Added jobs for time 1399911535000 ms
14/05/12 21:48:55 INFO JobScheduler: Starting job streaming job 1399911535000 ms.0 from job set of time 1399911535000 ms
14/05/12 21:48:55 INFO JobScheduler: Finished job streaming job 1399911535000 ms.0 from job set of time 1399911535000 ms
14/05/12 21:48:55 INFO JobScheduler: Total delay: 0.011 s for time 1399911535000 ms (execution: 0.000 s)
14/05/12 21:48:55 INFO FileInputDStream: Cleared 1 old files that were older than 1399911530000 ms: 1399911525000 ms
14/05/12 21:48:58 INFO AppClient$ClientActor: Connecting to master spark://localhost:7077...
14/05/12 21:48:58 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:48:58 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:48:58 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:48:58 WARN AppClient$ClientActor: Could not connect to akka.tcp://sparkMaster@localhost:7077: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@localhost:7077]
14/05/12 21:49:00 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:49:00 INFO FileInputDStream: New files at time 1399911540000 ms:

14/05/12 21:49:00 INFO JobScheduler: Added jobs for time 1399911540000 ms
14/05/12 21:49:00 INFO JobScheduler: Starting job streaming job 1399911540000 ms.0 from job set of time 1399911540000 ms
14/05/12 21:49:00 INFO JobScheduler: Finished job streaming job 1399911540000 ms.0 from job set of time 1399911540000 ms
14/05/12 21:49:00 INFO JobScheduler: Total delay: 0.021 s for time 1399911540000 ms (execution: 0.000 s)
14/05/12 21:49:00 INFO FileInputDStream: Cleared 1 old files that were older than 1399911535000 ms: 1399911530000 ms
14/05/12 21:50:25 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/12 21:50:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/12 21:50:26 INFO Slf4jLogger: Slf4jLogger started
14/05/12 21:50:26 INFO Remoting: Starting remoting
14/05/12 21:50:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:39093]
14/05/12 21:50:27 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:39093]
14/05/12 21:50:27 INFO SparkEnv: Registering BlockManagerMaster
14/05/12 21:50:27 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140512215027-1b7c
14/05/12 21:50:27 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/12 21:50:27 INFO ConnectionManager: Bound socket to port 45290 with id = ConnectionManagerId(ubuntu,45290)
14/05/12 21:50:27 INFO BlockManagerMaster: Trying to register BlockManager
14/05/12 21:50:27 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:45290 with 640.2 MB RAM
14/05/12 21:50:27 INFO BlockManagerMaster: Registered BlockManager
14/05/12 21:50:27 INFO HttpServer: Starting HTTP Server
14/05/12 21:50:27 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:56266
14/05/12 21:50:27 INFO SparkEnv: Registering MapOutputTracker
14/05/12 21:50:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-c13daa42-3481-44bf-9dcc-c8d66d3f7c92
14/05/12 21:50:27 INFO HttpServer: Starting HTTP Server
14/05/12 21:50:28 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/12 21:50:28 INFO ConnectionManager: Selector thread was interrupted!
14/05/12 21:51:50 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/12 21:51:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/12 21:51:51 INFO Slf4jLogger: Slf4jLogger started
14/05/12 21:51:51 INFO Remoting: Starting remoting
14/05/12 21:51:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:52547]
14/05/12 21:51:51 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:52547]
14/05/12 21:51:51 INFO SparkEnv: Registering BlockManagerMaster
14/05/12 21:51:51 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140512215151-cd9e
14/05/12 21:51:52 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/12 21:51:52 INFO ConnectionManager: Bound socket to port 42654 with id = ConnectionManagerId(ubuntu,42654)
14/05/12 21:51:52 INFO BlockManagerMaster: Trying to register BlockManager
14/05/12 21:51:52 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:42654 with 640.2 MB RAM
14/05/12 21:51:52 INFO BlockManagerMaster: Registered BlockManager
14/05/12 21:51:52 INFO HttpServer: Starting HTTP Server
14/05/12 21:51:52 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:39990
14/05/12 21:51:52 INFO SparkEnv: Registering MapOutputTracker
14/05/12 21:51:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-5b78f3c9-80bc-4074-b63e-4d2f88f3df07
14/05/12 21:51:52 INFO HttpServer: Starting HTTP Server
14/05/12 21:51:52 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/12 21:51:54 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/12 21:51:54 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/12 21:51:54 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/12 21:51:54 INFO FileInputDStream: Slide time = 5000 ms
14/05/12 21:51:54 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:51:54 INFO FileInputDStream: Checkpoint interval = null
14/05/12 21:51:54 INFO FileInputDStream: Remember duration = 5000 ms
14/05/12 21:51:54 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@5d89ec5c
14/05/12 21:51:54 INFO MappedDStream: Slide time = 5000 ms
14/05/12 21:51:54 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:51:54 INFO MappedDStream: Checkpoint interval = null
14/05/12 21:51:54 INFO MappedDStream: Remember duration = 5000 ms
14/05/12 21:51:54 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@9fcbbfe
14/05/12 21:51:54 INFO ForEachDStream: Slide time = 5000 ms
14/05/12 21:51:54 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:51:54 INFO ForEachDStream: Checkpoint interval = null
14/05/12 21:51:54 INFO ForEachDStream: Remember duration = 5000 ms
14/05/12 21:51:54 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@2f9a25d1
14/05/12 21:51:54 INFO JobGenerator: JobGenerator started at 1399911715000 ms
14/05/12 21:51:54 INFO JobScheduler: JobScheduler started
14/05/12 21:51:55 INFO FileInputDStream: Finding new files took 102 ms
14/05/12 21:51:55 INFO FileInputDStream: New files at time 1399911715000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log
14/05/12 21:51:55 INFO MemoryStore: ensureFreeSpace(33264) called with curMem=0, maxMem=671298355
14/05/12 21:51:55 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/12 21:51:55 INFO FileInputFormat: Total input paths to process : 1
14/05/12 21:51:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/12 21:51:55 WARN LoadSnappy: Snappy native library not loaded
14/05/12 21:51:55 INFO JobScheduler: Added jobs for time 1399911715000 ms
14/05/12 21:51:55 INFO JobScheduler: Starting job streaming job 1399911715000 ms.0 from job set of time 1399911715000 ms
14/05/12 21:51:55 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:51:55 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:51:55 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/12 21:51:55 INFO DAGScheduler: Parents of final stage: List()
14/05/12 21:51:55 INFO DAGScheduler: Missing parents: List()
14/05/12 21:51:55 INFO DAGScheduler: Computing the requested partition locally
14/05/12 21:51:55 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log:0+187296
14/05/12 21:51:55 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.071131843 s
14/05/12 21:51:55 INFO JobScheduler: Finished job streaming job 1399911715000 ms.0 from job set of time 1399911715000 ms
14/05/12 21:51:55 INFO JobScheduler: Total delay: 0.435 s for time 1399911715000 ms (execution: 0.101 s)
14/05/12 21:51:55 INFO FileInputDStream: Cleared 0 old files that were older than 1399911710000 ms: 
14/05/12 21:52:00 INFO FileInputDStream: Finding new files took 2 ms
14/05/12 21:52:00 INFO FileInputDStream: New files at time 1399911720000 ms:

14/05/12 21:52:00 INFO JobScheduler: Added jobs for time 1399911720000 ms
14/05/12 21:52:00 INFO JobScheduler: Starting job streaming job 1399911720000 ms.0 from job set of time 1399911720000 ms
14/05/12 21:52:00 INFO JobScheduler: Finished job streaming job 1399911720000 ms.0 from job set of time 1399911720000 ms
14/05/12 21:52:00 INFO FileInputDStream: Cleared 0 old files that were older than 1399911715000 ms: 
14/05/12 21:52:00 INFO JobScheduler: Total delay: 0.012 s for time 1399911720000 ms (execution: 0.001 s)
14/05/12 21:52:05 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:52:05 INFO FileInputDStream: New files at time 1399911725000 ms:

14/05/12 21:52:05 INFO JobScheduler: Added jobs for time 1399911725000 ms
14/05/12 21:52:05 INFO JobScheduler: Starting job streaming job 1399911725000 ms.0 from job set of time 1399911725000 ms
14/05/12 21:52:05 INFO JobScheduler: Finished job streaming job 1399911725000 ms.0 from job set of time 1399911725000 ms
14/05/12 21:52:05 INFO JobScheduler: Total delay: 0.011 s for time 1399911725000 ms (execution: 0.000 s)
14/05/12 21:52:05 INFO FileInputDStream: Cleared 1 old files that were older than 1399911720000 ms: 1399911715000 ms
14/05/12 21:52:10 INFO FileInputDStream: Finding new files took 0 ms
14/05/12 21:52:10 INFO FileInputDStream: New files at time 1399911730000 ms:

14/05/12 21:52:10 INFO JobScheduler: Added jobs for time 1399911730000 ms
14/05/12 21:52:10 INFO JobScheduler: Starting job streaming job 1399911730000 ms.0 from job set of time 1399911730000 ms
14/05/12 21:52:10 INFO JobScheduler: Finished job streaming job 1399911730000 ms.0 from job set of time 1399911730000 ms
14/05/12 21:52:10 INFO JobScheduler: Total delay: 0.014 s for time 1399911730000 ms (execution: 0.001 s)
14/05/12 21:52:10 INFO FileInputDStream: Cleared 1 old files that were older than 1399911725000 ms: 1399911720000 ms
14/05/12 21:52:15 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:52:15 INFO FileInputDStream: New files at time 1399911735000 ms:

14/05/12 21:52:15 INFO JobScheduler: Added jobs for time 1399911735000 ms
14/05/12 21:52:15 INFO JobScheduler: Starting job streaming job 1399911735000 ms.0 from job set of time 1399911735000 ms
14/05/12 21:52:15 INFO JobScheduler: Finished job streaming job 1399911735000 ms.0 from job set of time 1399911735000 ms
14/05/12 21:52:15 INFO JobScheduler: Total delay: 0.010 s for time 1399911735000 ms (execution: 0.000 s)
14/05/12 21:52:15 INFO FileInputDStream: Cleared 1 old files that were older than 1399911730000 ms: 1399911725000 ms
14/05/12 21:52:20 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:52:20 INFO FileInputDStream: New files at time 1399911740000 ms:

14/05/12 21:52:20 INFO JobScheduler: Added jobs for time 1399911740000 ms
14/05/12 21:52:20 INFO JobScheduler: Starting job streaming job 1399911740000 ms.0 from job set of time 1399911740000 ms
14/05/12 21:52:20 INFO JobScheduler: Finished job streaming job 1399911740000 ms.0 from job set of time 1399911740000 ms
14/05/12 21:52:20 INFO JobScheduler: Total delay: 0.012 s for time 1399911740000 ms (execution: 0.000 s)
14/05/12 21:52:20 INFO FileInputDStream: Cleared 1 old files that were older than 1399911735000 ms: 1399911730000 ms
14/05/12 21:52:25 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:52:25 INFO FileInputDStream: New files at time 1399911745000 ms:

14/05/12 21:52:25 INFO JobScheduler: Added jobs for time 1399911745000 ms
14/05/12 21:52:25 INFO JobScheduler: Starting job streaming job 1399911745000 ms.0 from job set of time 1399911745000 ms
14/05/12 21:52:25 INFO JobScheduler: Finished job streaming job 1399911745000 ms.0 from job set of time 1399911745000 ms
14/05/12 21:52:25 INFO JobScheduler: Total delay: 0.013 s for time 1399911745000 ms (execution: 0.000 s)
14/05/12 21:52:25 INFO FileInputDStream: Cleared 1 old files that were older than 1399911740000 ms: 1399911735000 ms
14/05/12 21:52:30 INFO FileInputDStream: Finding new files took 0 ms
14/05/12 21:52:30 INFO FileInputDStream: New files at time 1399911750000 ms:

14/05/12 21:52:30 INFO JobScheduler: Added jobs for time 1399911750000 ms
14/05/12 21:52:30 INFO JobScheduler: Starting job streaming job 1399911750000 ms.0 from job set of time 1399911750000 ms
14/05/12 21:52:30 INFO JobScheduler: Finished job streaming job 1399911750000 ms.0 from job set of time 1399911750000 ms
14/05/12 21:52:30 INFO JobScheduler: Total delay: 0.014 s for time 1399911750000 ms (execution: 0.001 s)
14/05/12 21:52:30 INFO FileInputDStream: Cleared 1 old files that were older than 1399911745000 ms: 1399911740000 ms
14/05/12 21:52:35 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:52:35 INFO FileInputDStream: New files at time 1399911755000 ms:

14/05/12 21:52:35 INFO JobScheduler: Added jobs for time 1399911755000 ms
14/05/12 21:52:35 INFO JobScheduler: Starting job streaming job 1399911755000 ms.0 from job set of time 1399911755000 ms
14/05/12 21:52:35 INFO JobScheduler: Finished job streaming job 1399911755000 ms.0 from job set of time 1399911755000 ms
14/05/12 21:52:35 INFO JobScheduler: Total delay: 0.006 s for time 1399911755000 ms (execution: 0.000 s)
14/05/12 21:52:35 INFO FileInputDStream: Cleared 1 old files that were older than 1399911750000 ms: 1399911745000 ms
14/05/12 21:52:40 INFO FileInputDStream: Finding new files took 0 ms
14/05/12 21:52:40 INFO FileInputDStream: New files at time 1399911760000 ms:

14/05/12 21:52:40 INFO JobScheduler: Added jobs for time 1399911760000 ms
14/05/12 21:52:40 INFO JobScheduler: Starting job streaming job 1399911760000 ms.0 from job set of time 1399911760000 ms
14/05/12 21:52:40 INFO JobScheduler: Finished job streaming job 1399911760000 ms.0 from job set of time 1399911760000 ms
14/05/12 21:52:40 INFO JobScheduler: Total delay: 0.013 s for time 1399911760000 ms (execution: 0.000 s)
14/05/12 21:52:40 INFO FileInputDStream: Cleared 1 old files that were older than 1399911755000 ms: 1399911750000 ms
14/05/12 21:52:45 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:52:45 INFO FileInputDStream: New files at time 1399911765000 ms:

14/05/12 21:52:45 INFO JobScheduler: Added jobs for time 1399911765000 ms
14/05/12 21:52:45 INFO JobScheduler: Starting job streaming job 1399911765000 ms.0 from job set of time 1399911765000 ms
14/05/12 21:52:45 INFO JobScheduler: Finished job streaming job 1399911765000 ms.0 from job set of time 1399911765000 ms
14/05/12 21:52:45 INFO JobScheduler: Total delay: 0.016 s for time 1399911765000 ms (execution: 0.000 s)
14/05/12 21:52:45 INFO FileInputDStream: Cleared 1 old files that were older than 1399911760000 ms: 1399911755000 ms
14/05/12 21:52:50 INFO FileInputDStream: Finding new files took 0 ms
14/05/12 21:52:50 INFO FileInputDStream: New files at time 1399911770000 ms:

14/05/12 21:52:50 INFO JobScheduler: Added jobs for time 1399911770000 ms
14/05/12 21:52:50 INFO JobScheduler: Starting job streaming job 1399911770000 ms.0 from job set of time 1399911770000 ms
14/05/12 21:52:50 INFO JobScheduler: Finished job streaming job 1399911770000 ms.0 from job set of time 1399911770000 ms
14/05/12 21:52:50 INFO JobScheduler: Total delay: 0.012 s for time 1399911770000 ms (execution: 0.000 s)
14/05/12 21:52:50 INFO FileInputDStream: Cleared 1 old files that were older than 1399911765000 ms: 1399911760000 ms
14/05/12 21:52:55 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:52:55 INFO FileInputDStream: New files at time 1399911775000 ms:

14/05/12 21:52:55 INFO JobScheduler: Added jobs for time 1399911775000 ms
14/05/12 21:52:55 INFO JobScheduler: Starting job streaming job 1399911775000 ms.0 from job set of time 1399911775000 ms
14/05/12 21:52:55 INFO JobScheduler: Finished job streaming job 1399911775000 ms.0 from job set of time 1399911775000 ms
14/05/12 21:52:55 INFO JobScheduler: Total delay: 0.011 s for time 1399911775000 ms (execution: 0.000 s)
14/05/12 21:52:55 INFO FileInputDStream: Cleared 1 old files that were older than 1399911770000 ms: 1399911765000 ms
14/05/12 21:53:00 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:53:00 INFO FileInputDStream: New files at time 1399911780000 ms:

14/05/12 21:53:00 INFO JobScheduler: Added jobs for time 1399911780000 ms
14/05/12 21:53:00 INFO JobScheduler: Starting job streaming job 1399911780000 ms.0 from job set of time 1399911780000 ms
14/05/12 21:53:00 INFO JobScheduler: Finished job streaming job 1399911780000 ms.0 from job set of time 1399911780000 ms
14/05/12 21:53:00 INFO FileInputDStream: Cleared 1 old files that were older than 1399911775000 ms: 1399911770000 ms
14/05/12 21:53:00 INFO JobScheduler: Total delay: 0.026 s for time 1399911780000 ms (execution: 0.001 s)
14/05/12 21:53:05 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:53:05 INFO FileInputDStream: New files at time 1399911785000 ms:

14/05/12 21:53:05 INFO JobScheduler: Added jobs for time 1399911785000 ms
14/05/12 21:53:05 INFO JobScheduler: Starting job streaming job 1399911785000 ms.0 from job set of time 1399911785000 ms
14/05/12 21:53:05 INFO JobScheduler: Finished job streaming job 1399911785000 ms.0 from job set of time 1399911785000 ms
14/05/12 21:53:05 INFO JobScheduler: Total delay: 0.013 s for time 1399911785000 ms (execution: 0.000 s)
14/05/12 21:53:05 INFO FileInputDStream: Cleared 1 old files that were older than 1399911780000 ms: 1399911775000 ms
14/05/12 21:54:26 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/12 21:54:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/12 21:54:27 INFO Slf4jLogger: Slf4jLogger started
14/05/12 21:54:27 INFO Remoting: Starting remoting
14/05/12 21:54:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:32937]
14/05/12 21:54:27 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:32937]
14/05/12 21:54:27 INFO SparkEnv: Registering BlockManagerMaster
14/05/12 21:54:27 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140512215427-4be6
14/05/12 21:54:27 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/12 21:54:28 INFO ConnectionManager: Bound socket to port 51642 with id = ConnectionManagerId(ubuntu,51642)
14/05/12 21:54:28 INFO BlockManagerMaster: Trying to register BlockManager
14/05/12 21:54:28 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:51642 with 640.2 MB RAM
14/05/12 21:54:28 INFO BlockManagerMaster: Registered BlockManager
14/05/12 21:54:28 INFO HttpServer: Starting HTTP Server
14/05/12 21:54:28 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:56993
14/05/12 21:54:28 INFO SparkEnv: Registering MapOutputTracker
14/05/12 21:54:28 INFO HttpFileServer: HTTP File server directory is /tmp/spark-b490ac52-8c3d-43f6-b43b-64fe79299612
14/05/12 21:54:28 INFO HttpServer: Starting HTTP Server
14/05/12 21:54:28 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/12 21:54:30 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/12 21:54:30 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/12 21:54:30 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/12 21:54:30 INFO FileInputDStream: Slide time = 5000 ms
14/05/12 21:54:30 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:54:30 INFO FileInputDStream: Checkpoint interval = null
14/05/12 21:54:30 INFO FileInputDStream: Remember duration = 5000 ms
14/05/12 21:54:30 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@7e024652
14/05/12 21:54:30 INFO MappedDStream: Slide time = 5000 ms
14/05/12 21:54:30 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:54:30 INFO MappedDStream: Checkpoint interval = null
14/05/12 21:54:30 INFO MappedDStream: Remember duration = 5000 ms
14/05/12 21:54:30 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@4756f21f
14/05/12 21:54:30 INFO ForEachDStream: Slide time = 5000 ms
14/05/12 21:54:30 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/12 21:54:30 INFO ForEachDStream: Checkpoint interval = null
14/05/12 21:54:30 INFO ForEachDStream: Remember duration = 5000 ms
14/05/12 21:54:30 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@1d31f5d0
14/05/12 21:54:30 INFO JobGenerator: JobGenerator started at 1399911875000 ms
14/05/12 21:54:30 INFO JobScheduler: JobScheduler started
14/05/12 21:54:35 INFO FileInputDStream: Finding new files took 108 ms
14/05/12 21:54:35 INFO FileInputDStream: New files at time 1399911875000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log
14/05/12 21:54:35 INFO MemoryStore: ensureFreeSpace(33264) called with curMem=0, maxMem=671298355
14/05/12 21:54:35 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/12 21:54:35 INFO FileInputFormat: Total input paths to process : 1
14/05/12 21:54:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/12 21:54:35 WARN LoadSnappy: Snappy native library not loaded
14/05/12 21:54:35 INFO JobScheduler: Added jobs for time 1399911875000 ms
14/05/12 21:54:35 INFO JobScheduler: Starting job streaming job 1399911875000 ms.0 from job set of time 1399911875000 ms
14/05/12 21:54:35 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/12 21:54:35 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/12 21:54:35 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/12 21:54:35 INFO DAGScheduler: Parents of final stage: List()
14/05/12 21:54:35 INFO DAGScheduler: Missing parents: List()
14/05/12 21:54:35 INFO DAGScheduler: Computing the requested partition locally
14/05/12 21:54:35 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log:0+187296
14/05/12 21:54:35 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.065074402 s
14/05/12 21:54:35 INFO JobScheduler: Finished job streaming job 1399911875000 ms.0 from job set of time 1399911875000 ms
14/05/12 21:54:35 INFO JobScheduler: Total delay: 0.441 s for time 1399911875000 ms (execution: 0.103 s)
14/05/12 21:54:35 INFO FileInputDStream: Cleared 0 old files that were older than 1399911870000 ms: 
14/05/12 21:54:40 INFO FileInputDStream: Finding new files took 2 ms
14/05/12 21:54:40 INFO FileInputDStream: New files at time 1399911880000 ms:

14/05/12 21:54:40 INFO JobScheduler: Added jobs for time 1399911880000 ms
14/05/12 21:54:40 INFO JobScheduler: Starting job streaming job 1399911880000 ms.0 from job set of time 1399911880000 ms
14/05/12 21:54:40 INFO JobScheduler: Finished job streaming job 1399911880000 ms.0 from job set of time 1399911880000 ms
14/05/12 21:54:40 INFO FileInputDStream: Cleared 0 old files that were older than 1399911875000 ms: 
14/05/12 21:54:40 INFO JobScheduler: Total delay: 0.013 s for time 1399911880000 ms (execution: 0.001 s)
14/05/12 21:54:45 INFO FileInputDStream: Finding new files took 0 ms
14/05/12 21:54:45 INFO FileInputDStream: New files at time 1399911885000 ms:

14/05/12 21:54:45 INFO JobScheduler: Added jobs for time 1399911885000 ms
14/05/12 21:54:45 INFO JobScheduler: Starting job streaming job 1399911885000 ms.0 from job set of time 1399911885000 ms
14/05/12 21:54:45 INFO JobScheduler: Finished job streaming job 1399911885000 ms.0 from job set of time 1399911885000 ms
14/05/12 21:54:45 INFO JobScheduler: Total delay: 0.010 s for time 1399911885000 ms (execution: 0.001 s)
14/05/12 21:54:45 INFO FileInputDStream: Cleared 1 old files that were older than 1399911880000 ms: 1399911875000 ms
14/05/12 21:54:50 INFO FileInputDStream: Finding new files took 0 ms
14/05/12 21:54:50 INFO FileInputDStream: New files at time 1399911890000 ms:

14/05/12 21:54:50 INFO JobScheduler: Added jobs for time 1399911890000 ms
14/05/12 21:54:50 INFO JobScheduler: Starting job streaming job 1399911890000 ms.0 from job set of time 1399911890000 ms
14/05/12 21:54:50 INFO JobScheduler: Finished job streaming job 1399911890000 ms.0 from job set of time 1399911890000 ms
14/05/12 21:54:50 INFO JobScheduler: Total delay: 0.012 s for time 1399911890000 ms (execution: 0.001 s)
14/05/12 21:54:50 INFO FileInputDStream: Cleared 1 old files that were older than 1399911885000 ms: 1399911880000 ms
14/05/12 21:54:55 INFO FileInputDStream: Finding new files took 1 ms
14/05/12 21:54:55 INFO FileInputDStream: New files at time 1399911895000 ms:

14/05/12 21:54:55 INFO JobScheduler: Added jobs for time 1399911895000 ms
14/05/12 21:54:55 INFO JobScheduler: Starting job streaming job 1399911895000 ms.0 from job set of time 1399911895000 ms
14/05/12 21:54:55 INFO JobScheduler: Finished job streaming job 1399911895000 ms.0 from job set of time 1399911895000 ms
14/05/12 21:54:55 INFO JobScheduler: Total delay: 0.013 s for time 1399911895000 ms (execution: 0.001 s)
14/05/12 21:54:55 INFO FileInputDStream: Cleared 1 old files that were older than 1399911890000 ms: 1399911885000 ms
14/05/13 13:44:26 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/13 13:44:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 13:44:27 INFO Slf4jLogger: Slf4jLogger started
14/05/13 13:44:28 INFO Remoting: Starting remoting
14/05/13 13:44:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:51840]
14/05/13 13:44:28 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:51840]
14/05/13 13:44:28 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 13:44:28 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513134428-e281
14/05/13 13:44:28 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 13:44:28 INFO ConnectionManager: Bound socket to port 47626 with id = ConnectionManagerId(ubuntu,47626)
14/05/13 13:44:28 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 13:44:28 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:47626 with 640.2 MB RAM
14/05/13 13:44:28 INFO BlockManagerMaster: Registered BlockManager
14/05/13 13:44:28 INFO HttpServer: Starting HTTP Server
14/05/13 13:44:29 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:47025
14/05/13 13:44:29 INFO SparkEnv: Registering MapOutputTracker
14/05/13 13:44:29 INFO HttpFileServer: HTTP File server directory is /tmp/spark-f082bd70-1d93-4335-bcd6-a3f1eb75a735
14/05/13 13:44:29 INFO HttpServer: Starting HTTP Server
14/05/13 13:44:29 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/13 13:44:30 INFO NetworkInputTracker: NetworkInputTracker started
14/05/13 13:44:30 INFO SparkContext: Starting job: runJob at NetworkInputTracker.scala:182
14/05/13 13:44:30 INFO DAGScheduler: Got job 0 (runJob at NetworkInputTracker.scala:182) with 1 output partitions (allowLocal=false)
14/05/13 13:44:30 INFO DAGScheduler: Final stage: Stage 0 (runJob at NetworkInputTracker.scala:182)
14/05/13 13:44:30 INFO DAGScheduler: Parents of final stage: List()
14/05/13 13:44:30 INFO DAGScheduler: Missing parents: List()
14/05/13 13:44:30 INFO DAGScheduler: Submitting Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165), which has no missing parents
14/05/13 13:44:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165)
14/05/13 13:44:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
14/05/13 13:44:30 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:30 INFO TaskSetManager: Serialized task 0.0:0 as 1978 bytes in 29 ms
14/05/13 13:44:30 INFO Executor: Running task ID 0
14/05/13 13:44:31 INFO SocketReceiver: Connecting to localhost:9999
14/05/13 13:44:31 INFO SocketReceiver: Attempting to register with tracker
14/05/13 13:44:31 INFO SocketReceiver: Connected to localhost:9999
14/05/13 13:44:31 INFO NetworkReceiver$BlockGenerator: Block pushing thread started
14/05/13 13:44:31 INFO NetworkReceiver$BlockGenerator: Data handler started
14/05/13 13:44:31 INFO NetworkInputTracker: Registered receiver for network stream 0 from akka://spark
14/05/13 13:44:31 INFO MemoryStore: ensureFreeSpace(20) called with curMem=0, maxMem=671298355
14/05/13 13:44:31 INFO MemoryStore: Block input-0-1399968871000 stored as bytes to memory (size 20.0 B, free 640.2 MB)
14/05/13 13:44:31 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399968871000 in memory on ubuntu:47626 (size: 20.0 B, free: 640.2 MB)
14/05/13 13:44:31 INFO BlockManagerMaster: Updated info of block input-0-1399968871000
14/05/13 13:44:31 INFO SendingConnection: Initiating connection to [ubuntu/127.0.1.1:47626]
14/05/13 13:44:31 INFO SendingConnection: Connected to [ubuntu/127.0.1.1:47626], 1 messages pending
14/05/13 13:44:31 INFO ConnectionManager: Accepted connection from [localhost/127.0.0.1]
14/05/13 13:44:31 WARN BlockManager: Block input-0-1399968871000 already exists on this machine; not re-adding it
14/05/13 13:44:31 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 13:44:31 INFO ShuffledDStream: metadataCleanupDelay = 3600
14/05/13 13:44:31 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 13:44:31 INFO FlatMappedDStream: metadataCleanupDelay = 3600
14/05/13 13:44:31 INFO SocketInputDStream: metadataCleanupDelay = 3600
14/05/13 13:44:31 INFO SocketInputDStream: Slide time = 10000 ms
14/05/13 13:44:31 INFO SocketInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:44:31 INFO SocketInputDStream: Checkpoint interval = null
14/05/13 13:44:31 INFO SocketInputDStream: Remember duration = 10000 ms
14/05/13 13:44:31 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@3a19a503
14/05/13 13:44:31 INFO FlatMappedDStream: Slide time = 10000 ms
14/05/13 13:44:31 INFO FlatMappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:44:31 INFO FlatMappedDStream: Checkpoint interval = null
14/05/13 13:44:31 INFO FlatMappedDStream: Remember duration = 10000 ms
14/05/13 13:44:31 INFO FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@69a085c1
14/05/13 13:44:31 INFO MappedDStream: Slide time = 10000 ms
14/05/13 13:44:31 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:44:31 INFO MappedDStream: Checkpoint interval = null
14/05/13 13:44:31 INFO MappedDStream: Remember duration = 10000 ms
14/05/13 13:44:31 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@29ad7814
14/05/13 13:44:31 INFO ShuffledDStream: Slide time = 10000 ms
14/05/13 13:44:31 INFO ShuffledDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:44:31 INFO ShuffledDStream: Checkpoint interval = null
14/05/13 13:44:31 INFO ShuffledDStream: Remember duration = 10000 ms
14/05/13 13:44:31 INFO ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@3ba67e6c
14/05/13 13:44:31 INFO ForEachDStream: Slide time = 10000 ms
14/05/13 13:44:31 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:44:31 INFO ForEachDStream: Checkpoint interval = null
14/05/13 13:44:31 INFO ForEachDStream: Remember duration = 10000 ms
14/05/13 13:44:31 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@2fb6030c
14/05/13 13:44:31 INFO JobGenerator: JobGenerator started at 1399968880000 ms
14/05/13 13:44:31 INFO JobScheduler: JobScheduler started
14/05/13 13:44:31 INFO MemoryStore: ensureFreeSpace(8) called with curMem=20, maxMem=671298355
14/05/13 13:44:31 INFO MemoryStore: Block input-0-1399968871600 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/13 13:44:31 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399968871600 in memory on ubuntu:47626 (size: 8.0 B, free: 640.2 MB)
14/05/13 13:44:31 INFO BlockManagerMaster: Updated info of block input-0-1399968871600
14/05/13 13:44:31 WARN BlockManager: Block input-0-1399968871600 already exists on this machine; not re-adding it
14/05/13 13:44:32 INFO MemoryStore: ensureFreeSpace(8) called with curMem=28, maxMem=671298355
14/05/13 13:44:32 INFO MemoryStore: Block input-0-1399968872400 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/13 13:44:32 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399968872400 in memory on ubuntu:47626 (size: 8.0 B, free: 640.2 MB)
14/05/13 13:44:32 INFO BlockManagerMaster: Updated info of block input-0-1399968872400
14/05/13 13:44:32 WARN BlockManager: Block input-0-1399968872400 already exists on this machine; not re-adding it
14/05/13 13:44:33 INFO MemoryStore: ensureFreeSpace(8) called with curMem=36, maxMem=671298355
14/05/13 13:44:33 INFO MemoryStore: Block input-0-1399968872800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/13 13:44:33 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399968872800 in memory on ubuntu:47626 (size: 8.0 B, free: 640.2 MB)
14/05/13 13:44:33 INFO BlockManagerMaster: Updated info of block input-0-1399968872800
14/05/13 13:44:33 WARN BlockManager: Block input-0-1399968872800 already exists on this machine; not re-adding it
14/05/13 13:44:33 INFO MemoryStore: ensureFreeSpace(8) called with curMem=44, maxMem=671298355
14/05/13 13:44:33 INFO MemoryStore: Block input-0-1399968873200 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/13 13:44:33 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399968873200 in memory on ubuntu:47626 (size: 8.0 B, free: 640.2 MB)
14/05/13 13:44:33 INFO BlockManagerMaster: Updated info of block input-0-1399968873200
14/05/13 13:44:33 WARN BlockManager: Block input-0-1399968873200 already exists on this machine; not re-adding it
14/05/13 13:44:34 INFO MemoryStore: ensureFreeSpace(8) called with curMem=52, maxMem=671298355
14/05/13 13:44:34 INFO MemoryStore: Block input-0-1399968873800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/13 13:44:34 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399968873800 in memory on ubuntu:47626 (size: 8.0 B, free: 640.2 MB)
14/05/13 13:44:34 INFO BlockManagerMaster: Updated info of block input-0-1399968873800
14/05/13 13:44:34 WARN BlockManager: Block input-0-1399968873800 already exists on this machine; not re-adding it
14/05/13 13:44:40 INFO NetworkInputTracker: Stream 0 received 6 blocks
14/05/13 13:44:40 INFO JobScheduler: Added jobs for time 1399968880000 ms
14/05/13 13:44:40 INFO JobScheduler: Starting job streaming job 1399968880000 ms.0 from job set of time 1399968880000 ms
14/05/13 13:44:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:44:40 INFO DAGScheduler: Registering RDD 4 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:44:40 INFO DAGScheduler: Got job 1 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:44:40 INFO DAGScheduler: Final stage: Stage 1 (take at DStream.scala:586)
14/05/13 13:44:40 INFO DAGScheduler: Parents of final stage: List(Stage 2)
14/05/13 13:44:40 INFO DAGScheduler: Missing parents: List(Stage 2)
14/05/13 13:44:40 INFO DAGScheduler: Submitting Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:44:40 INFO DAGScheduler: Submitting 6 missing tasks from Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:44:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 6 tasks
14/05/13 13:44:40 INFO TaskSetManager: Starting task 2.0:0 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:40 INFO TaskSetManager: Serialized task 2.0:0 as 1517 bytes in 1 ms
14/05/13 13:44:40 INFO Executor: Running task ID 1
14/05/13 13:44:40 INFO BlockManager: Found block input-0-1399968871000 locally
14/05/13 13:44:40 INFO Executor: Serialized size of result for 1 is 743
14/05/13 13:44:40 INFO Executor: Sending result for 1 directly to driver
14/05/13 13:44:40 INFO Executor: Finished task ID 1
14/05/13 13:44:40 INFO TaskSetManager: Starting task 2.0:1 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:40 INFO TaskSetManager: Serialized task 2.0:1 as 1517 bytes in 0 ms
14/05/13 13:44:40 INFO Executor: Running task ID 2
14/05/13 13:44:40 INFO TaskSetManager: Finished TID 1 in 321 ms on localhost (progress: 0/6)
14/05/13 13:44:40 INFO DAGScheduler: Completed ShuffleMapTask(2, 0)
14/05/13 13:44:40 INFO BlockManager: Found block input-0-1399968871600 locally
14/05/13 13:44:40 INFO Executor: Serialized size of result for 2 is 743
14/05/13 13:44:40 INFO Executor: Sending result for 2 directly to driver
14/05/13 13:44:40 INFO Executor: Finished task ID 2
14/05/13 13:44:40 INFO TaskSetManager: Starting task 2.0:2 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:40 INFO TaskSetManager: Serialized task 2.0:2 as 1517 bytes in 0 ms
14/05/13 13:44:40 INFO Executor: Running task ID 3
14/05/13 13:44:40 INFO TaskSetManager: Finished TID 2 in 21 ms on localhost (progress: 1/6)
14/05/13 13:44:40 INFO DAGScheduler: Completed ShuffleMapTask(2, 1)
14/05/13 13:44:40 INFO BlockManager: Found block input-0-1399968872400 locally
14/05/13 13:44:40 INFO Executor: Serialized size of result for 3 is 743
14/05/13 13:44:40 INFO Executor: Sending result for 3 directly to driver
14/05/13 13:44:40 INFO Executor: Finished task ID 3
14/05/13 13:44:40 INFO TaskSetManager: Starting task 2.0:3 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:40 INFO TaskSetManager: Serialized task 2.0:3 as 1517 bytes in 1 ms
14/05/13 13:44:40 INFO Executor: Running task ID 4
14/05/13 13:44:40 INFO TaskSetManager: Finished TID 3 in 23 ms on localhost (progress: 2/6)
14/05/13 13:44:40 INFO DAGScheduler: Completed ShuffleMapTask(2, 2)
14/05/13 13:44:40 INFO BlockManager: Found block input-0-1399968872800 locally
14/05/13 13:44:40 INFO Executor: Serialized size of result for 4 is 743
14/05/13 13:44:40 INFO Executor: Sending result for 4 directly to driver
14/05/13 13:44:40 INFO Executor: Finished task ID 4
14/05/13 13:44:40 INFO TaskSetManager: Starting task 2.0:4 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:40 INFO TaskSetManager: Serialized task 2.0:4 as 1517 bytes in 1 ms
14/05/13 13:44:40 INFO Executor: Running task ID 5
14/05/13 13:44:40 INFO TaskSetManager: Finished TID 4 in 20 ms on localhost (progress: 3/6)
14/05/13 13:44:40 INFO DAGScheduler: Completed ShuffleMapTask(2, 3)
14/05/13 13:44:40 INFO BlockManager: Found block input-0-1399968873200 locally
14/05/13 13:44:40 INFO Executor: Serialized size of result for 5 is 743
14/05/13 13:44:40 INFO Executor: Sending result for 5 directly to driver
14/05/13 13:44:40 INFO Executor: Finished task ID 5
14/05/13 13:44:40 INFO TaskSetManager: Starting task 2.0:5 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:40 INFO TaskSetManager: Serialized task 2.0:5 as 1517 bytes in 1 ms
14/05/13 13:44:40 INFO Executor: Running task ID 6
14/05/13 13:44:40 INFO TaskSetManager: Finished TID 5 in 20 ms on localhost (progress: 4/6)
14/05/13 13:44:40 INFO DAGScheduler: Completed ShuffleMapTask(2, 4)
14/05/13 13:44:40 INFO BlockManager: Found block input-0-1399968873800 locally
14/05/13 13:44:40 INFO Executor: Serialized size of result for 6 is 743
14/05/13 13:44:40 INFO Executor: Sending result for 6 directly to driver
14/05/13 13:44:40 INFO Executor: Finished task ID 6
14/05/13 13:44:40 INFO TaskSetManager: Finished TID 6 in 25 ms on localhost (progress: 5/6)
14/05/13 13:44:40 INFO TaskSchedulerImpl: Remove TaskSet 2.0 from pool 
14/05/13 13:44:40 INFO DAGScheduler: Completed ShuffleMapTask(2, 5)
14/05/13 13:44:40 INFO DAGScheduler: Stage 2 (combineByKey at ShuffledDStream.scala:42) finished in 0.422 s
14/05/13 13:44:40 INFO DAGScheduler: looking for newly runnable stages
14/05/13 13:44:40 INFO DAGScheduler: running: Set(Stage 0)
14/05/13 13:44:40 INFO DAGScheduler: waiting: Set(Stage 1)
14/05/13 13:44:40 INFO DAGScheduler: failed: Set()
14/05/13 13:44:40 INFO DAGScheduler: Missing parents for Stage 1: List()
14/05/13 13:44:40 INFO DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/13 13:44:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:44:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
14/05/13 13:44:40 INFO TaskSetManager: Starting task 1.0:0 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:40 INFO TaskSetManager: Serialized task 1.0:0 as 1562 bytes in 0 ms
14/05/13 13:44:40 INFO Executor: Running task ID 7
14/05/13 13:44:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 4 non-zero-bytes blocks out of 6 blocks
14/05/13 13:44:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  6 ms
14/05/13 13:44:40 INFO Executor: Serialized size of result for 7 is 979
14/05/13 13:44:40 INFO Executor: Sending result for 7 directly to driver
14/05/13 13:44:40 INFO Executor: Finished task ID 7
14/05/13 13:44:40 INFO TaskSetManager: Finished TID 7 in 64 ms on localhost (progress: 0/1)
14/05/13 13:44:40 INFO TaskSchedulerImpl: Remove TaskSet 1.0 from pool 
14/05/13 13:44:40 INFO DAGScheduler: Completed ResultTask(1, 0)
14/05/13 13:44:40 INFO DAGScheduler: Stage 1 (take at DStream.scala:586) finished in 0.067 s
14/05/13 13:44:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.602532505 s
14/05/13 13:44:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:44:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 148 bytes
14/05/13 13:44:40 INFO DAGScheduler: Got job 2 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:44:40 INFO DAGScheduler: Final stage: Stage 3 (take at DStream.scala:586)
14/05/13 13:44:40 INFO DAGScheduler: Parents of final stage: List(Stage 4)
14/05/13 13:44:40 INFO DAGScheduler: Missing parents: List()
14/05/13 13:44:40 INFO DAGScheduler: Submitting Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:44:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:44:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
14/05/13 13:44:40 INFO TaskSetManager: Starting task 3.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:40 INFO TaskSetManager: Serialized task 3.0:0 as 1561 bytes in 0 ms
14/05/13 13:44:40 INFO Executor: Running task ID 8
14/05/13 13:44:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 3 non-zero-bytes blocks out of 6 blocks
14/05/13 13:44:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:44:40 INFO Executor: Serialized size of result for 8 is 979
14/05/13 13:44:40 INFO Executor: Sending result for 8 directly to driver
14/05/13 13:44:40 INFO Executor: Finished task ID 8
14/05/13 13:44:40 INFO TaskSetManager: Finished TID 8 in 26 ms on localhost (progress: 0/1)
14/05/13 13:44:40 INFO TaskSchedulerImpl: Remove TaskSet 3.0 from pool 
14/05/13 13:44:40 INFO DAGScheduler: Completed ResultTask(3, 1)
14/05/13 13:44:40 INFO DAGScheduler: Stage 3 (take at DStream.scala:586) finished in 0.028 s
14/05/13 13:44:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.044171012 s
14/05/13 13:44:40 INFO JobScheduler: Finished job streaming job 1399968880000 ms.0 from job set of time 1399968880000 ms
14/05/13 13:44:40 INFO JobScheduler: Total delay: 0.750 s for time 1399968880000 ms (execution: 0.660 s)
14/05/13 13:44:50 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:44:50 INFO JobScheduler: Added jobs for time 1399968890000 ms
14/05/13 13:44:50 INFO JobScheduler: Starting job streaming job 1399968890000 ms.0 from job set of time 1399968890000 ms
14/05/13 13:44:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:44:50 INFO DAGScheduler: Registering RDD 10 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:44:50 INFO DAGScheduler: Got job 3 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:44:50 INFO DAGScheduler: Final stage: Stage 5 (take at DStream.scala:586)
14/05/13 13:44:50 INFO DAGScheduler: Parents of final stage: List(Stage 6)
14/05/13 13:44:50 INFO DAGScheduler: Missing parents: List()
14/05/13 13:44:50 INFO DAGScheduler: Submitting Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:44:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:44:50 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
14/05/13 13:44:50 INFO TaskSetManager: Starting task 5.0:0 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:50 INFO TaskSetManager: Serialized task 5.0:0 as 1563 bytes in 1 ms
14/05/13 13:44:50 INFO Executor: Running task ID 9
14/05/13 13:44:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:44:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:44:50 INFO Executor: Serialized size of result for 9 is 813
14/05/13 13:44:50 INFO Executor: Sending result for 9 directly to driver
14/05/13 13:44:50 INFO Executor: Finished task ID 9
14/05/13 13:44:50 INFO TaskSetManager: Finished TID 9 in 15 ms on localhost (progress: 0/1)
14/05/13 13:44:50 INFO DAGScheduler: Completed ResultTask(5, 0)
14/05/13 13:44:50 INFO TaskSchedulerImpl: Remove TaskSet 5.0 from pool 
14/05/13 13:44:50 INFO DAGScheduler: Stage 5 (take at DStream.scala:586) finished in 0.017 s
14/05/13 13:44:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.032981868 s
14/05/13 13:44:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:44:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 82 bytes
14/05/13 13:44:50 INFO DAGScheduler: Got job 4 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:44:50 INFO DAGScheduler: Final stage: Stage 7 (take at DStream.scala:586)
14/05/13 13:44:50 INFO DAGScheduler: Parents of final stage: List(Stage 8)
14/05/13 13:44:50 INFO DAGScheduler: Missing parents: List()
14/05/13 13:44:50 INFO DAGScheduler: Submitting Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:44:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:44:50 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
14/05/13 13:44:50 INFO TaskSetManager: Starting task 7.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:44:50 INFO TaskSetManager: Serialized task 7.0:0 as 1563 bytes in 0 ms
14/05/13 13:44:50 INFO Executor: Running task ID 10
14/05/13 13:44:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:44:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:44:50 INFO Executor: Serialized size of result for 10 is 813
14/05/13 13:44:50 INFO Executor: Sending result for 10 directly to driver
14/05/13 13:44:50 INFO Executor: Finished task ID 10
14/05/13 13:44:50 INFO TaskSetManager: Finished TID 10 in 15 ms on localhost (progress: 0/1)
14/05/13 13:44:50 INFO DAGScheduler: Completed ResultTask(7, 1)
14/05/13 13:44:50 INFO TaskSchedulerImpl: Remove TaskSet 7.0 from pool 
14/05/13 13:44:50 INFO DAGScheduler: Stage 7 (take at DStream.scala:586) finished in 0.018 s
14/05/13 13:44:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.034327931 s
14/05/13 13:44:50 INFO JobScheduler: Finished job streaming job 1399968890000 ms.0 from job set of time 1399968890000 ms
14/05/13 13:44:50 INFO JobScheduler: Total delay: 0.103 s for time 1399968890000 ms (execution: 0.080 s)
14/05/13 13:45:00 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:45:00 INFO JobScheduler: Added jobs for time 1399968900000 ms
14/05/13 13:45:00 INFO JobScheduler: Starting job streaming job 1399968900000 ms.0 from job set of time 1399968900000 ms
14/05/13 13:45:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:45:00 INFO DAGScheduler: Registering RDD 16 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:45:00 INFO DAGScheduler: Got job 5 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:45:00 INFO DAGScheduler: Final stage: Stage 9 (take at DStream.scala:586)
14/05/13 13:45:00 INFO DAGScheduler: Parents of final stage: List(Stage 10)
14/05/13 13:45:00 INFO DAGScheduler: Missing parents: List()
14/05/13 13:45:00 INFO DAGScheduler: Submitting Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:45:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:45:00 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
14/05/13 13:45:00 INFO TaskSetManager: Starting task 9.0:0 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:45:00 INFO TaskSetManager: Serialized task 9.0:0 as 1563 bytes in 0 ms
14/05/13 13:45:00 INFO Executor: Running task ID 11
14/05/13 13:45:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:45:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:45:00 INFO Executor: Serialized size of result for 11 is 813
14/05/13 13:45:00 INFO Executor: Sending result for 11 directly to driver
14/05/13 13:45:00 INFO Executor: Finished task ID 11
14/05/13 13:45:00 INFO TaskSetManager: Finished TID 11 in 20 ms on localhost (progress: 0/1)
14/05/13 13:45:00 INFO DAGScheduler: Completed ResultTask(9, 0)
14/05/13 13:45:00 INFO TaskSchedulerImpl: Remove TaskSet 9.0 from pool 
14/05/13 13:45:00 INFO DAGScheduler: Stage 9 (take at DStream.scala:586) finished in 0.023 s
14/05/13 13:45:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.035489177 s
14/05/13 13:45:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:45:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 82 bytes
14/05/13 13:45:00 INFO DAGScheduler: Got job 6 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:45:00 INFO DAGScheduler: Final stage: Stage 11 (take at DStream.scala:586)
14/05/13 13:45:00 INFO DAGScheduler: Parents of final stage: List(Stage 12)
14/05/13 13:45:00 INFO DAGScheduler: Missing parents: List()
14/05/13 13:45:00 INFO DAGScheduler: Submitting Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:45:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:45:00 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
14/05/13 13:45:00 INFO TaskSetManager: Starting task 11.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:45:00 INFO TaskSetManager: Serialized task 11.0:0 as 1563 bytes in 0 ms
14/05/13 13:45:00 INFO Executor: Running task ID 12
14/05/13 13:45:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:45:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:45:00 INFO Executor: Serialized size of result for 12 is 813
14/05/13 13:45:00 INFO Executor: Sending result for 12 directly to driver
14/05/13 13:45:00 INFO Executor: Finished task ID 12
14/05/13 13:45:00 INFO TaskSetManager: Finished TID 12 in 16 ms on localhost (progress: 0/1)
14/05/13 13:45:00 INFO TaskSchedulerImpl: Remove TaskSet 11.0 from pool 
14/05/13 13:45:00 INFO DAGScheduler: Completed ResultTask(11, 1)
14/05/13 13:45:00 INFO DAGScheduler: Stage 11 (take at DStream.scala:586) finished in 0.018 s
14/05/13 13:45:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.032433023 s
14/05/13 13:45:00 INFO JobScheduler: Finished job streaming job 1399968900000 ms.0 from job set of time 1399968900000 ms
14/05/13 13:45:00 INFO JobScheduler: Total delay: 0.097 s for time 1399968900000 ms (execution: 0.078 s)
14/05/13 13:47:30 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/13 13:47:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 13:47:31 INFO Slf4jLogger: Slf4jLogger started
14/05/13 13:47:31 INFO Remoting: Starting remoting
14/05/13 13:47:32 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:49969]
14/05/13 13:47:32 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:49969]
14/05/13 13:47:32 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 13:47:32 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513134732-214e
14/05/13 13:47:32 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 13:47:32 INFO ConnectionManager: Bound socket to port 46699 with id = ConnectionManagerId(ubuntu,46699)
14/05/13 13:47:32 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 13:47:32 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:46699 with 640.2 MB RAM
14/05/13 13:47:32 INFO BlockManagerMaster: Registered BlockManager
14/05/13 13:47:32 INFO HttpServer: Starting HTTP Server
14/05/13 13:47:32 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:41209
14/05/13 13:47:32 INFO SparkEnv: Registering MapOutputTracker
14/05/13 13:47:32 INFO HttpFileServer: HTTP File server directory is /tmp/spark-7a5c739e-d3ff-42b3-8a8b-08fdb5a0da3b
14/05/13 13:47:32 INFO HttpServer: Starting HTTP Server
14/05/13 13:47:32 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/13 13:47:34 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 13:47:34 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 13:47:34 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/13 13:47:34 INFO FileInputDStream: Slide time = 5000 ms
14/05/13 13:47:34 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:47:34 INFO FileInputDStream: Checkpoint interval = null
14/05/13 13:47:34 INFO FileInputDStream: Remember duration = 5000 ms
14/05/13 13:47:34 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@18798e38
14/05/13 13:47:34 INFO MappedDStream: Slide time = 5000 ms
14/05/13 13:47:34 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:47:34 INFO MappedDStream: Checkpoint interval = null
14/05/13 13:47:34 INFO MappedDStream: Remember duration = 5000 ms
14/05/13 13:47:34 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@54680b15
14/05/13 13:47:34 INFO ForEachDStream: Slide time = 5000 ms
14/05/13 13:47:34 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:47:34 INFO ForEachDStream: Checkpoint interval = null
14/05/13 13:47:34 INFO ForEachDStream: Remember duration = 5000 ms
14/05/13 13:47:34 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@7aafbafd
14/05/13 13:47:34 INFO JobGenerator: JobGenerator started at 1399969055000 ms
14/05/13 13:47:34 INFO JobScheduler: JobScheduler started
14/05/13 13:47:35 INFO FileInputDStream: Finding new files took 153 ms
14/05/13 13:47:35 INFO FileInputDStream: New files at time 1399969055000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log
14/05/13 13:47:35 INFO MemoryStore: ensureFreeSpace(33264) called with curMem=0, maxMem=671298355
14/05/13 13:47:35 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/13 13:47:35 INFO FileInputFormat: Total input paths to process : 1
14/05/13 13:47:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/13 13:47:35 WARN LoadSnappy: Snappy native library not loaded
14/05/13 13:47:35 INFO JobScheduler: Added jobs for time 1399969055000 ms
14/05/13 13:47:35 INFO JobScheduler: Starting job streaming job 1399969055000 ms.0 from job set of time 1399969055000 ms
14/05/13 13:47:35 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:47:35 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:47:35 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/13 13:47:35 INFO DAGScheduler: Parents of final stage: List()
14/05/13 13:47:35 INFO DAGScheduler: Missing parents: List()
14/05/13 13:47:35 INFO DAGScheduler: Computing the requested partition locally
14/05/13 13:47:35 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log:0+187296
14/05/13 13:47:35 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.116681651 s
14/05/13 13:47:35 INFO JobScheduler: Finished job streaming job 1399969055000 ms.0 from job set of time 1399969055000 ms
14/05/13 13:47:35 INFO JobScheduler: Total delay: 0.582 s for time 1399969055000 ms (execution: 0.150 s)
14/05/13 13:47:35 INFO FileInputDStream: Cleared 0 old files that were older than 1399969050000 ms: 
14/05/13 13:47:40 INFO FileInputDStream: Finding new files took 1 ms
14/05/13 13:47:40 INFO FileInputDStream: New files at time 1399969060000 ms:

14/05/13 13:47:40 INFO JobScheduler: Added jobs for time 1399969060000 ms
14/05/13 13:47:40 INFO JobScheduler: Starting job streaming job 1399969060000 ms.0 from job set of time 1399969060000 ms
14/05/13 13:47:40 INFO JobScheduler: Finished job streaming job 1399969060000 ms.0 from job set of time 1399969060000 ms
14/05/13 13:47:40 INFO FileInputDStream: Cleared 0 old files that were older than 1399969055000 ms: 
14/05/13 13:47:40 INFO JobScheduler: Total delay: 0.013 s for time 1399969060000 ms (execution: 0.001 s)
14/05/13 13:47:45 INFO FileInputDStream: Finding new files took 0 ms
14/05/13 13:47:45 INFO FileInputDStream: New files at time 1399969065000 ms:

14/05/13 13:47:45 INFO JobScheduler: Added jobs for time 1399969065000 ms
14/05/13 13:47:45 INFO JobScheduler: Starting job streaming job 1399969065000 ms.0 from job set of time 1399969065000 ms
14/05/13 13:47:45 INFO JobScheduler: Finished job streaming job 1399969065000 ms.0 from job set of time 1399969065000 ms
14/05/13 13:47:45 INFO JobScheduler: Total delay: 0.010 s for time 1399969065000 ms (execution: 0.000 s)
14/05/13 13:47:45 INFO FileInputDStream: Cleared 1 old files that were older than 1399969060000 ms: 1399969055000 ms
14/05/13 13:47:50 INFO FileInputDStream: Finding new files took 1 ms
14/05/13 13:47:50 INFO FileInputDStream: New files at time 1399969070000 ms:

14/05/13 13:47:50 INFO JobScheduler: Added jobs for time 1399969070000 ms
14/05/13 13:47:50 INFO JobScheduler: Starting job streaming job 1399969070000 ms.0 from job set of time 1399969070000 ms
14/05/13 13:47:50 INFO JobScheduler: Finished job streaming job 1399969070000 ms.0 from job set of time 1399969070000 ms
14/05/13 13:47:50 INFO JobScheduler: Total delay: 0.010 s for time 1399969070000 ms (execution: 0.000 s)
14/05/13 13:47:50 INFO FileInputDStream: Cleared 1 old files that were older than 1399969065000 ms: 1399969060000 ms
14/05/13 13:48:45 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/13 13:48:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 13:48:46 INFO Slf4jLogger: Slf4jLogger started
14/05/13 13:48:46 INFO Remoting: Starting remoting
14/05/13 13:48:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:59767]
14/05/13 13:48:47 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:59767]
14/05/13 13:48:47 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 13:48:47 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513134847-cdf8
14/05/13 13:48:47 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 13:48:47 INFO ConnectionManager: Bound socket to port 34409 with id = ConnectionManagerId(ubuntu,34409)
14/05/13 13:48:47 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 13:48:47 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:34409 with 640.2 MB RAM
14/05/13 13:48:47 INFO BlockManagerMaster: Registered BlockManager
14/05/13 13:48:47 INFO HttpServer: Starting HTTP Server
14/05/13 13:48:47 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:57483
14/05/13 13:48:47 INFO SparkEnv: Registering MapOutputTracker
14/05/13 13:48:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-1cec7056-08ce-4732-86e8-f646f3449696
14/05/13 13:48:47 INFO HttpServer: Starting HTTP Server
14/05/13 13:48:47 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/13 13:48:49 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 13:48:49 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 13:48:49 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/13 13:48:49 INFO FileInputDStream: Slide time = 5000 ms
14/05/13 13:48:49 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:48:49 INFO FileInputDStream: Checkpoint interval = null
14/05/13 13:48:49 INFO FileInputDStream: Remember duration = 5000 ms
14/05/13 13:48:49 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@37acfc7a
14/05/13 13:48:49 INFO MappedDStream: Slide time = 5000 ms
14/05/13 13:48:49 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:48:49 INFO MappedDStream: Checkpoint interval = null
14/05/13 13:48:49 INFO MappedDStream: Remember duration = 5000 ms
14/05/13 13:48:49 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@3df3ca24
14/05/13 13:48:49 INFO ForEachDStream: Slide time = 5000 ms
14/05/13 13:48:49 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:48:49 INFO ForEachDStream: Checkpoint interval = null
14/05/13 13:48:49 INFO ForEachDStream: Remember duration = 5000 ms
14/05/13 13:48:49 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@505c2142
14/05/13 13:48:49 INFO JobGenerator: JobGenerator started at 1399969130000 ms
14/05/13 13:48:49 INFO JobScheduler: JobScheduler started
14/05/13 13:48:50 INFO FileInputDStream: Finding new files took 107 ms
14/05/13 13:48:50 INFO FileInputDStream: New files at time 1399969130000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log
14/05/13 13:48:50 INFO MemoryStore: ensureFreeSpace(33264) called with curMem=0, maxMem=671298355
14/05/13 13:48:50 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/13 13:48:50 INFO FileInputFormat: Total input paths to process : 1
14/05/13 13:48:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/13 13:48:50 WARN LoadSnappy: Snappy native library not loaded
14/05/13 13:48:50 INFO JobScheduler: Added jobs for time 1399969130000 ms
14/05/13 13:48:50 INFO JobScheduler: Starting job streaming job 1399969130000 ms.0 from job set of time 1399969130000 ms
14/05/13 13:48:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:48:50 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:48:50 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/13 13:48:50 INFO DAGScheduler: Parents of final stage: List()
14/05/13 13:48:50 INFO DAGScheduler: Missing parents: List()
14/05/13 13:48:50 INFO DAGScheduler: Computing the requested partition locally
14/05/13 13:48:50 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log:0+187296
14/05/13 13:48:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.067350061 s
14/05/13 13:48:50 INFO JobScheduler: Finished job streaming job 1399969130000 ms.0 from job set of time 1399969130000 ms
14/05/13 13:48:50 INFO JobScheduler: Total delay: 0.453 s for time 1399969130000 ms (execution: 0.099 s)
14/05/13 13:48:50 INFO FileInputDStream: Cleared 0 old files that were older than 1399969125000 ms: 
14/05/13 13:48:55 INFO FileInputDStream: Finding new files took 2 ms
14/05/13 13:48:55 INFO FileInputDStream: New files at time 1399969135000 ms:

14/05/13 13:48:55 INFO JobScheduler: Added jobs for time 1399969135000 ms
14/05/13 13:48:55 INFO JobScheduler: Starting job streaming job 1399969135000 ms.0 from job set of time 1399969135000 ms
14/05/13 13:48:55 INFO JobScheduler: Finished job streaming job 1399969135000 ms.0 from job set of time 1399969135000 ms
14/05/13 13:48:55 INFO FileInputDStream: Cleared 0 old files that were older than 1399969130000 ms: 
14/05/13 13:48:55 INFO JobScheduler: Total delay: 0.014 s for time 1399969135000 ms (execution: 0.001 s)
14/05/13 13:49:00 INFO FileInputDStream: Finding new files took 0 ms
14/05/13 13:49:00 INFO FileInputDStream: New files at time 1399969140000 ms:

14/05/13 13:49:00 INFO JobScheduler: Added jobs for time 1399969140000 ms
14/05/13 13:49:00 INFO JobScheduler: Starting job streaming job 1399969140000 ms.0 from job set of time 1399969140000 ms
14/05/13 13:49:00 INFO JobScheduler: Finished job streaming job 1399969140000 ms.0 from job set of time 1399969140000 ms
14/05/13 13:49:00 INFO JobScheduler: Total delay: 0.010 s for time 1399969140000 ms (execution: 0.001 s)
14/05/13 13:49:00 INFO FileInputDStream: Cleared 1 old files that were older than 1399969135000 ms: 1399969130000 ms
14/05/13 13:50:03 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/13 13:50:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 13:50:04 INFO Slf4jLogger: Slf4jLogger started
14/05/13 13:50:04 INFO Remoting: Starting remoting
14/05/13 13:50:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:52576]
14/05/13 13:50:05 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:52576]
14/05/13 13:50:05 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 13:50:05 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513135005-fd04
14/05/13 13:50:05 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 13:50:05 INFO ConnectionManager: Bound socket to port 58839 with id = ConnectionManagerId(ubuntu,58839)
14/05/13 13:50:05 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 13:50:05 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:58839 with 640.2 MB RAM
14/05/13 13:50:05 INFO BlockManagerMaster: Registered BlockManager
14/05/13 13:50:05 INFO HttpServer: Starting HTTP Server
14/05/13 13:50:05 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:60820
14/05/13 13:50:05 INFO SparkEnv: Registering MapOutputTracker
14/05/13 13:50:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-12a2517d-f893-4b74-970c-4ba194e165d8
14/05/13 13:50:05 INFO HttpServer: Starting HTTP Server
14/05/13 13:50:05 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/13 13:50:06 INFO NetworkInputTracker: NetworkInputTracker started
14/05/13 13:50:06 INFO SparkContext: Starting job: runJob at NetworkInputTracker.scala:182
14/05/13 13:50:06 INFO DAGScheduler: Got job 0 (runJob at NetworkInputTracker.scala:182) with 1 output partitions (allowLocal=false)
14/05/13 13:50:06 INFO DAGScheduler: Final stage: Stage 0 (runJob at NetworkInputTracker.scala:182)
14/05/13 13:50:06 INFO DAGScheduler: Parents of final stage: List()
14/05/13 13:50:06 INFO DAGScheduler: Missing parents: List()
14/05/13 13:50:06 INFO DAGScheduler: Submitting Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165), which has no missing parents
14/05/13 13:50:06 INFO DAGScheduler: Submitting 1 missing tasks from Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165)
14/05/13 13:50:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
14/05/13 13:50:06 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:06 INFO TaskSetManager: Serialized task 0.0:0 as 1978 bytes in 11 ms
14/05/13 13:50:06 INFO Executor: Running task ID 0
14/05/13 13:50:06 INFO SocketReceiver: Connecting to localhost:9999
14/05/13 13:50:06 INFO SocketReceiver: Attempting to register with tracker
14/05/13 13:50:06 INFO SocketReceiver: Connected to localhost:9999
14/05/13 13:50:06 INFO NetworkReceiver$BlockGenerator: Block pushing thread started
14/05/13 13:50:06 INFO NetworkReceiver$BlockGenerator: Data handler started
14/05/13 13:50:06 INFO NetworkInputTracker: Registered receiver for network stream 0 from akka://spark
14/05/13 13:50:07 INFO MemoryStore: ensureFreeSpace(38) called with curMem=0, maxMem=671298355
14/05/13 13:50:07 INFO MemoryStore: Block input-0-1399969206800 stored as bytes to memory (size 38.0 B, free 640.2 MB)
14/05/13 13:50:07 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969206800 in memory on ubuntu:58839 (size: 38.0 B, free: 640.2 MB)
14/05/13 13:50:07 INFO BlockManagerMaster: Updated info of block input-0-1399969206800
14/05/13 13:50:07 INFO SendingConnection: Initiating connection to [ubuntu/127.0.1.1:58839]
14/05/13 13:50:07 INFO ConnectionManager: Accepted connection from [localhost/127.0.0.1]
14/05/13 13:50:07 INFO SendingConnection: Connected to [ubuntu/127.0.1.1:58839], 1 messages pending
14/05/13 13:50:07 WARN BlockManager: Block input-0-1399969206800 already exists on this machine; not re-adding it
14/05/13 13:50:07 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 13:50:07 INFO ShuffledDStream: metadataCleanupDelay = 3600
14/05/13 13:50:07 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 13:50:07 INFO FlatMappedDStream: metadataCleanupDelay = 3600
14/05/13 13:50:07 INFO SocketInputDStream: metadataCleanupDelay = 3600
14/05/13 13:50:07 INFO SocketInputDStream: Slide time = 10000 ms
14/05/13 13:50:07 INFO SocketInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:50:07 INFO SocketInputDStream: Checkpoint interval = null
14/05/13 13:50:07 INFO SocketInputDStream: Remember duration = 10000 ms
14/05/13 13:50:07 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@851bfe0
14/05/13 13:50:07 INFO FlatMappedDStream: Slide time = 10000 ms
14/05/13 13:50:07 INFO FlatMappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:50:07 INFO FlatMappedDStream: Checkpoint interval = null
14/05/13 13:50:07 INFO FlatMappedDStream: Remember duration = 10000 ms
14/05/13 13:50:07 INFO FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@2f0c0f64
14/05/13 13:50:07 INFO MappedDStream: Slide time = 10000 ms
14/05/13 13:50:07 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:50:07 INFO MappedDStream: Checkpoint interval = null
14/05/13 13:50:07 INFO MappedDStream: Remember duration = 10000 ms
14/05/13 13:50:07 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@40c6865d
14/05/13 13:50:07 INFO ShuffledDStream: Slide time = 10000 ms
14/05/13 13:50:07 INFO ShuffledDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:50:07 INFO ShuffledDStream: Checkpoint interval = null
14/05/13 13:50:07 INFO ShuffledDStream: Remember duration = 10000 ms
14/05/13 13:50:07 INFO ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@299f64e4
14/05/13 13:50:07 INFO ForEachDStream: Slide time = 10000 ms
14/05/13 13:50:07 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:50:07 INFO ForEachDStream: Checkpoint interval = null
14/05/13 13:50:07 INFO ForEachDStream: Remember duration = 10000 ms
14/05/13 13:50:07 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@1f98ca15
14/05/13 13:50:07 INFO JobGenerator: JobGenerator started at 1399969210000 ms
14/05/13 13:50:07 INFO JobScheduler: JobScheduler started
14/05/13 13:50:10 INFO NetworkInputTracker: Stream 0 received 1 blocks
14/05/13 13:50:10 INFO JobScheduler: Added jobs for time 1399969210000 ms
14/05/13 13:50:10 INFO JobScheduler: Starting job streaming job 1399969210000 ms.0 from job set of time 1399969210000 ms
14/05/13 13:50:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:50:10 INFO DAGScheduler: Registering RDD 4 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:10 INFO DAGScheduler: Got job 1 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:50:10 INFO DAGScheduler: Final stage: Stage 1 (take at DStream.scala:586)
14/05/13 13:50:10 INFO DAGScheduler: Parents of final stage: List(Stage 2)
14/05/13 13:50:10 INFO DAGScheduler: Missing parents: List(Stage 2)
14/05/13 13:50:10 INFO DAGScheduler: Submitting Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:50:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
14/05/13 13:50:10 INFO TaskSetManager: Starting task 2.0:0 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:10 INFO TaskSetManager: Serialized task 2.0:0 as 1517 bytes in 0 ms
14/05/13 13:50:10 INFO Executor: Running task ID 1
14/05/13 13:50:10 INFO BlockManager: Found block input-0-1399969206800 locally
14/05/13 13:50:10 INFO Executor: Serialized size of result for 1 is 743
14/05/13 13:50:10 INFO Executor: Sending result for 1 directly to driver
14/05/13 13:50:10 INFO Executor: Finished task ID 1
14/05/13 13:50:10 INFO TaskSetManager: Finished TID 1 in 179 ms on localhost (progress: 0/1)
14/05/13 13:50:10 INFO TaskSchedulerImpl: Remove TaskSet 2.0 from pool 
14/05/13 13:50:10 INFO DAGScheduler: Completed ShuffleMapTask(2, 0)
14/05/13 13:50:10 INFO DAGScheduler: Stage 2 (combineByKey at ShuffledDStream.scala:42) finished in 0.191 s
14/05/13 13:50:10 INFO DAGScheduler: looking for newly runnable stages
14/05/13 13:50:10 INFO DAGScheduler: running: Set(Stage 0)
14/05/13 13:50:10 INFO DAGScheduler: waiting: Set(Stage 1)
14/05/13 13:50:10 INFO DAGScheduler: failed: Set()
14/05/13 13:50:10 INFO DAGScheduler: Missing parents for Stage 1: List()
14/05/13 13:50:10 INFO DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/13 13:50:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
14/05/13 13:50:10 INFO TaskSetManager: Starting task 1.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:10 INFO TaskSetManager: Serialized task 1.0:0 as 1562 bytes in 0 ms
14/05/13 13:50:10 INFO Executor: Running task ID 2
14/05/13 13:50:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 1 blocks
14/05/13 13:50:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  6 ms
14/05/13 13:50:10 INFO Executor: Serialized size of result for 2 is 959
14/05/13 13:50:10 INFO Executor: Sending result for 2 directly to driver
14/05/13 13:50:10 INFO Executor: Finished task ID 2
14/05/13 13:50:10 INFO TaskSetManager: Finished TID 2 in 52 ms on localhost (progress: 0/1)
14/05/13 13:50:10 INFO TaskSchedulerImpl: Remove TaskSet 1.0 from pool 
14/05/13 13:50:10 INFO DAGScheduler: Completed ResultTask(1, 0)
14/05/13 13:50:10 INFO DAGScheduler: Stage 1 (take at DStream.scala:586) finished in 0.056 s
14/05/13 13:50:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.367781492 s
14/05/13 13:50:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:50:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 132 bytes
14/05/13 13:50:10 INFO DAGScheduler: Got job 2 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:50:10 INFO DAGScheduler: Final stage: Stage 3 (take at DStream.scala:586)
14/05/13 13:50:10 INFO DAGScheduler: Parents of final stage: List(Stage 4)
14/05/13 13:50:10 INFO DAGScheduler: Missing parents: List()
14/05/13 13:50:10 INFO DAGScheduler: Submitting Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:50:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:10 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
14/05/13 13:50:10 INFO TaskSetManager: Starting task 3.0:0 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:10 INFO TaskSetManager: Serialized task 3.0:0 as 1562 bytes in 0 ms
14/05/13 13:50:10 INFO Executor: Running task ID 3
14/05/13 13:50:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 1 blocks
14/05/13 13:50:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:50:10 INFO Executor: Serialized size of result for 3 is 996
14/05/13 13:50:10 INFO Executor: Sending result for 3 directly to driver
14/05/13 13:50:10 INFO Executor: Finished task ID 3
14/05/13 13:50:10 INFO TaskSetManager: Finished TID 3 in 19 ms on localhost (progress: 0/1)
14/05/13 13:50:10 INFO DAGScheduler: Completed ResultTask(3, 1)
14/05/13 13:50:10 INFO TaskSchedulerImpl: Remove TaskSet 3.0 from pool 
14/05/13 13:50:10 INFO DAGScheduler: Stage 3 (take at DStream.scala:586) finished in 0.023 s
14/05/13 13:50:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.038190258 s
14/05/13 13:50:10 INFO JobScheduler: Finished job streaming job 1399969210000 ms.0 from job set of time 1399969210000 ms
14/05/13 13:50:10 INFO JobScheduler: Total delay: 0.491 s for time 1399969210000 ms (execution: 0.424 s)
14/05/13 13:50:20 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:50:20 INFO JobScheduler: Added jobs for time 1399969220000 ms
14/05/13 13:50:20 INFO JobScheduler: Starting job streaming job 1399969220000 ms.0 from job set of time 1399969220000 ms
14/05/13 13:50:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:50:20 INFO DAGScheduler: Registering RDD 10 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:20 INFO DAGScheduler: Got job 3 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:50:20 INFO DAGScheduler: Final stage: Stage 5 (take at DStream.scala:586)
14/05/13 13:50:20 INFO DAGScheduler: Parents of final stage: List(Stage 6)
14/05/13 13:50:20 INFO DAGScheduler: Missing parents: List()
14/05/13 13:50:20 INFO DAGScheduler: Submitting Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:50:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:20 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
14/05/13 13:50:20 INFO TaskSetManager: Starting task 5.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:20 INFO TaskSetManager: Serialized task 5.0:0 as 1563 bytes in 1 ms
14/05/13 13:50:20 INFO Executor: Running task ID 4
14/05/13 13:50:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:50:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:50:20 INFO Executor: Serialized size of result for 4 is 813
14/05/13 13:50:20 INFO Executor: Sending result for 4 directly to driver
14/05/13 13:50:20 INFO Executor: Finished task ID 4
14/05/13 13:50:20 INFO TaskSetManager: Finished TID 4 in 19 ms on localhost (progress: 0/1)
14/05/13 13:50:20 INFO DAGScheduler: Completed ResultTask(5, 0)
14/05/13 13:50:20 INFO TaskSchedulerImpl: Remove TaskSet 5.0 from pool 
14/05/13 13:50:20 INFO DAGScheduler: Stage 5 (take at DStream.scala:586) finished in 0.023 s
14/05/13 13:50:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.039580701 s
14/05/13 13:50:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:50:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 82 bytes
14/05/13 13:50:20 INFO DAGScheduler: Got job 4 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:50:20 INFO DAGScheduler: Final stage: Stage 7 (take at DStream.scala:586)
14/05/13 13:50:20 INFO DAGScheduler: Parents of final stage: List(Stage 8)
14/05/13 13:50:20 INFO DAGScheduler: Missing parents: List()
14/05/13 13:50:20 INFO DAGScheduler: Submitting Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:50:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:20 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
14/05/13 13:50:20 INFO TaskSetManager: Starting task 7.0:0 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:20 INFO TaskSetManager: Serialized task 7.0:0 as 1563 bytes in 0 ms
14/05/13 13:50:20 INFO Executor: Running task ID 5
14/05/13 13:50:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:50:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:50:20 INFO Executor: Serialized size of result for 5 is 813
14/05/13 13:50:20 INFO Executor: Sending result for 5 directly to driver
14/05/13 13:50:20 INFO Executor: Finished task ID 5
14/05/13 13:50:20 INFO TaskSetManager: Finished TID 5 in 15 ms on localhost (progress: 0/1)
14/05/13 13:50:20 INFO TaskSchedulerImpl: Remove TaskSet 7.0 from pool 
14/05/13 13:50:20 INFO DAGScheduler: Completed ResultTask(7, 1)
14/05/13 13:50:20 INFO DAGScheduler: Stage 7 (take at DStream.scala:586) finished in 0.017 s
14/05/13 13:50:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.032862643 s
14/05/13 13:50:20 INFO JobScheduler: Finished job streaming job 1399969220000 ms.0 from job set of time 1399969220000 ms
14/05/13 13:50:20 INFO JobScheduler: Total delay: 0.100 s for time 1399969220000 ms (execution: 0.085 s)
14/05/13 13:50:30 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:50:30 INFO JobScheduler: Added jobs for time 1399969230000 ms
14/05/13 13:50:30 INFO JobScheduler: Starting job streaming job 1399969230000 ms.0 from job set of time 1399969230000 ms
14/05/13 13:50:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:50:30 INFO DAGScheduler: Registering RDD 16 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:30 INFO DAGScheduler: Got job 5 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:50:30 INFO DAGScheduler: Final stage: Stage 9 (take at DStream.scala:586)
14/05/13 13:50:30 INFO DAGScheduler: Parents of final stage: List(Stage 10)
14/05/13 13:50:30 INFO DAGScheduler: Missing parents: List()
14/05/13 13:50:30 INFO DAGScheduler: Submitting Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:50:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:30 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
14/05/13 13:50:30 INFO TaskSetManager: Starting task 9.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:30 INFO TaskSetManager: Serialized task 9.0:0 as 1563 bytes in 0 ms
14/05/13 13:50:30 INFO Executor: Running task ID 6
14/05/13 13:50:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:50:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:50:30 INFO Executor: Serialized size of result for 6 is 813
14/05/13 13:50:30 INFO Executor: Sending result for 6 directly to driver
14/05/13 13:50:30 INFO Executor: Finished task ID 6
14/05/13 13:50:30 INFO TaskSetManager: Finished TID 6 in 21 ms on localhost (progress: 0/1)
14/05/13 13:50:30 INFO DAGScheduler: Completed ResultTask(9, 0)
14/05/13 13:50:30 INFO TaskSchedulerImpl: Remove TaskSet 9.0 from pool 
14/05/13 13:50:30 INFO DAGScheduler: Stage 9 (take at DStream.scala:586) finished in 0.024 s
14/05/13 13:50:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.038362692 s
14/05/13 13:50:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:50:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 82 bytes
14/05/13 13:50:30 INFO DAGScheduler: Got job 6 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:50:30 INFO DAGScheduler: Final stage: Stage 11 (take at DStream.scala:586)
14/05/13 13:50:30 INFO DAGScheduler: Parents of final stage: List(Stage 12)
14/05/13 13:50:30 INFO DAGScheduler: Missing parents: List()
14/05/13 13:50:30 INFO DAGScheduler: Submitting Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:50:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:30 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
14/05/13 13:50:30 INFO TaskSetManager: Starting task 11.0:0 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:30 INFO TaskSetManager: Serialized task 11.0:0 as 1563 bytes in 1 ms
14/05/13 13:50:30 INFO Executor: Running task ID 7
14/05/13 13:50:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:50:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:50:30 INFO Executor: Serialized size of result for 7 is 813
14/05/13 13:50:30 INFO Executor: Sending result for 7 directly to driver
14/05/13 13:50:30 INFO Executor: Finished task ID 7
14/05/13 13:50:30 INFO TaskSetManager: Finished TID 7 in 21 ms on localhost (progress: 0/1)
14/05/13 13:50:30 INFO TaskSchedulerImpl: Remove TaskSet 11.0 from pool 
14/05/13 13:50:30 INFO DAGScheduler: Completed ResultTask(11, 1)
14/05/13 13:50:30 INFO DAGScheduler: Stage 11 (take at DStream.scala:586) finished in 0.024 s
14/05/13 13:50:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.04014504 s
14/05/13 13:50:30 INFO JobScheduler: Finished job streaming job 1399969230000 ms.0 from job set of time 1399969230000 ms
14/05/13 13:50:30 INFO JobScheduler: Total delay: 0.106 s for time 1399969230000 ms (execution: 0.088 s)
14/05/13 13:50:32 INFO MemoryStore: ensureFreeSpace(13) called with curMem=38, maxMem=671298355
14/05/13 13:50:32 INFO MemoryStore: Block input-0-1399969232000 stored as bytes to memory (size 13.0 B, free 640.2 MB)
14/05/13 13:50:32 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969232000 in memory on ubuntu:58839 (size: 13.0 B, free: 640.2 MB)
14/05/13 13:50:32 INFO BlockManagerMaster: Updated info of block input-0-1399969232000
14/05/13 13:50:32 WARN BlockManager: Block input-0-1399969232000 already exists on this machine; not re-adding it
14/05/13 13:50:40 INFO NetworkInputTracker: Stream 0 received 1 blocks
14/05/13 13:50:40 INFO JobScheduler: Added jobs for time 1399969240000 ms
14/05/13 13:50:40 INFO JobScheduler: Starting job streaming job 1399969240000 ms.0 from job set of time 1399969240000 ms
14/05/13 13:50:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:50:40 INFO DAGScheduler: Registering RDD 22 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:40 INFO DAGScheduler: Got job 7 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:50:40 INFO DAGScheduler: Final stage: Stage 13 (take at DStream.scala:586)
14/05/13 13:50:40 INFO DAGScheduler: Parents of final stage: List(Stage 14)
14/05/13 13:50:40 INFO DAGScheduler: Missing parents: List(Stage 14)
14/05/13 13:50:40 INFO DAGScheduler: Submitting Stage 14 (MapPartitionsRDD[22] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:50:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 14 (MapPartitionsRDD[22] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
14/05/13 13:50:40 INFO TaskSetManager: Starting task 14.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:40 INFO TaskSetManager: Serialized task 14.0:0 as 1519 bytes in 0 ms
14/05/13 13:50:40 INFO Executor: Running task ID 8
14/05/13 13:50:40 INFO BlockManager: Found block input-0-1399969232000 locally
14/05/13 13:50:40 INFO Executor: Serialized size of result for 8 is 743
14/05/13 13:50:40 INFO Executor: Sending result for 8 directly to driver
14/05/13 13:50:40 INFO Executor: Finished task ID 8
14/05/13 13:50:40 INFO TaskSetManager: Finished TID 8 in 26 ms on localhost (progress: 0/1)
14/05/13 13:50:40 INFO TaskSchedulerImpl: Remove TaskSet 14.0 from pool 
14/05/13 13:50:40 INFO DAGScheduler: Completed ShuffleMapTask(14, 0)
14/05/13 13:50:40 INFO DAGScheduler: Stage 14 (combineByKey at ShuffledDStream.scala:42) finished in 0.029 s
14/05/13 13:50:40 INFO DAGScheduler: looking for newly runnable stages
14/05/13 13:50:40 INFO DAGScheduler: running: Set(Stage 0)
14/05/13 13:50:40 INFO DAGScheduler: waiting: Set(Stage 13)
14/05/13 13:50:40 INFO DAGScheduler: failed: Set()
14/05/13 13:50:40 INFO DAGScheduler: Missing parents for Stage 13: List()
14/05/13 13:50:40 INFO DAGScheduler: Submitting Stage 13 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/13 13:50:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 13 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:40 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
14/05/13 13:50:40 INFO TaskSetManager: Starting task 13.0:0 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:40 INFO TaskSetManager: Serialized task 13.0:0 as 1564 bytes in 1 ms
14/05/13 13:50:40 INFO Executor: Running task ID 9
14/05/13 13:50:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 1 blocks
14/05/13 13:50:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:50:40 INFO Executor: Serialized size of result for 9 is 813
14/05/13 13:50:40 INFO Executor: Sending result for 9 directly to driver
14/05/13 13:50:40 INFO Executor: Finished task ID 9
14/05/13 13:50:40 INFO TaskSetManager: Finished TID 9 in 19 ms on localhost (progress: 0/1)
14/05/13 13:50:40 INFO DAGScheduler: Completed ResultTask(13, 0)
14/05/13 13:50:40 INFO TaskSchedulerImpl: Remove TaskSet 13.0 from pool 
14/05/13 13:50:40 INFO DAGScheduler: Stage 13 (take at DStream.scala:586) finished in 0.022 s
14/05/13 13:50:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.074611801 s
14/05/13 13:50:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:50:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 132 bytes
14/05/13 13:50:40 INFO DAGScheduler: Got job 8 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:50:40 INFO DAGScheduler: Final stage: Stage 15 (take at DStream.scala:586)
14/05/13 13:50:40 INFO DAGScheduler: Parents of final stage: List(Stage 16)
14/05/13 13:50:40 INFO DAGScheduler: Missing parents: List()
14/05/13 13:50:40 INFO DAGScheduler: Submitting Stage 15 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:50:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 15 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:50:40 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
14/05/13 13:50:40 INFO TaskSetManager: Starting task 15.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:50:40 INFO TaskSetManager: Serialized task 15.0:0 as 1564 bytes in 0 ms
14/05/13 13:50:40 INFO Executor: Running task ID 10
14/05/13 13:50:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 1 blocks
14/05/13 13:50:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:50:40 INFO Executor: Serialized size of result for 10 is 964
14/05/13 13:50:40 INFO Executor: Sending result for 10 directly to driver
14/05/13 13:50:40 INFO Executor: Finished task ID 10
14/05/13 13:50:40 INFO TaskSetManager: Finished TID 10 in 22 ms on localhost (progress: 0/1)
14/05/13 13:50:40 INFO DAGScheduler: Completed ResultTask(15, 1)
14/05/13 13:50:40 INFO TaskSchedulerImpl: Remove TaskSet 15.0 from pool 
14/05/13 13:50:40 INFO DAGScheduler: Stage 15 (take at DStream.scala:586) finished in 0.027 s
14/05/13 13:50:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.043136533 s
14/05/13 13:50:40 INFO JobScheduler: Finished job streaming job 1399969240000 ms.0 from job set of time 1399969240000 ms
14/05/13 13:50:40 INFO JobScheduler: Total delay: 0.145 s for time 1399969240000 ms (execution: 0.128 s)
14/05/13 13:57:15 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/13 13:57:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 13:57:17 INFO Slf4jLogger: Slf4jLogger started
14/05/13 13:57:17 INFO Remoting: Starting remoting
14/05/13 13:57:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu.local:60381]
14/05/13 13:57:17 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu.local:60381]
14/05/13 13:57:17 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 13:57:17 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513135717-7772
14/05/13 13:57:17 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 13:57:17 INFO ConnectionManager: Bound socket to port 39029 with id = ConnectionManagerId(ubuntu.local,39029)
14/05/13 13:57:17 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 13:57:17 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu.local:39029 with 640.2 MB RAM
14/05/13 13:57:17 INFO BlockManagerMaster: Registered BlockManager
14/05/13 13:57:17 INFO HttpServer: Starting HTTP Server
14/05/13 13:57:18 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:55217
14/05/13 13:57:18 INFO SparkEnv: Registering MapOutputTracker
14/05/13 13:57:18 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3a0babee-72cf-4f30-978e-5f33a976b7da
14/05/13 13:57:18 INFO HttpServer: Starting HTTP Server
14/05/13 13:57:18 INFO SparkUI: Started Spark Web UI at http://ubuntu.local:4040
14/05/13 13:57:19 INFO NetworkInputTracker: NetworkInputTracker started
14/05/13 13:57:19 INFO SparkContext: Starting job: runJob at NetworkInputTracker.scala:182
14/05/13 13:57:19 INFO DAGScheduler: Got job 0 (runJob at NetworkInputTracker.scala:182) with 1 output partitions (allowLocal=false)
14/05/13 13:57:19 INFO DAGScheduler: Final stage: Stage 0 (runJob at NetworkInputTracker.scala:182)
14/05/13 13:57:19 INFO DAGScheduler: Parents of final stage: List()
14/05/13 13:57:19 INFO DAGScheduler: Missing parents: List()
14/05/13 13:57:19 INFO DAGScheduler: Submitting Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165), which has no missing parents
14/05/13 13:57:19 INFO DAGScheduler: Submitting 1 missing tasks from Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165)
14/05/13 13:57:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
14/05/13 13:57:19 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:57:19 INFO TaskSetManager: Serialized task 0.0:0 as 1978 bytes in 11 ms
14/05/13 13:57:19 INFO Executor: Running task ID 0
14/05/13 13:57:19 INFO SocketReceiver: Connecting to localhost:9999
14/05/13 13:57:19 INFO SocketReceiver: Attempting to register with tracker
14/05/13 13:57:19 INFO SocketReceiver: Connected to localhost:9999
14/05/13 13:57:19 INFO NetworkReceiver$BlockGenerator: Block pushing thread started
14/05/13 13:57:19 INFO NetworkReceiver$BlockGenerator: Data handler started
14/05/13 13:57:19 INFO NetworkInputTracker: Registered receiver for network stream 0 from akka://spark
14/05/13 13:57:19 INFO MemoryStore: ensureFreeSpace(31) called with curMem=0, maxMem=671298355
14/05/13 13:57:19 INFO MemoryStore: Block input-0-1399969639400 stored as bytes to memory (size 31.0 B, free 640.2 MB)
14/05/13 13:57:19 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969639400 in memory on ubuntu.local:39029 (size: 31.0 B, free: 640.2 MB)
14/05/13 13:57:19 INFO BlockManagerMaster: Updated info of block input-0-1399969639400
14/05/13 13:57:19 INFO SendingConnection: Initiating connection to [ubuntu.local/10.8.7.208:39029]
14/05/13 13:57:19 INFO SendingConnection: Connected to [ubuntu.local/10.8.7.208:39029], 1 messages pending
14/05/13 13:57:20 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 13:57:20 INFO ShuffledDStream: metadataCleanupDelay = 3600
14/05/13 13:57:20 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 13:57:20 INFO FlatMappedDStream: metadataCleanupDelay = 3600
14/05/13 13:57:20 INFO SocketInputDStream: metadataCleanupDelay = 3600
14/05/13 13:57:20 INFO SocketInputDStream: Slide time = 10000 ms
14/05/13 13:57:20 INFO SocketInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:57:20 INFO SocketInputDStream: Checkpoint interval = null
14/05/13 13:57:20 INFO SocketInputDStream: Remember duration = 10000 ms
14/05/13 13:57:20 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@4b3bf0f2
14/05/13 13:57:20 INFO FlatMappedDStream: Slide time = 10000 ms
14/05/13 13:57:20 INFO FlatMappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:57:20 INFO FlatMappedDStream: Checkpoint interval = null
14/05/13 13:57:20 INFO FlatMappedDStream: Remember duration = 10000 ms
14/05/13 13:57:20 INFO FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@4c47c674
14/05/13 13:57:20 INFO MappedDStream: Slide time = 10000 ms
14/05/13 13:57:20 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:57:20 INFO MappedDStream: Checkpoint interval = null
14/05/13 13:57:20 INFO MappedDStream: Remember duration = 10000 ms
14/05/13 13:57:20 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@7c3610cb
14/05/13 13:57:20 INFO ShuffledDStream: Slide time = 10000 ms
14/05/13 13:57:20 INFO ShuffledDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:57:20 INFO ShuffledDStream: Checkpoint interval = null
14/05/13 13:57:20 INFO ShuffledDStream: Remember duration = 10000 ms
14/05/13 13:57:20 INFO ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@4188bf22
14/05/13 13:57:20 INFO ForEachDStream: Slide time = 10000 ms
14/05/13 13:57:20 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 13:57:20 INFO ForEachDStream: Checkpoint interval = null
14/05/13 13:57:20 INFO ForEachDStream: Remember duration = 10000 ms
14/05/13 13:57:20 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@78bc72ca
14/05/13 13:57:20 INFO JobGenerator: JobGenerator started at 1399969650000 ms
14/05/13 13:57:20 INFO JobScheduler: JobScheduler started
14/05/13 13:57:20 INFO ConnectionManager: Accepted connection from [ubuntu.local/10.8.7.208]
14/05/13 13:57:20 WARN BlockManager: Block input-0-1399969639400 already exists on this machine; not re-adding it
14/05/13 13:57:30 INFO NetworkInputTracker: Stream 0 received 1 blocks
14/05/13 13:57:30 INFO JobScheduler: Added jobs for time 1399969650000 ms
14/05/13 13:57:30 INFO JobScheduler: Starting job streaming job 1399969650000 ms.0 from job set of time 1399969650000 ms
14/05/13 13:57:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:57:30 INFO DAGScheduler: Registering RDD 4 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:30 INFO DAGScheduler: Got job 1 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:57:30 INFO DAGScheduler: Final stage: Stage 1 (take at DStream.scala:586)
14/05/13 13:57:30 INFO DAGScheduler: Parents of final stage: List(Stage 2)
14/05/13 13:57:30 INFO DAGScheduler: Missing parents: List(Stage 2)
14/05/13 13:57:30 INFO DAGScheduler: Submitting Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:57:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 2 (MapPartitionsRDD[4] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
14/05/13 13:57:30 INFO TaskSetManager: Starting task 2.0:0 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:57:30 INFO TaskSetManager: Serialized task 2.0:0 as 1517 bytes in 1 ms
14/05/13 13:57:30 INFO Executor: Running task ID 1
14/05/13 13:57:30 INFO BlockManager: Found block input-0-1399969639400 locally
14/05/13 13:57:30 INFO Executor: Serialized size of result for 1 is 749
14/05/13 13:57:30 INFO Executor: Sending result for 1 directly to driver
14/05/13 13:57:30 INFO Executor: Finished task ID 1
14/05/13 13:57:30 INFO TaskSetManager: Finished TID 1 in 181 ms on localhost (progress: 0/1)
14/05/13 13:57:30 INFO TaskSchedulerImpl: Remove TaskSet 2.0 from pool 
14/05/13 13:57:30 INFO DAGScheduler: Completed ShuffleMapTask(2, 0)
14/05/13 13:57:30 INFO DAGScheduler: Stage 2 (combineByKey at ShuffledDStream.scala:42) finished in 0.194 s
14/05/13 13:57:30 INFO DAGScheduler: looking for newly runnable stages
14/05/13 13:57:30 INFO DAGScheduler: running: Set(Stage 0)
14/05/13 13:57:30 INFO DAGScheduler: waiting: Set(Stage 1)
14/05/13 13:57:30 INFO DAGScheduler: failed: Set()
14/05/13 13:57:30 INFO DAGScheduler: Missing parents for Stage 1: List()
14/05/13 13:57:30 INFO DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/13 13:57:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
14/05/13 13:57:30 INFO TaskSetManager: Starting task 1.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:57:30 INFO TaskSetManager: Serialized task 1.0:0 as 1562 bytes in 1 ms
14/05/13 13:57:30 INFO Executor: Running task ID 2
14/05/13 13:57:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 1 blocks
14/05/13 13:57:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  6 ms
14/05/13 13:57:30 INFO Executor: Serialized size of result for 2 is 991
14/05/13 13:57:30 INFO Executor: Sending result for 2 directly to driver
14/05/13 13:57:30 INFO Executor: Finished task ID 2
14/05/13 13:57:30 INFO TaskSetManager: Finished TID 2 in 55 ms on localhost (progress: 0/1)
14/05/13 13:57:30 INFO TaskSchedulerImpl: Remove TaskSet 1.0 from pool 
14/05/13 13:57:30 INFO DAGScheduler: Completed ResultTask(1, 0)
14/05/13 13:57:30 INFO DAGScheduler: Stage 1 (take at DStream.scala:586) finished in 0.059 s
14/05/13 13:57:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.388337988 s
14/05/13 13:57:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:57:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 138 bytes
14/05/13 13:57:30 INFO DAGScheduler: Got job 2 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:57:30 INFO DAGScheduler: Final stage: Stage 3 (take at DStream.scala:586)
14/05/13 13:57:30 INFO DAGScheduler: Parents of final stage: List(Stage 4)
14/05/13 13:57:30 INFO DAGScheduler: Missing parents: List()
14/05/13 13:57:30 INFO DAGScheduler: Submitting Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:57:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
14/05/13 13:57:30 INFO TaskSetManager: Starting task 3.0:0 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:57:30 INFO TaskSetManager: Serialized task 3.0:0 as 1562 bytes in 0 ms
14/05/13 13:57:30 INFO Executor: Running task ID 3
14/05/13 13:57:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-zero-bytes blocks out of 1 blocks
14/05/13 13:57:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:57:30 INFO Executor: Serialized size of result for 3 is 990
14/05/13 13:57:30 INFO Executor: Sending result for 3 directly to driver
14/05/13 13:57:30 INFO Executor: Finished task ID 3
14/05/13 13:57:30 INFO TaskSetManager: Finished TID 3 in 21 ms on localhost (progress: 0/1)
14/05/13 13:57:30 INFO TaskSchedulerImpl: Remove TaskSet 3.0 from pool 
14/05/13 13:57:30 INFO DAGScheduler: Completed ResultTask(3, 1)
14/05/13 13:57:30 INFO DAGScheduler: Stage 3 (take at DStream.scala:586) finished in 0.025 s
14/05/13 13:57:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.041754929 s
14/05/13 13:57:30 INFO JobScheduler: Finished job streaming job 1399969650000 ms.0 from job set of time 1399969650000 ms
14/05/13 13:57:30 INFO JobScheduler: Total delay: 0.523 s for time 1399969650000 ms (execution: 0.455 s)
14/05/13 13:57:40 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:57:40 INFO JobScheduler: Added jobs for time 1399969660000 ms
14/05/13 13:57:40 INFO JobScheduler: Starting job streaming job 1399969660000 ms.0 from job set of time 1399969660000 ms
14/05/13 13:57:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:57:40 INFO DAGScheduler: Registering RDD 10 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:40 INFO DAGScheduler: Got job 3 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:57:40 INFO DAGScheduler: Final stage: Stage 5 (take at DStream.scala:586)
14/05/13 13:57:40 INFO DAGScheduler: Parents of final stage: List(Stage 6)
14/05/13 13:57:40 INFO DAGScheduler: Missing parents: List()
14/05/13 13:57:40 INFO DAGScheduler: Submitting Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:57:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:40 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
14/05/13 13:57:40 INFO TaskSetManager: Starting task 5.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:57:40 INFO TaskSetManager: Serialized task 5.0:0 as 1563 bytes in 0 ms
14/05/13 13:57:40 INFO Executor: Running task ID 4
14/05/13 13:57:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:57:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:57:40 INFO Executor: Serialized size of result for 4 is 813
14/05/13 13:57:40 INFO Executor: Sending result for 4 directly to driver
14/05/13 13:57:40 INFO Executor: Finished task ID 4
14/05/13 13:57:40 INFO TaskSetManager: Finished TID 4 in 18 ms on localhost (progress: 0/1)
14/05/13 13:57:40 INFO DAGScheduler: Completed ResultTask(5, 0)
14/05/13 13:57:40 INFO TaskSchedulerImpl: Remove TaskSet 5.0 from pool 
14/05/13 13:57:40 INFO DAGScheduler: Stage 5 (take at DStream.scala:586) finished in 0.021 s
14/05/13 13:57:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.037033367 s
14/05/13 13:57:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:57:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 82 bytes
14/05/13 13:57:40 INFO DAGScheduler: Got job 4 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:57:40 INFO DAGScheduler: Final stage: Stage 7 (take at DStream.scala:586)
14/05/13 13:57:40 INFO DAGScheduler: Parents of final stage: List(Stage 8)
14/05/13 13:57:40 INFO DAGScheduler: Missing parents: List()
14/05/13 13:57:40 INFO DAGScheduler: Submitting Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:57:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:40 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
14/05/13 13:57:40 INFO TaskSetManager: Starting task 7.0:0 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:57:40 INFO TaskSetManager: Serialized task 7.0:0 as 1563 bytes in 0 ms
14/05/13 13:57:40 INFO Executor: Running task ID 5
14/05/13 13:57:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:57:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:57:40 INFO Executor: Serialized size of result for 5 is 813
14/05/13 13:57:40 INFO Executor: Sending result for 5 directly to driver
14/05/13 13:57:40 INFO Executor: Finished task ID 5
14/05/13 13:57:40 INFO TaskSetManager: Finished TID 5 in 19 ms on localhost (progress: 0/1)
14/05/13 13:57:40 INFO DAGScheduler: Completed ResultTask(7, 1)
14/05/13 13:57:40 INFO TaskSchedulerImpl: Remove TaskSet 7.0 from pool 
14/05/13 13:57:40 INFO DAGScheduler: Stage 7 (take at DStream.scala:586) finished in 0.022 s
14/05/13 13:57:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.038147117 s
14/05/13 13:57:40 INFO JobScheduler: Finished job streaming job 1399969660000 ms.0 from job set of time 1399969660000 ms
14/05/13 13:57:40 INFO JobScheduler: Total delay: 0.113 s for time 1399969660000 ms (execution: 0.088 s)
14/05/13 13:57:50 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:57:50 INFO JobScheduler: Added jobs for time 1399969670000 ms
14/05/13 13:57:50 INFO JobScheduler: Starting job streaming job 1399969670000 ms.0 from job set of time 1399969670000 ms
14/05/13 13:57:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:57:50 INFO DAGScheduler: Registering RDD 16 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:50 INFO DAGScheduler: Got job 5 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:57:50 INFO DAGScheduler: Final stage: Stage 9 (take at DStream.scala:586)
14/05/13 13:57:50 INFO DAGScheduler: Parents of final stage: List(Stage 10)
14/05/13 13:57:50 INFO DAGScheduler: Missing parents: List()
14/05/13 13:57:50 INFO DAGScheduler: Submitting Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:57:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:50 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
14/05/13 13:57:50 INFO TaskSetManager: Starting task 9.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:57:50 INFO TaskSetManager: Serialized task 9.0:0 as 1563 bytes in 1 ms
14/05/13 13:57:50 INFO Executor: Running task ID 6
14/05/13 13:57:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:57:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/13 13:57:50 INFO Executor: Serialized size of result for 6 is 813
14/05/13 13:57:50 INFO Executor: Sending result for 6 directly to driver
14/05/13 13:57:50 INFO Executor: Finished task ID 6
14/05/13 13:57:50 INFO TaskSetManager: Finished TID 6 in 24 ms on localhost (progress: 0/1)
14/05/13 13:57:50 INFO DAGScheduler: Completed ResultTask(9, 0)
14/05/13 13:57:50 INFO TaskSchedulerImpl: Remove TaskSet 9.0 from pool 
14/05/13 13:57:50 INFO DAGScheduler: Stage 9 (take at DStream.scala:586) finished in 0.028 s
14/05/13 13:57:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.044503607 s
14/05/13 13:57:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:57:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 82 bytes
14/05/13 13:57:50 INFO DAGScheduler: Got job 6 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:57:50 INFO DAGScheduler: Final stage: Stage 11 (take at DStream.scala:586)
14/05/13 13:57:50 INFO DAGScheduler: Parents of final stage: List(Stage 12)
14/05/13 13:57:50 INFO DAGScheduler: Missing parents: List()
14/05/13 13:57:50 INFO DAGScheduler: Submitting Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:57:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:57:50 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
14/05/13 13:57:50 INFO TaskSetManager: Starting task 11.0:0 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:57:50 INFO TaskSetManager: Serialized task 11.0:0 as 1563 bytes in 0 ms
14/05/13 13:57:50 INFO Executor: Running task ID 7
14/05/13 13:57:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:57:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:57:50 INFO Executor: Serialized size of result for 7 is 813
14/05/13 13:57:50 INFO Executor: Sending result for 7 directly to driver
14/05/13 13:57:50 INFO Executor: Finished task ID 7
14/05/13 13:57:50 INFO TaskSetManager: Finished TID 7 in 24 ms on localhost (progress: 0/1)
14/05/13 13:57:50 INFO DAGScheduler: Completed ResultTask(11, 1)
14/05/13 13:57:50 INFO TaskSchedulerImpl: Remove TaskSet 11.0 from pool 
14/05/13 13:57:50 INFO DAGScheduler: Stage 11 (take at DStream.scala:586) finished in 0.027 s
14/05/13 13:57:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.044842082 s
14/05/13 13:57:50 INFO JobScheduler: Finished job streaming job 1399969670000 ms.0 from job set of time 1399969670000 ms
14/05/13 13:57:50 INFO JobScheduler: Total delay: 0.122 s for time 1399969670000 ms (execution: 0.100 s)
14/05/13 13:58:00 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:58:00 INFO JobScheduler: Added jobs for time 1399969680000 ms
14/05/13 13:58:00 INFO JobScheduler: Starting job streaming job 1399969680000 ms.0 from job set of time 1399969680000 ms
14/05/13 13:58:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:00 INFO DAGScheduler: Registering RDD 22 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:00 INFO DAGScheduler: Got job 7 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:00 INFO DAGScheduler: Final stage: Stage 13 (take at DStream.scala:586)
14/05/13 13:58:00 INFO DAGScheduler: Parents of final stage: List(Stage 14)
14/05/13 13:58:00 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:00 INFO DAGScheduler: Submitting Stage 13 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 13 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:00 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
14/05/13 13:58:00 INFO TaskSetManager: Starting task 13.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:00 INFO TaskSetManager: Serialized task 13.0:0 as 1564 bytes in 0 ms
14/05/13 13:58:00 INFO Executor: Running task ID 8
14/05/13 13:58:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:58:00 INFO Executor: Serialized size of result for 8 is 813
14/05/13 13:58:00 INFO Executor: Sending result for 8 directly to driver
14/05/13 13:58:00 INFO Executor: Finished task ID 8
14/05/13 13:58:00 INFO TaskSetManager: Finished TID 8 in 19 ms on localhost (progress: 0/1)
14/05/13 13:58:00 INFO DAGScheduler: Completed ResultTask(13, 0)
14/05/13 13:58:00 INFO TaskSchedulerImpl: Remove TaskSet 13.0 from pool 
14/05/13 13:58:00 INFO DAGScheduler: Stage 13 (take at DStream.scala:586) finished in 0.021 s
14/05/13 13:58:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.030209346 s
14/05/13 13:58:00 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 82 bytes
14/05/13 13:58:00 INFO DAGScheduler: Got job 8 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:00 INFO DAGScheduler: Final stage: Stage 15 (take at DStream.scala:586)
14/05/13 13:58:00 INFO DAGScheduler: Parents of final stage: List(Stage 16)
14/05/13 13:58:00 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:00 INFO DAGScheduler: Submitting Stage 15 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:00 INFO DAGScheduler: Submitting 1 missing tasks from Stage 15 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:00 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
14/05/13 13:58:00 INFO TaskSetManager: Starting task 15.0:0 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:00 INFO TaskSetManager: Serialized task 15.0:0 as 1564 bytes in 0 ms
14/05/13 13:58:00 INFO Executor: Running task ID 9
14/05/13 13:58:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:00 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:58:00 INFO Executor: Serialized size of result for 9 is 813
14/05/13 13:58:00 INFO Executor: Sending result for 9 directly to driver
14/05/13 13:58:00 INFO Executor: Finished task ID 9
14/05/13 13:58:00 INFO TaskSetManager: Finished TID 9 in 19 ms on localhost (progress: 0/1)
14/05/13 13:58:00 INFO DAGScheduler: Completed ResultTask(15, 1)
14/05/13 13:58:00 INFO TaskSchedulerImpl: Remove TaskSet 15.0 from pool 
14/05/13 13:58:00 INFO DAGScheduler: Stage 15 (take at DStream.scala:586) finished in 0.022 s
14/05/13 13:58:00 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.036448887 s
14/05/13 13:58:00 INFO JobScheduler: Finished job streaming job 1399969680000 ms.0 from job set of time 1399969680000 ms
14/05/13 13:58:00 INFO JobScheduler: Total delay: 0.102 s for time 1399969680000 ms (execution: 0.077 s)
14/05/13 13:58:10 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:58:10 INFO JobScheduler: Added jobs for time 1399969690000 ms
14/05/13 13:58:10 INFO JobScheduler: Starting job streaming job 1399969690000 ms.0 from job set of time 1399969690000 ms
14/05/13 13:58:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:10 INFO DAGScheduler: Registering RDD 28 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:10 INFO DAGScheduler: Got job 9 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:10 INFO DAGScheduler: Final stage: Stage 17 (take at DStream.scala:586)
14/05/13 13:58:10 INFO DAGScheduler: Parents of final stage: List(Stage 18)
14/05/13 13:58:10 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:10 INFO DAGScheduler: Submitting Stage 17 (MapPartitionsRDD[30] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 17 (MapPartitionsRDD[30] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:10 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
14/05/13 13:58:10 INFO TaskSetManager: Starting task 17.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:10 INFO TaskSetManager: Serialized task 17.0:0 as 1562 bytes in 0 ms
14/05/13 13:58:10 INFO Executor: Running task ID 10
14/05/13 13:58:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:58:10 INFO Executor: Serialized size of result for 10 is 813
14/05/13 13:58:10 INFO Executor: Sending result for 10 directly to driver
14/05/13 13:58:10 INFO Executor: Finished task ID 10
14/05/13 13:58:10 INFO TaskSetManager: Finished TID 10 in 15 ms on localhost (progress: 0/1)
14/05/13 13:58:10 INFO DAGScheduler: Completed ResultTask(17, 0)
14/05/13 13:58:10 INFO TaskSchedulerImpl: Remove TaskSet 17.0 from pool 
14/05/13 13:58:10 INFO DAGScheduler: Stage 17 (take at DStream.scala:586) finished in 0.018 s
14/05/13 13:58:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.03233954 s
14/05/13 13:58:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 82 bytes
14/05/13 13:58:10 INFO DAGScheduler: Got job 10 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:10 INFO DAGScheduler: Final stage: Stage 19 (take at DStream.scala:586)
14/05/13 13:58:10 INFO DAGScheduler: Parents of final stage: List(Stage 20)
14/05/13 13:58:10 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:10 INFO DAGScheduler: Submitting Stage 19 (MapPartitionsRDD[30] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:10 INFO DAGScheduler: Submitting 1 missing tasks from Stage 19 (MapPartitionsRDD[30] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:10 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
14/05/13 13:58:10 INFO TaskSetManager: Starting task 19.0:0 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:10 INFO TaskSetManager: Serialized task 19.0:0 as 1562 bytes in 1 ms
14/05/13 13:58:10 INFO Executor: Running task ID 11
14/05/13 13:58:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:10 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/13 13:58:10 INFO Executor: Serialized size of result for 11 is 813
14/05/13 13:58:10 INFO Executor: Sending result for 11 directly to driver
14/05/13 13:58:10 INFO Executor: Finished task ID 11
14/05/13 13:58:10 INFO TaskSetManager: Finished TID 11 in 21 ms on localhost (progress: 0/1)
14/05/13 13:58:10 INFO DAGScheduler: Completed ResultTask(19, 1)
14/05/13 13:58:10 INFO TaskSchedulerImpl: Remove TaskSet 19.0 from pool 
14/05/13 13:58:10 INFO DAGScheduler: Stage 19 (take at DStream.scala:586) finished in 0.024 s
14/05/13 13:58:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.039030622 s
14/05/13 13:58:10 INFO JobScheduler: Finished job streaming job 1399969690000 ms.0 from job set of time 1399969690000 ms
14/05/13 13:58:10 INFO JobScheduler: Total delay: 0.098 s for time 1399969690000 ms (execution: 0.081 s)
14/05/13 13:58:20 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:58:20 INFO JobScheduler: Added jobs for time 1399969700000 ms
14/05/13 13:58:20 INFO JobScheduler: Starting job streaming job 1399969700000 ms.0 from job set of time 1399969700000 ms
14/05/13 13:58:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:20 INFO DAGScheduler: Registering RDD 34 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:20 INFO DAGScheduler: Got job 11 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:20 INFO DAGScheduler: Final stage: Stage 21 (take at DStream.scala:586)
14/05/13 13:58:20 INFO DAGScheduler: Parents of final stage: List(Stage 22)
14/05/13 13:58:20 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:20 INFO DAGScheduler: Submitting Stage 21 (MapPartitionsRDD[36] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 21 (MapPartitionsRDD[36] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:20 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
14/05/13 13:58:20 INFO TaskSetManager: Starting task 21.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:20 INFO TaskSetManager: Serialized task 21.0:0 as 1564 bytes in 0 ms
14/05/13 13:58:20 INFO Executor: Running task ID 12
14/05/13 13:58:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:58:20 INFO Executor: Serialized size of result for 12 is 813
14/05/13 13:58:20 INFO Executor: Sending result for 12 directly to driver
14/05/13 13:58:20 INFO Executor: Finished task ID 12
14/05/13 13:58:20 INFO TaskSetManager: Finished TID 12 in 16 ms on localhost (progress: 0/1)
14/05/13 13:58:20 INFO DAGScheduler: Completed ResultTask(21, 0)
14/05/13 13:58:20 INFO TaskSchedulerImpl: Remove TaskSet 21.0 from pool 
14/05/13 13:58:20 INFO DAGScheduler: Stage 21 (take at DStream.scala:586) finished in 0.018 s
14/05/13 13:58:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.032118131 s
14/05/13 13:58:20 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 82 bytes
14/05/13 13:58:20 INFO DAGScheduler: Got job 12 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:20 INFO DAGScheduler: Final stage: Stage 23 (take at DStream.scala:586)
14/05/13 13:58:20 INFO DAGScheduler: Parents of final stage: List(Stage 24)
14/05/13 13:58:20 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:20 INFO DAGScheduler: Submitting Stage 23 (MapPartitionsRDD[36] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:20 INFO DAGScheduler: Submitting 1 missing tasks from Stage 23 (MapPartitionsRDD[36] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:20 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
14/05/13 13:58:20 INFO TaskSetManager: Starting task 23.0:0 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:20 INFO TaskSetManager: Serialized task 23.0:0 as 1564 bytes in 1 ms
14/05/13 13:58:20 INFO Executor: Running task ID 13
14/05/13 13:58:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:20 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/13 13:58:20 INFO Executor: Serialized size of result for 13 is 813
14/05/13 13:58:20 INFO Executor: Sending result for 13 directly to driver
14/05/13 13:58:20 INFO Executor: Finished task ID 13
14/05/13 13:58:20 INFO TaskSetManager: Finished TID 13 in 20 ms on localhost (progress: 0/1)
14/05/13 13:58:20 INFO TaskSchedulerImpl: Remove TaskSet 23.0 from pool 
14/05/13 13:58:20 INFO DAGScheduler: Completed ResultTask(23, 1)
14/05/13 13:58:20 INFO DAGScheduler: Stage 23 (take at DStream.scala:586) finished in 0.025 s
14/05/13 13:58:20 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.039429654 s
14/05/13 13:58:20 INFO JobScheduler: Finished job streaming job 1399969700000 ms.0 from job set of time 1399969700000 ms
14/05/13 13:58:20 INFO JobScheduler: Total delay: 0.096 s for time 1399969700000 ms (execution: 0.081 s)
14/05/13 13:58:30 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:58:30 INFO JobScheduler: Added jobs for time 1399969710000 ms
14/05/13 13:58:30 INFO JobScheduler: Starting job streaming job 1399969710000 ms.0 from job set of time 1399969710000 ms
14/05/13 13:58:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:30 INFO DAGScheduler: Registering RDD 40 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:30 INFO DAGScheduler: Got job 13 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:30 INFO DAGScheduler: Final stage: Stage 25 (take at DStream.scala:586)
14/05/13 13:58:30 INFO DAGScheduler: Parents of final stage: List(Stage 26)
14/05/13 13:58:30 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:30 INFO DAGScheduler: Submitting Stage 25 (MapPartitionsRDD[42] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 25 (MapPartitionsRDD[42] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:30 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
14/05/13 13:58:30 INFO TaskSetManager: Starting task 25.0:0 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:30 INFO TaskSetManager: Serialized task 25.0:0 as 1565 bytes in 1 ms
14/05/13 13:58:30 INFO Executor: Running task ID 14
14/05/13 13:58:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/13 13:58:30 INFO Executor: Serialized size of result for 14 is 813
14/05/13 13:58:30 INFO Executor: Sending result for 14 directly to driver
14/05/13 13:58:30 INFO Executor: Finished task ID 14
14/05/13 13:58:30 INFO TaskSetManager: Finished TID 14 in 20 ms on localhost (progress: 0/1)
14/05/13 13:58:30 INFO DAGScheduler: Completed ResultTask(25, 0)
14/05/13 13:58:30 INFO TaskSchedulerImpl: Remove TaskSet 25.0 from pool 
14/05/13 13:58:30 INFO DAGScheduler: Stage 25 (take at DStream.scala:586) finished in 0.023 s
14/05/13 13:58:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.037255547 s
14/05/13 13:58:30 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 82 bytes
14/05/13 13:58:30 INFO DAGScheduler: Got job 14 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:30 INFO DAGScheduler: Final stage: Stage 27 (take at DStream.scala:586)
14/05/13 13:58:30 INFO DAGScheduler: Parents of final stage: List(Stage 28)
14/05/13 13:58:30 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:30 INFO DAGScheduler: Submitting Stage 27 (MapPartitionsRDD[42] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:30 INFO DAGScheduler: Submitting 1 missing tasks from Stage 27 (MapPartitionsRDD[42] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:30 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
14/05/13 13:58:30 INFO TaskSetManager: Starting task 27.0:0 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:30 INFO TaskSetManager: Serialized task 27.0:0 as 1565 bytes in 0 ms
14/05/13 13:58:30 INFO Executor: Running task ID 15
14/05/13 13:58:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:30 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/13 13:58:30 INFO Executor: Serialized size of result for 15 is 813
14/05/13 13:58:30 INFO Executor: Sending result for 15 directly to driver
14/05/13 13:58:30 INFO Executor: Finished task ID 15
14/05/13 13:58:30 INFO TaskSetManager: Finished TID 15 in 23 ms on localhost (progress: 0/1)
14/05/13 13:58:30 INFO DAGScheduler: Completed ResultTask(27, 1)
14/05/13 13:58:30 INFO TaskSchedulerImpl: Remove TaskSet 27.0 from pool 
14/05/13 13:58:30 INFO DAGScheduler: Stage 27 (take at DStream.scala:586) finished in 0.026 s
14/05/13 13:58:30 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.039417264 s
14/05/13 13:58:30 INFO JobScheduler: Finished job streaming job 1399969710000 ms.0 from job set of time 1399969710000 ms
14/05/13 13:58:30 INFO JobScheduler: Total delay: 0.105 s for time 1399969710000 ms (execution: 0.085 s)
14/05/13 13:58:40 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 13:58:40 INFO JobScheduler: Added jobs for time 1399969720000 ms
14/05/13 13:58:40 INFO JobScheduler: Starting job streaming job 1399969720000 ms.0 from job set of time 1399969720000 ms
14/05/13 13:58:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:40 INFO DAGScheduler: Registering RDD 46 (combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:40 INFO DAGScheduler: Got job 15 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:40 INFO DAGScheduler: Final stage: Stage 29 (take at DStream.scala:586)
14/05/13 13:58:40 INFO DAGScheduler: Parents of final stage: List(Stage 30)
14/05/13 13:58:40 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:40 INFO DAGScheduler: Submitting Stage 29 (MapPartitionsRDD[48] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 29 (MapPartitionsRDD[48] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:40 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
14/05/13 13:58:40 INFO TaskSetManager: Starting task 29.0:0 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:40 INFO TaskSetManager: Serialized task 29.0:0 as 1563 bytes in 0 ms
14/05/13 13:58:40 INFO Executor: Running task ID 16
14/05/13 13:58:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:58:40 INFO Executor: Serialized size of result for 16 is 813
14/05/13 13:58:40 INFO Executor: Sending result for 16 directly to driver
14/05/13 13:58:40 INFO Executor: Finished task ID 16
14/05/13 13:58:40 INFO TaskSetManager: Finished TID 16 in 18 ms on localhost (progress: 0/1)
14/05/13 13:58:40 INFO TaskSchedulerImpl: Remove TaskSet 29.0 from pool 
14/05/13 13:58:40 INFO DAGScheduler: Completed ResultTask(29, 0)
14/05/13 13:58:40 INFO DAGScheduler: Stage 29 (take at DStream.scala:586) finished in 0.020 s
14/05/13 13:58:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.032103446 s
14/05/13 13:58:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 13:58:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 82 bytes
14/05/13 13:58:40 INFO DAGScheduler: Got job 16 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 13:58:40 INFO DAGScheduler: Final stage: Stage 31 (take at DStream.scala:586)
14/05/13 13:58:40 INFO DAGScheduler: Parents of final stage: List(Stage 32)
14/05/13 13:58:40 INFO DAGScheduler: Missing parents: List()
14/05/13 13:58:40 INFO DAGScheduler: Submitting Stage 31 (MapPartitionsRDD[48] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 13:58:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 31 (MapPartitionsRDD[48] at combineByKey at ShuffledDStream.scala:42)
14/05/13 13:58:40 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
14/05/13 13:58:40 INFO TaskSetManager: Starting task 31.0:0 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 13:58:40 INFO TaskSetManager: Serialized task 31.0:0 as 1563 bytes in 0 ms
14/05/13 13:58:40 INFO Executor: Running task ID 17
14/05/13 13:58:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 13:58:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 13:58:40 INFO Executor: Serialized size of result for 17 is 813
14/05/13 13:58:40 INFO Executor: Sending result for 17 directly to driver
14/05/13 13:58:40 INFO Executor: Finished task ID 17
14/05/13 13:58:40 INFO TaskSetManager: Finished TID 17 in 12 ms on localhost (progress: 0/1)
14/05/13 13:58:40 INFO DAGScheduler: Completed ResultTask(31, 1)
14/05/13 13:58:40 INFO TaskSchedulerImpl: Remove TaskSet 31.0 from pool 
14/05/13 13:58:40 INFO DAGScheduler: Stage 31 (take at DStream.scala:586) finished in 0.014 s
14/05/13 13:58:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.023436774 s
14/05/13 13:58:40 INFO JobScheduler: Finished job streaming job 1399969720000 ms.0 from job set of time 1399969720000 ms
14/05/13 13:58:40 INFO JobScheduler: Total delay: 0.080 s for time 1399969720000 ms (execution: 0.063 s)
14/05/13 13:59:52 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/13 13:59:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 13:59:54 INFO Slf4jLogger: Slf4jLogger started
14/05/13 13:59:54 INFO Remoting: Starting remoting
14/05/13 13:59:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu.local:41844]
14/05/13 13:59:54 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu.local:41844]
14/05/13 13:59:54 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 13:59:54 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513135954-4fb8
14/05/13 13:59:54 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 13:59:54 INFO ConnectionManager: Bound socket to port 51408 with id = ConnectionManagerId(ubuntu.local,51408)
14/05/13 13:59:54 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 13:59:54 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu.local:51408 with 640.2 MB RAM
14/05/13 13:59:54 INFO BlockManagerMaster: Registered BlockManager
14/05/13 13:59:54 INFO HttpServer: Starting HTTP Server
14/05/13 13:59:54 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:57115
14/05/13 13:59:54 INFO SparkEnv: Registering MapOutputTracker
14/05/13 13:59:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9da19f75-71fd-411a-875e-222952b5b06b
14/05/13 13:59:54 INFO HttpServer: Starting HTTP Server
14/05/13 13:59:55 INFO SparkUI: Started Spark Web UI at http://ubuntu.local:4040
14/05/13 13:59:55 INFO ConnectionManager: Selector thread was interrupted!
14/05/13 14:00:31 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/13 14:00:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 14:00:34 INFO Slf4jLogger: Slf4jLogger started
14/05/13 14:00:34 INFO Remoting: Starting remoting
14/05/13 14:00:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu.local:55209]
14/05/13 14:00:34 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu.local:55209]
14/05/13 14:00:34 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 14:00:34 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513140034-fcf7
14/05/13 14:00:34 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 14:00:34 INFO ConnectionManager: Bound socket to port 56952 with id = ConnectionManagerId(ubuntu.local,56952)
14/05/13 14:00:34 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 14:00:34 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu.local:56952 with 640.2 MB RAM
14/05/13 14:00:34 INFO BlockManagerMaster: Registered BlockManager
14/05/13 14:00:34 INFO HttpServer: Starting HTTP Server
14/05/13 14:00:34 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:37226
14/05/13 14:00:34 INFO SparkEnv: Registering MapOutputTracker
14/05/13 14:00:34 INFO HttpFileServer: HTTP File server directory is /tmp/spark-696f742b-b06e-48e3-be97-71db75d8d5f1
14/05/13 14:00:34 INFO HttpServer: Starting HTTP Server
14/05/13 14:00:35 INFO SparkUI: Started Spark Web UI at http://ubuntu.local:4040
14/05/13 14:00:35 INFO NetworkInputTracker: NetworkInputTracker started
14/05/13 14:00:35 INFO SparkContext: Starting job: runJob at NetworkInputTracker.scala:182
14/05/13 14:00:35 INFO DAGScheduler: Got job 0 (runJob at NetworkInputTracker.scala:182) with 1 output partitions (allowLocal=false)
14/05/13 14:00:35 INFO DAGScheduler: Final stage: Stage 0 (runJob at NetworkInputTracker.scala:182)
14/05/13 14:00:35 INFO DAGScheduler: Parents of final stage: List()
14/05/13 14:00:35 INFO DAGScheduler: Missing parents: List()
14/05/13 14:00:35 INFO DAGScheduler: Submitting Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165), which has no missing parents
14/05/13 14:00:36 INFO DAGScheduler: Submitting 1 missing tasks from Stage 0 (ParallelCollectionRDD[0] at makeRDD at NetworkInputTracker.scala:165)
14/05/13 14:00:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
14/05/13 14:00:36 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:36 INFO TaskSetManager: Serialized task 0.0:0 as 1978 bytes in 9 ms
14/05/13 14:00:36 INFO Executor: Running task ID 0
14/05/13 14:00:36 INFO SocketReceiver: Connecting to localhost:9999
14/05/13 14:00:36 INFO SocketReceiver: Attempting to register with tracker
14/05/13 14:00:36 INFO SocketReceiver: Connected to localhost:9999
14/05/13 14:00:36 INFO NetworkReceiver$BlockGenerator: Data handler started
14/05/13 14:00:36 INFO NetworkReceiver$BlockGenerator: Block pushing thread started
14/05/13 14:00:36 INFO NetworkInputTracker: Registered receiver for network stream 0 from akka://spark
14/05/13 14:00:36 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 14:00:36 INFO ShuffledDStream: metadataCleanupDelay = 3600
14/05/13 14:00:36 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 14:00:36 INFO FlatMappedDStream: metadataCleanupDelay = 3600
14/05/13 14:00:36 INFO SocketInputDStream: metadataCleanupDelay = 3600
14/05/13 14:00:36 INFO SocketInputDStream: Slide time = 5000 ms
14/05/13 14:00:36 INFO SocketInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:00:36 INFO SocketInputDStream: Checkpoint interval = null
14/05/13 14:00:36 INFO SocketInputDStream: Remember duration = 5000 ms
14/05/13 14:00:36 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@24a038ab
14/05/13 14:00:36 INFO FlatMappedDStream: Slide time = 5000 ms
14/05/13 14:00:36 INFO FlatMappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:00:36 INFO FlatMappedDStream: Checkpoint interval = null
14/05/13 14:00:36 INFO FlatMappedDStream: Remember duration = 5000 ms
14/05/13 14:00:36 INFO FlatMappedDStream: Initialized and validated org.apache.spark.streaming.dstream.FlatMappedDStream@12e87556
14/05/13 14:00:36 INFO MappedDStream: Slide time = 5000 ms
14/05/13 14:00:36 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:00:36 INFO MappedDStream: Checkpoint interval = null
14/05/13 14:00:36 INFO MappedDStream: Remember duration = 5000 ms
14/05/13 14:00:36 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@5b6f6acc
14/05/13 14:00:36 INFO ShuffledDStream: Slide time = 5000 ms
14/05/13 14:00:36 INFO ShuffledDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:00:36 INFO ShuffledDStream: Checkpoint interval = null
14/05/13 14:00:36 INFO ShuffledDStream: Remember duration = 5000 ms
14/05/13 14:00:36 INFO ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@6fcca5f9
14/05/13 14:00:36 INFO ForEachDStream: Slide time = 5000 ms
14/05/13 14:00:36 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:00:36 INFO ForEachDStream: Checkpoint interval = null
14/05/13 14:00:36 INFO ForEachDStream: Remember duration = 5000 ms
14/05/13 14:00:36 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@64a4b7c6
14/05/13 14:00:36 INFO JobGenerator: JobGenerator started at 1399969840000 ms
14/05/13 14:00:36 INFO JobScheduler: JobScheduler started
14/05/13 14:00:40 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 14:00:40 INFO JobScheduler: Added jobs for time 1399969840000 ms
14/05/13 14:00:40 INFO JobScheduler: Starting job streaming job 1399969840000 ms.0 from job set of time 1399969840000 ms
14/05/13 14:00:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:00:40 INFO DAGScheduler: Registering RDD 4 (combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:40 INFO DAGScheduler: Got job 1 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:00:40 INFO DAGScheduler: Final stage: Stage 1 (take at DStream.scala:586)
14/05/13 14:00:40 INFO DAGScheduler: Parents of final stage: List(Stage 2)
14/05/13 14:00:40 INFO DAGScheduler: Missing parents: List()
14/05/13 14:00:40 INFO DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 14:00:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
14/05/13 14:00:40 INFO TaskSetManager: Starting task 1.0:0 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:40 INFO TaskSetManager: Serialized task 1.0:0 as 1562 bytes in 0 ms
14/05/13 14:00:40 INFO Executor: Running task ID 1
14/05/13 14:00:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 14:00:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  5 ms
14/05/13 14:00:40 INFO Executor: Serialized size of result for 1 is 813
14/05/13 14:00:40 INFO Executor: Sending result for 1 directly to driver
14/05/13 14:00:40 INFO Executor: Finished task ID 1
14/05/13 14:00:40 INFO TaskSetManager: Finished TID 1 in 153 ms on localhost (progress: 0/1)
14/05/13 14:00:40 INFO TaskSchedulerImpl: Remove TaskSet 1.0 from pool 
14/05/13 14:00:40 INFO DAGScheduler: Completed ResultTask(1, 0)
14/05/13 14:00:40 INFO DAGScheduler: Stage 1 (take at DStream.scala:586) finished in 0.163 s
14/05/13 14:00:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.2403453 s
14/05/13 14:00:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:00:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 82 bytes
14/05/13 14:00:40 INFO DAGScheduler: Got job 2 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:00:40 INFO DAGScheduler: Final stage: Stage 3 (take at DStream.scala:586)
14/05/13 14:00:40 INFO DAGScheduler: Parents of final stage: List(Stage 4)
14/05/13 14:00:40 INFO DAGScheduler: Missing parents: List()
14/05/13 14:00:40 INFO DAGScheduler: Submitting Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 14:00:40 INFO DAGScheduler: Submitting 1 missing tasks from Stage 3 (MapPartitionsRDD[6] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
14/05/13 14:00:40 INFO TaskSetManager: Starting task 3.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:40 INFO TaskSetManager: Serialized task 3.0:0 as 1562 bytes in 0 ms
14/05/13 14:00:40 INFO Executor: Running task ID 2
14/05/13 14:00:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 14:00:40 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 14:00:40 INFO Executor: Serialized size of result for 2 is 813
14/05/13 14:00:40 INFO Executor: Sending result for 2 directly to driver
14/05/13 14:00:40 INFO Executor: Finished task ID 2
14/05/13 14:00:40 INFO TaskSetManager: Finished TID 2 in 17 ms on localhost (progress: 0/1)
14/05/13 14:00:40 INFO DAGScheduler: Completed ResultTask(3, 1)
14/05/13 14:00:40 INFO TaskSchedulerImpl: Remove TaskSet 3.0 from pool 
14/05/13 14:00:40 INFO DAGScheduler: Stage 3 (take at DStream.scala:586) finished in 0.020 s
14/05/13 14:00:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.034502745 s
14/05/13 14:00:40 INFO JobScheduler: Finished job streaming job 1399969840000 ms.0 from job set of time 1399969840000 ms
14/05/13 14:00:40 INFO JobScheduler: Total delay: 0.365 s for time 1399969840000 ms (execution: 0.297 s)
14/05/13 14:00:45 INFO NetworkInputTracker: Stream 0 received 0 blocks
14/05/13 14:00:45 INFO JobScheduler: Added jobs for time 1399969845000 ms
14/05/13 14:00:45 INFO JobScheduler: Starting job streaming job 1399969845000 ms.0 from job set of time 1399969845000 ms
14/05/13 14:00:45 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:00:45 INFO DAGScheduler: Registering RDD 10 (combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:45 INFO DAGScheduler: Got job 3 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:00:45 INFO DAGScheduler: Final stage: Stage 5 (take at DStream.scala:586)
14/05/13 14:00:45 INFO DAGScheduler: Parents of final stage: List(Stage 6)
14/05/13 14:00:45 INFO DAGScheduler: Missing parents: List()
14/05/13 14:00:45 INFO DAGScheduler: Submitting Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 14:00:45 INFO DAGScheduler: Submitting 1 missing tasks from Stage 5 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
14/05/13 14:00:45 INFO TaskSetManager: Starting task 5.0:0 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:45 INFO TaskSetManager: Serialized task 5.0:0 as 1563 bytes in 0 ms
14/05/13 14:00:45 INFO Executor: Running task ID 3
14/05/13 14:00:45 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 14:00:45 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 14:00:45 INFO Executor: Serialized size of result for 3 is 813
14/05/13 14:00:45 INFO Executor: Sending result for 3 directly to driver
14/05/13 14:00:45 INFO Executor: Finished task ID 3
14/05/13 14:00:45 INFO TaskSetManager: Finished TID 3 in 20 ms on localhost (progress: 0/1)
14/05/13 14:00:45 INFO DAGScheduler: Completed ResultTask(5, 0)
14/05/13 14:00:45 INFO TaskSchedulerImpl: Remove TaskSet 5.0 from pool 
14/05/13 14:00:45 INFO DAGScheduler: Stage 5 (take at DStream.scala:586) finished in 0.024 s
14/05/13 14:00:45 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.03864429 s
14/05/13 14:00:45 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:00:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 82 bytes
14/05/13 14:00:45 INFO DAGScheduler: Got job 4 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:00:45 INFO DAGScheduler: Final stage: Stage 7 (take at DStream.scala:586)
14/05/13 14:00:45 INFO DAGScheduler: Parents of final stage: List(Stage 8)
14/05/13 14:00:45 INFO DAGScheduler: Missing parents: List()
14/05/13 14:00:45 INFO DAGScheduler: Submitting Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 14:00:45 INFO DAGScheduler: Submitting 1 missing tasks from Stage 7 (MapPartitionsRDD[12] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:45 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
14/05/13 14:00:45 INFO TaskSetManager: Starting task 7.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:45 INFO TaskSetManager: Serialized task 7.0:0 as 1563 bytes in 0 ms
14/05/13 14:00:45 INFO Executor: Running task ID 4
14/05/13 14:00:45 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 0 blocks
14/05/13 14:00:45 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 14:00:45 INFO Executor: Serialized size of result for 4 is 813
14/05/13 14:00:45 INFO Executor: Sending result for 4 directly to driver
14/05/13 14:00:45 INFO Executor: Finished task ID 4
14/05/13 14:00:45 INFO TaskSetManager: Finished TID 4 in 20 ms on localhost (progress: 0/1)
14/05/13 14:00:45 INFO DAGScheduler: Completed ResultTask(7, 1)
14/05/13 14:00:45 INFO TaskSchedulerImpl: Remove TaskSet 7.0 from pool 
14/05/13 14:00:45 INFO DAGScheduler: Stage 7 (take at DStream.scala:586) finished in 0.023 s
14/05/13 14:00:45 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.040295548 s
14/05/13 14:00:45 INFO JobScheduler: Finished job streaming job 1399969845000 ms.0 from job set of time 1399969845000 ms
14/05/13 14:00:45 INFO JobScheduler: Total delay: 0.111 s for time 1399969845000 ms (execution: 0.091 s)
14/05/13 14:00:47 INFO MemoryStore: ensureFreeSpace(11) called with curMem=0, maxMem=671298355
14/05/13 14:00:47 INFO MemoryStore: Block input-0-1399969846800 stored as bytes to memory (size 11.0 B, free 640.2 MB)
14/05/13 14:00:47 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969846800 in memory on ubuntu.local:56952 (size: 11.0 B, free: 640.2 MB)
14/05/13 14:00:47 INFO BlockManagerMaster: Updated info of block input-0-1399969846800
14/05/13 14:00:47 INFO SendingConnection: Initiating connection to [ubuntu.local/10.8.7.208:56952]
14/05/13 14:00:47 INFO ConnectionManager: Accepted connection from [ubuntu.local/10.8.7.208]
14/05/13 14:00:47 INFO SendingConnection: Connected to [ubuntu.local/10.8.7.208:56952], 1 messages pending
14/05/13 14:00:47 WARN BlockManager: Block input-0-1399969846800 already exists on this machine; not re-adding it
14/05/13 14:00:47 INFO MemoryStore: ensureFreeSpace(8) called with curMem=11, maxMem=671298355
14/05/13 14:00:47 INFO MemoryStore: Block input-0-1399969847000 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/13 14:00:47 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969847000 in memory on ubuntu.local:56952 (size: 8.0 B, free: 640.2 MB)
14/05/13 14:00:47 INFO BlockManagerMaster: Updated info of block input-0-1399969847000
14/05/13 14:00:47 WARN BlockManager: Block input-0-1399969847000 already exists on this machine; not re-adding it
14/05/13 14:00:47 INFO MemoryStore: ensureFreeSpace(9) called with curMem=19, maxMem=671298355
14/05/13 14:00:47 INFO MemoryStore: Block input-0-1399969847400 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/13 14:00:47 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969847400 in memory on ubuntu.local:56952 (size: 9.0 B, free: 640.2 MB)
14/05/13 14:00:47 INFO BlockManagerMaster: Updated info of block input-0-1399969847400
14/05/13 14:00:47 WARN BlockManager: Block input-0-1399969847400 already exists on this machine; not re-adding it
14/05/13 14:00:47 INFO MemoryStore: ensureFreeSpace(7) called with curMem=28, maxMem=671298355
14/05/13 14:00:47 INFO MemoryStore: Block input-0-1399969847600 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/13 14:00:47 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969847600 in memory on ubuntu.local:56952 (size: 7.0 B, free: 640.2 MB)
14/05/13 14:00:47 INFO BlockManagerMaster: Updated info of block input-0-1399969847600
14/05/13 14:00:47 WARN BlockManager: Block input-0-1399969847600 already exists on this machine; not re-adding it
14/05/13 14:00:48 INFO MemoryStore: ensureFreeSpace(9) called with curMem=35, maxMem=671298355
14/05/13 14:00:48 INFO MemoryStore: Block input-0-1399969848000 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/13 14:00:48 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969848000 in memory on ubuntu.local:56952 (size: 9.0 B, free: 640.2 MB)
14/05/13 14:00:48 INFO BlockManagerMaster: Updated info of block input-0-1399969848000
14/05/13 14:00:48 WARN BlockManager: Block input-0-1399969848000 already exists on this machine; not re-adding it
14/05/13 14:00:48 INFO MemoryStore: ensureFreeSpace(8) called with curMem=44, maxMem=671298355
14/05/13 14:00:48 INFO MemoryStore: Block input-0-1399969848200 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/13 14:00:48 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969848200 in memory on ubuntu.local:56952 (size: 8.0 B, free: 640.2 MB)
14/05/13 14:00:48 INFO BlockManagerMaster: Updated info of block input-0-1399969848200
14/05/13 14:00:49 WARN BlockManager: Block input-0-1399969848200 already exists on this machine; not re-adding it
14/05/13 14:00:49 INFO MemoryStore: ensureFreeSpace(7) called with curMem=52, maxMem=671298355
14/05/13 14:00:49 INFO MemoryStore: Block input-0-1399969848600 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/13 14:00:49 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969848600 in memory on ubuntu.local:56952 (size: 7.0 B, free: 640.2 MB)
14/05/13 14:00:49 INFO BlockManagerMaster: Updated info of block input-0-1399969848600
14/05/13 14:00:49 WARN BlockManager: Block input-0-1399969848600 already exists on this machine; not re-adding it
14/05/13 14:00:49 INFO MemoryStore: ensureFreeSpace(9) called with curMem=59, maxMem=671298355
14/05/13 14:00:49 INFO MemoryStore: Block input-0-1399969849000 stored as bytes to memory (size 9.0 B, free 640.2 MB)
14/05/13 14:00:49 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969849000 in memory on ubuntu.local:56952 (size: 9.0 B, free: 640.2 MB)
14/05/13 14:00:49 INFO BlockManagerMaster: Updated info of block input-0-1399969849000
14/05/13 14:00:49 WARN BlockManager: Block input-0-1399969849000 already exists on this machine; not re-adding it
14/05/13 14:00:50 INFO NetworkInputTracker: Stream 0 received 7 blocks
14/05/13 14:00:50 INFO JobScheduler: Added jobs for time 1399969850000 ms
14/05/13 14:00:50 INFO JobScheduler: Starting job streaming job 1399969850000 ms.0 from job set of time 1399969850000 ms
14/05/13 14:00:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:00:50 INFO DAGScheduler: Registering RDD 16 (combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:50 INFO DAGScheduler: Got job 5 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:00:50 INFO DAGScheduler: Final stage: Stage 9 (take at DStream.scala:586)
14/05/13 14:00:50 INFO DAGScheduler: Parents of final stage: List(Stage 10)
14/05/13 14:00:50 INFO DAGScheduler: Missing parents: List(Stage 10)
14/05/13 14:00:50 INFO DAGScheduler: Submitting Stage 10 (MapPartitionsRDD[16] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 14:00:50 INFO DAGScheduler: Submitting 7 missing tasks from Stage 10 (MapPartitionsRDD[16] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:50 INFO TaskSchedulerImpl: Adding task set 10.0 with 7 tasks
14/05/13 14:00:50 INFO TaskSetManager: Starting task 10.0:0 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:50 INFO TaskSetManager: Serialized task 10.0:0 as 1517 bytes in 2 ms
14/05/13 14:00:50 INFO Executor: Running task ID 5
14/05/13 14:00:50 INFO BlockManager: Found block input-0-1399969846800 locally
14/05/13 14:00:50 INFO Executor: Serialized size of result for 5 is 749
14/05/13 14:00:50 INFO Executor: Sending result for 5 directly to driver
14/05/13 14:00:50 INFO Executor: Finished task ID 5
14/05/13 14:00:50 INFO TaskSetManager: Starting task 10.0:1 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:50 INFO TaskSetManager: Serialized task 10.0:1 as 1517 bytes in 0 ms
14/05/13 14:00:50 INFO Executor: Running task ID 6
14/05/13 14:00:50 INFO TaskSetManager: Finished TID 5 in 54 ms on localhost (progress: 0/7)
14/05/13 14:00:50 INFO DAGScheduler: Completed ShuffleMapTask(10, 0)
14/05/13 14:00:50 INFO BlockManager: Found block input-0-1399969847000 locally
14/05/13 14:00:50 INFO Executor: Serialized size of result for 6 is 749
14/05/13 14:00:50 INFO Executor: Sending result for 6 directly to driver
14/05/13 14:00:50 INFO Executor: Finished task ID 6
14/05/13 14:00:50 INFO TaskSetManager: Starting task 10.0:2 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:50 INFO TaskSetManager: Serialized task 10.0:2 as 1517 bytes in 1 ms
14/05/13 14:00:50 INFO TaskSetManager: Finished TID 6 in 19 ms on localhost (progress: 1/7)
14/05/13 14:00:50 INFO Executor: Running task ID 7
14/05/13 14:00:50 INFO DAGScheduler: Completed ShuffleMapTask(10, 1)
14/05/13 14:00:50 INFO BlockManager: Found block input-0-1399969847400 locally
14/05/13 14:00:50 INFO Executor: Serialized size of result for 7 is 749
14/05/13 14:00:50 INFO Executor: Sending result for 7 directly to driver
14/05/13 14:00:50 INFO Executor: Finished task ID 7
14/05/13 14:00:50 INFO TaskSetManager: Starting task 10.0:3 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:50 INFO TaskSetManager: Serialized task 10.0:3 as 1517 bytes in 1 ms
14/05/13 14:00:50 INFO TaskSetManager: Finished TID 7 in 19 ms on localhost (progress: 2/7)
14/05/13 14:00:50 INFO Executor: Running task ID 8
14/05/13 14:00:50 INFO DAGScheduler: Completed ShuffleMapTask(10, 2)
14/05/13 14:00:50 INFO BlockManager: Found block input-0-1399969847600 locally
14/05/13 14:00:50 INFO Executor: Serialized size of result for 8 is 749
14/05/13 14:00:50 INFO Executor: Sending result for 8 directly to driver
14/05/13 14:00:50 INFO Executor: Finished task ID 8
14/05/13 14:00:50 INFO TaskSetManager: Starting task 10.0:4 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:50 INFO TaskSetManager: Serialized task 10.0:4 as 1517 bytes in 0 ms
14/05/13 14:00:50 INFO Executor: Running task ID 9
14/05/13 14:00:50 INFO TaskSetManager: Finished TID 8 in 22 ms on localhost (progress: 3/7)
14/05/13 14:00:50 INFO DAGScheduler: Completed ShuffleMapTask(10, 3)
14/05/13 14:00:50 INFO BlockManager: Found block input-0-1399969848000 locally
14/05/13 14:00:50 INFO Executor: Serialized size of result for 9 is 749
14/05/13 14:00:50 INFO Executor: Sending result for 9 directly to driver
14/05/13 14:00:50 INFO Executor: Finished task ID 9
14/05/13 14:00:50 INFO TaskSetManager: Starting task 10.0:5 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:50 INFO TaskSetManager: Serialized task 10.0:5 as 1517 bytes in 0 ms
14/05/13 14:00:50 INFO Executor: Running task ID 10
14/05/13 14:00:50 INFO TaskSetManager: Finished TID 9 in 19 ms on localhost (progress: 4/7)
14/05/13 14:00:50 INFO DAGScheduler: Completed ShuffleMapTask(10, 4)
14/05/13 14:00:50 INFO BlockManager: Found block input-0-1399969848200 locally
14/05/13 14:00:50 INFO Executor: Serialized size of result for 10 is 749
14/05/13 14:00:50 INFO Executor: Sending result for 10 directly to driver
14/05/13 14:00:50 INFO Executor: Finished task ID 10
14/05/13 14:00:50 INFO TaskSetManager: Starting task 10.0:6 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:50 INFO TaskSetManager: Serialized task 10.0:6 as 1517 bytes in 1 ms
14/05/13 14:00:50 INFO Executor: Running task ID 11
14/05/13 14:00:50 INFO TaskSetManager: Finished TID 10 in 21 ms on localhost (progress: 5/7)
14/05/13 14:00:50 INFO DAGScheduler: Completed ShuffleMapTask(10, 5)
14/05/13 14:00:50 INFO BlockManager: Found block input-0-1399969848600 locally
14/05/13 14:00:50 INFO Executor: Serialized size of result for 11 is 749
14/05/13 14:00:50 INFO Executor: Sending result for 11 directly to driver
14/05/13 14:00:50 INFO Executor: Finished task ID 11
14/05/13 14:00:50 INFO TaskSetManager: Finished TID 11 in 19 ms on localhost (progress: 6/7)
14/05/13 14:00:50 INFO TaskSchedulerImpl: Remove TaskSet 10.0 from pool 
14/05/13 14:00:50 INFO DAGScheduler: Completed ShuffleMapTask(10, 6)
14/05/13 14:00:50 INFO DAGScheduler: Stage 10 (combineByKey at ShuffledDStream.scala:42) finished in 0.163 s
14/05/13 14:00:50 INFO DAGScheduler: looking for newly runnable stages
14/05/13 14:00:50 INFO DAGScheduler: running: Set(Stage 0)
14/05/13 14:00:50 INFO DAGScheduler: waiting: Set(Stage 9)
14/05/13 14:00:50 INFO DAGScheduler: failed: Set()
14/05/13 14:00:50 INFO DAGScheduler: Missing parents for Stage 9: List()
14/05/13 14:00:50 INFO DAGScheduler: Submitting Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/13 14:00:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 9 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:50 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
14/05/13 14:00:50 INFO TaskSetManager: Starting task 9.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:50 INFO TaskSetManager: Serialized task 9.0:0 as 1563 bytes in 1 ms
14/05/13 14:00:50 INFO MemoryStore: ensureFreeSpace(8) called with curMem=68, maxMem=671298355
14/05/13 14:00:50 INFO Executor: Running task ID 12
14/05/13 14:00:50 INFO MemoryStore: Block input-0-1399969849400 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/13 14:00:50 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969849400 in memory on ubuntu.local:56952 (size: 8.0 B, free: 640.2 MB)
14/05/13 14:00:50 INFO BlockManagerMaster: Updated info of block input-0-1399969849400
14/05/13 14:00:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 7 non-zero-bytes blocks out of 7 blocks
14/05/13 14:00:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  1 ms
14/05/13 14:00:50 INFO Executor: Serialized size of result for 12 is 1041
14/05/13 14:00:50 INFO Executor: Sending result for 12 directly to driver
14/05/13 14:00:50 INFO Executor: Finished task ID 12
14/05/13 14:00:50 INFO TaskSetManager: Finished TID 12 in 46 ms on localhost (progress: 0/1)
14/05/13 14:00:50 INFO DAGScheduler: Completed ResultTask(9, 0)
14/05/13 14:00:50 INFO TaskSchedulerImpl: Remove TaskSet 9.0 from pool 
14/05/13 14:00:50 INFO DAGScheduler: Stage 9 (take at DStream.scala:586) finished in 0.051 s
14/05/13 14:00:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.266866365 s
14/05/13 14:00:50 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:00:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 148 bytes
14/05/13 14:00:50 INFO DAGScheduler: Got job 6 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:00:50 INFO DAGScheduler: Final stage: Stage 11 (take at DStream.scala:586)
14/05/13 14:00:50 INFO DAGScheduler: Parents of final stage: List(Stage 12)
14/05/13 14:00:50 INFO DAGScheduler: Missing parents: List()
14/05/13 14:00:50 INFO DAGScheduler: Submitting Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 14:00:50 INFO DAGScheduler: Submitting 1 missing tasks from Stage 11 (MapPartitionsRDD[18] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:50 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
14/05/13 14:00:50 INFO TaskSetManager: Starting task 11.0:0 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:50 INFO TaskSetManager: Serialized task 11.0:0 as 1563 bytes in 0 ms
14/05/13 14:00:50 INFO Executor: Running task ID 13
14/05/13 14:00:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 7 blocks
14/05/13 14:00:50 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 14:00:50 INFO Executor: Serialized size of result for 13 is 813
14/05/13 14:00:50 INFO Executor: Sending result for 13 directly to driver
14/05/13 14:00:50 INFO Executor: Finished task ID 13
14/05/13 14:00:50 INFO TaskSetManager: Finished TID 13 in 22 ms on localhost (progress: 0/1)
14/05/13 14:00:50 INFO DAGScheduler: Completed ResultTask(11, 1)
14/05/13 14:00:50 INFO TaskSchedulerImpl: Remove TaskSet 11.0 from pool 
14/05/13 14:00:50 INFO DAGScheduler: Stage 11 (take at DStream.scala:586) finished in 0.026 s
14/05/13 14:00:50 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.04524103 s
14/05/13 14:00:50 INFO JobScheduler: Finished job streaming job 1399969850000 ms.0 from job set of time 1399969850000 ms
14/05/13 14:00:50 INFO JobScheduler: Total delay: 0.339 s for time 1399969850000 ms (execution: 0.323 s)
14/05/13 14:00:50 WARN BlockManager: Block input-0-1399969849400 already exists on this machine; not re-adding it
14/05/13 14:00:51 INFO MemoryStore: ensureFreeSpace(8) called with curMem=76, maxMem=671298355
14/05/13 14:00:51 INFO MemoryStore: Block input-0-1399969849800 stored as bytes to memory (size 8.0 B, free 640.2 MB)
14/05/13 14:00:51 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969849800 in memory on ubuntu.local:56952 (size: 8.0 B, free: 640.2 MB)
14/05/13 14:00:51 INFO BlockManagerMaster: Updated info of block input-0-1399969849800
14/05/13 14:00:51 WARN BlockManager: Block input-0-1399969849800 already exists on this machine; not re-adding it
14/05/13 14:00:52 INFO MemoryStore: ensureFreeSpace(7) called with curMem=84, maxMem=671298355
14/05/13 14:00:52 INFO MemoryStore: Block input-0-1399969850000 stored as bytes to memory (size 7.0 B, free 640.2 MB)
14/05/13 14:00:52 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969850000 in memory on ubuntu.local:56952 (size: 7.0 B, free: 640.2 MB)
14/05/13 14:00:52 INFO BlockManagerMaster: Updated info of block input-0-1399969850000
14/05/13 14:00:52 WARN BlockManager: Block input-0-1399969850000 already exists on this machine; not re-adding it
14/05/13 14:00:52 INFO MemoryStore: ensureFreeSpace(10) called with curMem=91, maxMem=671298355
14/05/13 14:00:52 INFO MemoryStore: Block input-0-1399969850400 stored as bytes to memory (size 10.0 B, free 640.2 MB)
14/05/13 14:00:52 INFO BlockManagerMasterActor$BlockManagerInfo: Added input-0-1399969850400 in memory on ubuntu.local:56952 (size: 10.0 B, free: 640.2 MB)
14/05/13 14:00:52 INFO BlockManagerMaster: Updated info of block input-0-1399969850400
14/05/13 14:00:52 WARN BlockManager: Block input-0-1399969850400 already exists on this machine; not re-adding it
14/05/13 14:00:55 INFO NetworkInputTracker: Stream 0 received 5 blocks
14/05/13 14:00:55 INFO JobScheduler: Added jobs for time 1399969855000 ms
14/05/13 14:00:55 INFO JobScheduler: Starting job streaming job 1399969855000 ms.0 from job set of time 1399969855000 ms
14/05/13 14:00:55 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:00:55 INFO DAGScheduler: Registering RDD 22 (combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:55 INFO DAGScheduler: Got job 7 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:00:55 INFO DAGScheduler: Final stage: Stage 13 (take at DStream.scala:586)
14/05/13 14:00:55 INFO DAGScheduler: Parents of final stage: List(Stage 14)
14/05/13 14:00:55 INFO DAGScheduler: Missing parents: List(Stage 14)
14/05/13 14:00:55 INFO DAGScheduler: Submitting Stage 14 (MapPartitionsRDD[22] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 14:00:55 INFO DAGScheduler: Submitting 5 missing tasks from Stage 14 (MapPartitionsRDD[22] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:55 INFO TaskSchedulerImpl: Adding task set 14.0 with 5 tasks
14/05/13 14:00:55 INFO TaskSetManager: Starting task 14.0:0 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:55 INFO TaskSetManager: Serialized task 14.0:0 as 1519 bytes in 0 ms
14/05/13 14:00:55 INFO Executor: Running task ID 14
14/05/13 14:00:55 INFO BlockManager: Found block input-0-1399969849000 locally
14/05/13 14:00:55 INFO Executor: Serialized size of result for 14 is 749
14/05/13 14:00:55 INFO Executor: Sending result for 14 directly to driver
14/05/13 14:00:55 INFO Executor: Finished task ID 14
14/05/13 14:00:55 INFO TaskSetManager: Starting task 14.0:1 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:55 INFO TaskSetManager: Serialized task 14.0:1 as 1519 bytes in 0 ms
14/05/13 14:00:55 INFO Executor: Running task ID 15
14/05/13 14:00:55 INFO TaskSetManager: Finished TID 14 in 15 ms on localhost (progress: 0/5)
14/05/13 14:00:55 INFO DAGScheduler: Completed ShuffleMapTask(14, 0)
14/05/13 14:00:55 INFO BlockManager: Found block input-0-1399969849400 locally
14/05/13 14:00:55 INFO Executor: Serialized size of result for 15 is 749
14/05/13 14:00:55 INFO Executor: Sending result for 15 directly to driver
14/05/13 14:00:55 INFO Executor: Finished task ID 15
14/05/13 14:00:55 INFO TaskSetManager: Starting task 14.0:2 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:55 INFO TaskSetManager: Serialized task 14.0:2 as 1519 bytes in 1 ms
14/05/13 14:00:55 INFO Executor: Running task ID 16
14/05/13 14:00:55 INFO TaskSetManager: Finished TID 15 in 17 ms on localhost (progress: 1/5)
14/05/13 14:00:55 INFO DAGScheduler: Completed ShuffleMapTask(14, 1)
14/05/13 14:00:55 INFO BlockManager: Found block input-0-1399969849800 locally
14/05/13 14:00:55 INFO Executor: Serialized size of result for 16 is 749
14/05/13 14:00:55 INFO Executor: Sending result for 16 directly to driver
14/05/13 14:00:55 INFO Executor: Finished task ID 16
14/05/13 14:00:55 INFO TaskSetManager: Starting task 14.0:3 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:55 INFO TaskSetManager: Serialized task 14.0:3 as 1519 bytes in 0 ms
14/05/13 14:00:55 INFO Executor: Running task ID 17
14/05/13 14:00:55 INFO TaskSetManager: Finished TID 16 in 17 ms on localhost (progress: 2/5)
14/05/13 14:00:55 INFO DAGScheduler: Completed ShuffleMapTask(14, 2)
14/05/13 14:00:55 INFO BlockManager: Found block input-0-1399969850000 locally
14/05/13 14:00:55 INFO Executor: Serialized size of result for 17 is 749
14/05/13 14:00:55 INFO Executor: Sending result for 17 directly to driver
14/05/13 14:00:55 INFO Executor: Finished task ID 17
14/05/13 14:00:55 INFO TaskSetManager: Starting task 14.0:4 as TID 18 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:55 INFO TaskSetManager: Serialized task 14.0:4 as 1519 bytes in 0 ms
14/05/13 14:00:55 INFO Executor: Running task ID 18
14/05/13 14:00:55 INFO TaskSetManager: Finished TID 17 in 15 ms on localhost (progress: 3/5)
14/05/13 14:00:55 INFO DAGScheduler: Completed ShuffleMapTask(14, 3)
14/05/13 14:00:55 INFO BlockManager: Found block input-0-1399969850400 locally
14/05/13 14:00:55 INFO Executor: Serialized size of result for 18 is 749
14/05/13 14:00:55 INFO Executor: Sending result for 18 directly to driver
14/05/13 14:00:55 INFO Executor: Finished task ID 18
14/05/13 14:00:55 INFO TaskSetManager: Finished TID 18 in 15 ms on localhost (progress: 4/5)
14/05/13 14:00:55 INFO TaskSchedulerImpl: Remove TaskSet 14.0 from pool 
14/05/13 14:00:55 INFO DAGScheduler: Completed ShuffleMapTask(14, 4)
14/05/13 14:00:55 INFO DAGScheduler: Stage 14 (combineByKey at ShuffledDStream.scala:42) finished in 0.074 s
14/05/13 14:00:55 INFO DAGScheduler: looking for newly runnable stages
14/05/13 14:00:55 INFO DAGScheduler: running: Set(Stage 0)
14/05/13 14:00:55 INFO DAGScheduler: waiting: Set(Stage 13)
14/05/13 14:00:55 INFO DAGScheduler: failed: Set()
14/05/13 14:00:55 INFO DAGScheduler: Missing parents for Stage 13: List()
14/05/13 14:00:55 INFO DAGScheduler: Submitting Stage 13 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42), which is now runnable
14/05/13 14:00:55 INFO DAGScheduler: Submitting 1 missing tasks from Stage 13 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:55 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
14/05/13 14:00:55 INFO TaskSetManager: Starting task 13.0:0 as TID 19 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:55 INFO TaskSetManager: Serialized task 13.0:0 as 1564 bytes in 1 ms
14/05/13 14:00:55 INFO Executor: Running task ID 19
14/05/13 14:00:55 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 5 non-zero-bytes blocks out of 5 blocks
14/05/13 14:00:55 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 14:00:55 INFO Executor: Serialized size of result for 19 is 999
14/05/13 14:00:55 INFO Executor: Sending result for 19 directly to driver
14/05/13 14:00:55 INFO Executor: Finished task ID 19
14/05/13 14:00:55 INFO TaskSetManager: Finished TID 19 in 27 ms on localhost (progress: 0/1)
14/05/13 14:00:55 INFO DAGScheduler: Completed ResultTask(13, 0)
14/05/13 14:00:55 INFO TaskSchedulerImpl: Remove TaskSet 13.0 from pool 
14/05/13 14:00:55 INFO DAGScheduler: Stage 13 (take at DStream.scala:586) finished in 0.032 s
14/05/13 14:00:55 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.132403782 s
14/05/13 14:00:55 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:00:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 146 bytes
14/05/13 14:00:55 INFO DAGScheduler: Got job 8 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:00:55 INFO DAGScheduler: Final stage: Stage 15 (take at DStream.scala:586)
14/05/13 14:00:55 INFO DAGScheduler: Parents of final stage: List(Stage 16)
14/05/13 14:00:55 INFO DAGScheduler: Missing parents: List()
14/05/13 14:00:55 INFO DAGScheduler: Submitting Stage 15 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42), which has no missing parents
14/05/13 14:00:55 INFO DAGScheduler: Submitting 1 missing tasks from Stage 15 (MapPartitionsRDD[24] at combineByKey at ShuffledDStream.scala:42)
14/05/13 14:00:55 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
14/05/13 14:00:55 INFO TaskSetManager: Starting task 15.0:0 as TID 20 on executor localhost: localhost (PROCESS_LOCAL)
14/05/13 14:00:55 INFO TaskSetManager: Serialized task 15.0:0 as 1565 bytes in 1 ms
14/05/13 14:00:55 INFO Executor: Running task ID 20
14/05/13 14:00:55 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Getting 0 non-zero-bytes blocks out of 5 blocks
14/05/13 14:00:55 INFO BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote gets in  0 ms
14/05/13 14:00:55 INFO Executor: Serialized size of result for 20 is 813
14/05/13 14:00:55 INFO Executor: Sending result for 20 directly to driver
14/05/13 14:00:55 INFO Executor: Finished task ID 20
14/05/13 14:00:55 INFO TaskSetManager: Finished TID 20 in 15 ms on localhost (progress: 0/1)
14/05/13 14:00:55 INFO TaskSchedulerImpl: Remove TaskSet 15.0 from pool 
14/05/13 14:00:55 INFO DAGScheduler: Completed ResultTask(15, 1)
14/05/13 14:00:55 INFO DAGScheduler: Stage 15 (take at DStream.scala:586) finished in 0.018 s
14/05/13 14:00:55 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.035327103 s
14/05/13 14:00:55 INFO JobScheduler: Finished job streaming job 1399969855000 ms.0 from job set of time 1399969855000 ms
14/05/13 14:00:55 INFO JobScheduler: Total delay: 0.200 s for time 1399969855000 ms (execution: 0.182 s)
14/05/13 14:03:04 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/13 14:03:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 14:03:08 INFO Slf4jLogger: Slf4jLogger started
14/05/13 14:03:08 INFO Remoting: Starting remoting
14/05/13 14:03:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu.local:33989]
14/05/13 14:03:08 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu.local:33989]
14/05/13 14:03:08 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 14:03:08 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513140308-3064
14/05/13 14:03:08 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 14:03:08 INFO ConnectionManager: Bound socket to port 50583 with id = ConnectionManagerId(ubuntu.local,50583)
14/05/13 14:03:08 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 14:03:08 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu.local:50583 with 640.2 MB RAM
14/05/13 14:03:08 INFO BlockManagerMaster: Registered BlockManager
14/05/13 14:03:08 INFO HttpServer: Starting HTTP Server
14/05/13 14:03:09 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:40374
14/05/13 14:03:09 INFO SparkEnv: Registering MapOutputTracker
14/05/13 14:03:09 INFO HttpFileServer: HTTP File server directory is /tmp/spark-1ff12e4f-f953-4eda-a42b-233fc964d111
14/05/13 14:03:09 INFO HttpServer: Starting HTTP Server
14/05/13 14:03:09 INFO SparkUI: Started Spark Web UI at http://ubuntu.local:4040
14/05/13 14:03:11 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 14:03:11 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 14:03:11 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/13 14:03:11 INFO FileInputDStream: Slide time = 5000 ms
14/05/13 14:03:11 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:03:11 INFO FileInputDStream: Checkpoint interval = null
14/05/13 14:03:11 INFO FileInputDStream: Remember duration = 5000 ms
14/05/13 14:03:11 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@24ea1299
14/05/13 14:03:11 INFO MappedDStream: Slide time = 5000 ms
14/05/13 14:03:11 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:03:11 INFO MappedDStream: Checkpoint interval = null
14/05/13 14:03:11 INFO MappedDStream: Remember duration = 5000 ms
14/05/13 14:03:11 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@36b0dbe
14/05/13 14:03:11 INFO ForEachDStream: Slide time = 5000 ms
14/05/13 14:03:11 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:03:11 INFO ForEachDStream: Checkpoint interval = null
14/05/13 14:03:11 INFO ForEachDStream: Remember duration = 5000 ms
14/05/13 14:03:11 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@695336b2
14/05/13 14:03:11 INFO JobGenerator: JobGenerator started at 1399969995000 ms
14/05/13 14:03:11 INFO JobScheduler: JobScheduler started
14/05/13 14:03:15 INFO FileInputDStream: Finding new files took 95 ms
14/05/13 14:03:15 INFO FileInputDStream: New files at time 1399969995000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log
14/05/13 14:03:15 INFO MemoryStore: ensureFreeSpace(33264) called with curMem=0, maxMem=671298355
14/05/13 14:03:15 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/13 14:03:15 INFO FileInputFormat: Total input paths to process : 1
14/05/13 14:03:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/13 14:03:15 WARN LoadSnappy: Snappy native library not loaded
14/05/13 14:03:15 INFO JobScheduler: Added jobs for time 1399969995000 ms
14/05/13 14:03:15 INFO JobScheduler: Starting job streaming job 1399969995000 ms.0 from job set of time 1399969995000 ms
14/05/13 14:03:15 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:03:15 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:03:15 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/13 14:03:15 INFO DAGScheduler: Parents of final stage: List()
14/05/13 14:03:15 INFO DAGScheduler: Missing parents: List()
14/05/13 14:03:15 INFO DAGScheduler: Computing the requested partition locally
14/05/13 14:03:15 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log:0+187296
14/05/13 14:03:15 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.068546612 s
14/05/13 14:03:15 INFO JobScheduler: Finished job streaming job 1399969995000 ms.0 from job set of time 1399969995000 ms
14/05/13 14:03:15 INFO JobScheduler: Total delay: 0.428 s for time 1399969995000 ms (execution: 0.102 s)
14/05/13 14:03:15 INFO FileInputDStream: Cleared 0 old files that were older than 1399969990000 ms: 
14/05/13 14:03:20 INFO FileInputDStream: Finding new files took 2 ms
14/05/13 14:03:20 INFO FileInputDStream: New files at time 1399970000000 ms:

14/05/13 14:03:20 INFO JobScheduler: Added jobs for time 1399970000000 ms
14/05/13 14:03:20 INFO JobScheduler: Starting job streaming job 1399970000000 ms.0 from job set of time 1399970000000 ms
14/05/13 14:03:20 INFO JobScheduler: Finished job streaming job 1399970000000 ms.0 from job set of time 1399970000000 ms
14/05/13 14:03:20 INFO FileInputDStream: Cleared 0 old files that were older than 1399969995000 ms: 
14/05/13 14:03:20 INFO JobScheduler: Total delay: 0.012 s for time 1399970000000 ms (execution: 0.001 s)
14/05/13 14:03:25 INFO FileInputDStream: Finding new files took 1 ms
14/05/13 14:03:25 INFO FileInputDStream: New files at time 1399970005000 ms:

14/05/13 14:03:25 INFO JobScheduler: Added jobs for time 1399970005000 ms
14/05/13 14:03:25 INFO JobScheduler: Starting job streaming job 1399970005000 ms.0 from job set of time 1399970005000 ms
14/05/13 14:03:25 INFO JobScheduler: Finished job streaming job 1399970005000 ms.0 from job set of time 1399970005000 ms
14/05/13 14:03:25 INFO JobScheduler: Total delay: 0.010 s for time 1399970005000 ms (execution: 0.001 s)
14/05/13 14:03:25 INFO FileInputDStream: Cleared 1 old files that were older than 1399970000000 ms: 1399969995000 ms
14/05/13 14:03:30 INFO FileInputDStream: Finding new files took 1 ms
14/05/13 14:03:30 INFO FileInputDStream: New files at time 1399970010000 ms:

14/05/13 14:03:30 INFO JobScheduler: Added jobs for time 1399970010000 ms
14/05/13 14:03:30 INFO JobScheduler: Starting job streaming job 1399970010000 ms.0 from job set of time 1399970010000 ms
14/05/13 14:03:30 INFO JobScheduler: Finished job streaming job 1399970010000 ms.0 from job set of time 1399970010000 ms
14/05/13 14:03:30 INFO JobScheduler: Total delay: 0.015 s for time 1399970010000 ms (execution: 0.001 s)
14/05/13 14:03:30 INFO FileInputDStream: Cleared 1 old files that were older than 1399970005000 ms: 1399970000000 ms
14/05/13 14:03:35 INFO FileInputDStream: Finding new files took 0 ms
14/05/13 14:03:35 INFO FileInputDStream: New files at time 1399970015000 ms:

14/05/13 14:03:35 INFO JobScheduler: Added jobs for time 1399970015000 ms
14/05/13 14:03:35 INFO JobScheduler: Starting job streaming job 1399970015000 ms.0 from job set of time 1399970015000 ms
14/05/13 14:03:35 INFO JobScheduler: Finished job streaming job 1399970015000 ms.0 from job set of time 1399970015000 ms
14/05/13 14:03:35 INFO JobScheduler: Total delay: 0.013 s for time 1399970015000 ms (execution: 0.001 s)
14/05/13 14:03:35 INFO FileInputDStream: Cleared 1 old files that were older than 1399970010000 ms: 1399970005000 ms
14/05/13 14:03:40 INFO FileInputDStream: Finding new files took 1 ms
14/05/13 14:03:40 INFO FileInputDStream: New files at time 1399970020000 ms:

14/05/13 14:03:40 INFO JobScheduler: Added jobs for time 1399970020000 ms
14/05/13 14:03:40 INFO JobScheduler: Starting job streaming job 1399970020000 ms.0 from job set of time 1399970020000 ms
14/05/13 14:03:40 INFO JobScheduler: Finished job streaming job 1399970020000 ms.0 from job set of time 1399970020000 ms
14/05/13 14:03:40 INFO JobScheduler: Total delay: 0.011 s for time 1399970020000 ms (execution: 0.001 s)
14/05/13 14:03:40 INFO FileInputDStream: Cleared 1 old files that were older than 1399970015000 ms: 1399970010000 ms
14/05/13 14:05:28 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!
14/05/13 14:05:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 14:05:29 INFO Slf4jLogger: Slf4jLogger started
14/05/13 14:05:30 INFO Remoting: Starting remoting
14/05/13 14:05:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu:60321]
14/05/13 14:05:30 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu:60321]
14/05/13 14:05:30 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 14:05:30 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513140530-7435
14/05/13 14:05:30 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 14:05:30 INFO ConnectionManager: Bound socket to port 42295 with id = ConnectionManagerId(ubuntu,42295)
14/05/13 14:05:30 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 14:05:30 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu:42295 with 640.2 MB RAM
14/05/13 14:05:30 INFO BlockManagerMaster: Registered BlockManager
14/05/13 14:05:30 INFO HttpServer: Starting HTTP Server
14/05/13 14:05:30 INFO HttpBroadcast: Broadcast server started at http://127.0.1.1:34192
14/05/13 14:05:30 INFO SparkEnv: Registering MapOutputTracker
14/05/13 14:05:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-1c7485ce-7eea-4d45-92d6-8c849a0400ac
14/05/13 14:05:30 INFO HttpServer: Starting HTTP Server
14/05/13 14:05:31 INFO SparkUI: Started Spark Web UI at http://ubuntu:4040
14/05/13 14:05:32 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 14:05:32 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 14:05:32 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/13 14:05:32 INFO FileInputDStream: Slide time = 5000 ms
14/05/13 14:05:32 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:05:32 INFO FileInputDStream: Checkpoint interval = null
14/05/13 14:05:32 INFO FileInputDStream: Remember duration = 5000 ms
14/05/13 14:05:32 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@9fcbbfe
14/05/13 14:05:32 INFO MappedDStream: Slide time = 5000 ms
14/05/13 14:05:32 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:05:32 INFO MappedDStream: Checkpoint interval = null
14/05/13 14:05:32 INFO MappedDStream: Remember duration = 5000 ms
14/05/13 14:05:32 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@2f9a25d1
14/05/13 14:05:32 INFO ForEachDStream: Slide time = 5000 ms
14/05/13 14:05:32 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:05:32 INFO ForEachDStream: Checkpoint interval = null
14/05/13 14:05:32 INFO ForEachDStream: Remember duration = 5000 ms
14/05/13 14:05:32 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@3128d4c1
14/05/13 14:05:32 INFO JobGenerator: JobGenerator started at 1399970135000 ms
14/05/13 14:05:32 INFO JobScheduler: JobScheduler started
14/05/13 14:05:35 INFO FileInputDStream: Finding new files took 110 ms
14/05/13 14:05:35 INFO FileInputDStream: New files at time 1399970135000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log
14/05/13 14:05:35 INFO MemoryStore: ensureFreeSpace(33264) called with curMem=0, maxMem=671298355
14/05/13 14:05:35 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/13 14:05:35 INFO FileInputFormat: Total input paths to process : 1
14/05/13 14:05:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/13 14:05:35 WARN LoadSnappy: Snappy native library not loaded
14/05/13 14:05:35 INFO JobScheduler: Added jobs for time 1399970135000 ms
14/05/13 14:05:35 INFO JobScheduler: Starting job streaming job 1399970135000 ms.0 from job set of time 1399970135000 ms
14/05/13 14:05:35 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:05:35 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:05:35 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/13 14:05:35 INFO DAGScheduler: Parents of final stage: List()
14/05/13 14:05:35 INFO DAGScheduler: Missing parents: List()
14/05/13 14:05:35 INFO DAGScheduler: Computing the requested partition locally
14/05/13 14:05:35 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log:0+187296
14/05/13 14:05:35 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.07406999 s
14/05/13 14:05:35 INFO JobScheduler: Finished job streaming job 1399970135000 ms.0 from job set of time 1399970135000 ms
14/05/13 14:05:35 INFO JobScheduler: Total delay: 0.462 s for time 1399970135000 ms (execution: 0.108 s)
14/05/13 14:05:35 INFO FileInputDStream: Cleared 0 old files that were older than 1399970130000 ms: 
14/05/13 14:05:40 INFO FileInputDStream: Finding new files took 2 ms
14/05/13 14:05:40 INFO FileInputDStream: New files at time 1399970140000 ms:

14/05/13 14:05:40 INFO JobScheduler: Added jobs for time 1399970140000 ms
14/05/13 14:05:40 INFO JobScheduler: Starting job streaming job 1399970140000 ms.0 from job set of time 1399970140000 ms
14/05/13 14:05:40 INFO JobScheduler: Finished job streaming job 1399970140000 ms.0 from job set of time 1399970140000 ms
14/05/13 14:05:40 INFO FileInputDStream: Cleared 0 old files that were older than 1399970135000 ms: 
14/05/13 14:05:40 INFO JobScheduler: Total delay: 0.013 s for time 1399970140000 ms (execution: 0.001 s)
14/05/13 14:05:45 INFO FileInputDStream: Finding new files took 0 ms
14/05/13 14:05:45 INFO FileInputDStream: New files at time 1399970145000 ms:

14/05/13 14:05:45 INFO JobScheduler: Added jobs for time 1399970145000 ms
14/05/13 14:05:45 INFO JobScheduler: Starting job streaming job 1399970145000 ms.0 from job set of time 1399970145000 ms
14/05/13 14:05:45 INFO JobScheduler: Finished job streaming job 1399970145000 ms.0 from job set of time 1399970145000 ms
14/05/13 14:05:45 INFO JobScheduler: Total delay: 0.014 s for time 1399970145000 ms (execution: 0.002 s)
14/05/13 14:05:45 INFO FileInputDStream: Cleared 1 old files that were older than 1399970140000 ms: 1399970135000 ms
14/05/13 14:11:04 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/13 14:11:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 14:11:06 INFO Slf4jLogger: Slf4jLogger started
14/05/13 14:11:06 INFO Remoting: Starting remoting
14/05/13 14:11:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu.local:46375]
14/05/13 14:11:06 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu.local:46375]
14/05/13 14:11:06 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 14:11:06 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513141106-fb57
14/05/13 14:11:06 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 14:11:06 INFO ConnectionManager: Bound socket to port 59300 with id = ConnectionManagerId(ubuntu.local,59300)
14/05/13 14:11:06 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 14:11:06 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu.local:59300 with 640.2 MB RAM
14/05/13 14:11:06 INFO BlockManagerMaster: Registered BlockManager
14/05/13 14:11:06 INFO HttpServer: Starting HTTP Server
14/05/13 14:11:06 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:34643
14/05/13 14:11:06 INFO SparkEnv: Registering MapOutputTracker
14/05/13 14:11:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-c8a3c02d-c09d-4076-b52f-4387812d300b
14/05/13 14:11:06 INFO HttpServer: Starting HTTP Server
14/05/13 14:11:07 INFO SparkUI: Started Spark Web UI at http://ubuntu.local:4040
14/05/13 14:11:08 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 14:11:08 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 14:11:08 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/13 14:11:08 INFO FileInputDStream: Slide time = 5000 ms
14/05/13 14:11:08 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:11:08 INFO FileInputDStream: Checkpoint interval = null
14/05/13 14:11:08 INFO FileInputDStream: Remember duration = 5000 ms
14/05/13 14:11:08 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@508b9d45
14/05/13 14:11:08 INFO MappedDStream: Slide time = 5000 ms
14/05/13 14:11:08 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:11:08 INFO MappedDStream: Checkpoint interval = null
14/05/13 14:11:08 INFO MappedDStream: Remember duration = 5000 ms
14/05/13 14:11:08 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@7e024652
14/05/13 14:11:08 INFO ForEachDStream: Slide time = 5000 ms
14/05/13 14:11:08 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:11:08 INFO ForEachDStream: Checkpoint interval = null
14/05/13 14:11:08 INFO ForEachDStream: Remember duration = 5000 ms
14/05/13 14:11:08 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@4756f21f
14/05/13 14:11:09 INFO JobGenerator: JobGenerator started at 1399970470000 ms
14/05/13 14:11:09 INFO JobScheduler: JobScheduler started
14/05/13 14:11:10 INFO FileInputDStream: Finding new files took 119 ms
14/05/13 14:11:10 INFO FileInputDStream: New files at time 1399970470000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log
14/05/13 14:11:10 INFO MemoryStore: ensureFreeSpace(33264) called with curMem=0, maxMem=671298355
14/05/13 14:11:10 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/13 14:11:10 INFO FileInputFormat: Total input paths to process : 1
14/05/13 14:11:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/13 14:11:10 WARN LoadSnappy: Snappy native library not loaded
14/05/13 14:11:10 INFO JobScheduler: Added jobs for time 1399970470000 ms
14/05/13 14:11:10 INFO JobScheduler: Starting job streaming job 1399970470000 ms.0 from job set of time 1399970470000 ms
14/05/13 14:11:10 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:11:10 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:11:10 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/13 14:11:10 INFO DAGScheduler: Parents of final stage: List()
14/05/13 14:11:10 INFO DAGScheduler: Missing parents: List()
14/05/13 14:11:10 INFO DAGScheduler: Computing the requested partition locally
14/05/13 14:11:10 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log:0+187296
14/05/13 14:11:10 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.063433596 s
14/05/13 14:11:10 INFO JobScheduler: Finished job streaming job 1399970470000 ms.0 from job set of time 1399970470000 ms
14/05/13 14:11:10 INFO JobScheduler: Total delay: 0.467 s for time 1399970470000 ms (execution: 0.094 s)
14/05/13 14:11:10 INFO FileInputDStream: Cleared 0 old files that were older than 1399970465000 ms: 
14/05/13 14:11:15 INFO FileInputDStream: Finding new files took 2 ms
14/05/13 14:11:15 INFO FileInputDStream: New files at time 1399970475000 ms:

14/05/13 14:11:15 INFO JobScheduler: Added jobs for time 1399970475000 ms
14/05/13 14:11:15 INFO JobScheduler: Starting job streaming job 1399970475000 ms.0 from job set of time 1399970475000 ms
14/05/13 14:11:15 INFO JobScheduler: Finished job streaming job 1399970475000 ms.0 from job set of time 1399970475000 ms
14/05/13 14:11:15 INFO JobScheduler: Total delay: 0.013 s for time 1399970475000 ms (execution: 0.000 s)
14/05/13 14:11:15 INFO FileInputDStream: Cleared 0 old files that were older than 1399970470000 ms: 
14/05/13 14:11:20 INFO FileInputDStream: Finding new files took 0 ms
14/05/13 14:11:20 INFO FileInputDStream: New files at time 1399970480000 ms:

14/05/13 14:11:20 INFO JobScheduler: Added jobs for time 1399970480000 ms
14/05/13 14:11:20 INFO JobScheduler: Starting job streaming job 1399970480000 ms.0 from job set of time 1399970480000 ms
14/05/13 14:11:20 INFO JobScheduler: Finished job streaming job 1399970480000 ms.0 from job set of time 1399970480000 ms
14/05/13 14:11:20 INFO JobScheduler: Total delay: 0.011 s for time 1399970480000 ms (execution: 0.000 s)
14/05/13 14:11:20 INFO FileInputDStream: Cleared 1 old files that were older than 1399970475000 ms: 1399970470000 ms
14/05/13 14:13:09 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/13 14:13:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 14:13:11 INFO Slf4jLogger: Slf4jLogger started
14/05/13 14:13:11 INFO Remoting: Starting remoting
14/05/13 14:13:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu.local:55971]
14/05/13 14:13:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu.local:55971]
14/05/13 14:13:12 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 14:13:12 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513141312-f34a
14/05/13 14:13:12 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 14:13:12 INFO ConnectionManager: Bound socket to port 56477 with id = ConnectionManagerId(ubuntu.local,56477)
14/05/13 14:13:12 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 14:13:12 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu.local:56477 with 640.2 MB RAM
14/05/13 14:13:12 INFO BlockManagerMaster: Registered BlockManager
14/05/13 14:13:12 INFO HttpServer: Starting HTTP Server
14/05/13 14:13:12 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:51025
14/05/13 14:13:12 INFO SparkEnv: Registering MapOutputTracker
14/05/13 14:13:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-289635df-23e7-4d6c-b334-4e31e793d233
14/05/13 14:13:12 INFO HttpServer: Starting HTTP Server
14/05/13 14:13:12 INFO SparkUI: Started Spark Web UI at http://ubuntu.local:4040
14/05/13 14:13:12 INFO ConnectionManager: Selector thread was interrupted!
14/05/13 14:13:38 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/13 14:13:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 14:13:40 INFO Slf4jLogger: Slf4jLogger started
14/05/13 14:13:41 INFO Remoting: Starting remoting
14/05/13 14:13:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu.local:34706]
14/05/13 14:13:41 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu.local:34706]
14/05/13 14:13:41 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 14:13:41 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513141341-c1cb
14/05/13 14:13:41 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 14:13:41 INFO ConnectionManager: Bound socket to port 53935 with id = ConnectionManagerId(ubuntu.local,53935)
14/05/13 14:13:41 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 14:13:41 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu.local:53935 with 640.2 MB RAM
14/05/13 14:13:41 INFO BlockManagerMaster: Registered BlockManager
14/05/13 14:13:41 INFO HttpServer: Starting HTTP Server
14/05/13 14:13:41 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:59704
14/05/13 14:13:41 INFO SparkEnv: Registering MapOutputTracker
14/05/13 14:13:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-252b5872-3673-415a-a019-c02b848ecb74
14/05/13 14:13:41 INFO HttpServer: Starting HTTP Server
14/05/13 14:13:42 INFO SparkUI: Started Spark Web UI at http://ubuntu.local:4040
14/05/13 14:13:42 INFO ConnectionManager: Selector thread was interrupted!
14/05/13 14:14:07 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/13 14:14:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 14:14:08 INFO Slf4jLogger: Slf4jLogger started
14/05/13 14:14:08 INFO Remoting: Starting remoting
14/05/13 14:14:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu.local:57426]
14/05/13 14:14:09 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu.local:57426]
14/05/13 14:14:09 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 14:14:09 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513141409-5a1c
14/05/13 14:14:09 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 14:14:09 INFO ConnectionManager: Bound socket to port 34441 with id = ConnectionManagerId(ubuntu.local,34441)
14/05/13 14:14:09 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 14:14:09 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu.local:34441 with 640.2 MB RAM
14/05/13 14:14:09 INFO BlockManagerMaster: Registered BlockManager
14/05/13 14:14:09 INFO HttpServer: Starting HTTP Server
14/05/13 14:14:09 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:57685
14/05/13 14:14:09 INFO SparkEnv: Registering MapOutputTracker
14/05/13 14:14:09 INFO HttpFileServer: HTTP File server directory is /tmp/spark-b4278632-cf07-422a-95a7-5dedf59b4332
14/05/13 14:14:09 INFO HttpServer: Starting HTTP Server
14/05/13 14:14:09 INFO SparkUI: Started Spark Web UI at http://ubuntu.local:4040
14/05/13 14:14:09 INFO ConnectionManager: Selector thread was interrupted!
14/05/13 14:19:31 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.8.7.208 instead (on interface wlan0)
14/05/13 14:19:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/13 14:19:32 INFO Slf4jLogger: Slf4jLogger started
14/05/13 14:19:33 INFO Remoting: Starting remoting
14/05/13 14:19:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@ubuntu.local:57920]
14/05/13 14:19:33 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@ubuntu.local:57920]
14/05/13 14:19:33 INFO SparkEnv: Registering BlockManagerMaster
14/05/13 14:19:33 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140513141933-bed3
14/05/13 14:19:33 INFO MemoryStore: MemoryStore started with capacity 640.2 MB.
14/05/13 14:19:33 INFO ConnectionManager: Bound socket to port 55132 with id = ConnectionManagerId(ubuntu.local,55132)
14/05/13 14:19:33 INFO BlockManagerMaster: Trying to register BlockManager
14/05/13 14:19:33 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager ubuntu.local:55132 with 640.2 MB RAM
14/05/13 14:19:33 INFO BlockManagerMaster: Registered BlockManager
14/05/13 14:19:33 INFO HttpServer: Starting HTTP Server
14/05/13 14:19:33 INFO HttpBroadcast: Broadcast server started at http://10.8.7.208:41736
14/05/13 14:19:33 INFO SparkEnv: Registering MapOutputTracker
14/05/13 14:19:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-40fa80ef-650b-4b7b-9d7b-d1225319d239
14/05/13 14:19:33 INFO HttpServer: Starting HTTP Server
14/05/13 14:19:34 INFO SparkUI: Started Spark Web UI at http://ubuntu.local:4040
14/05/13 14:19:35 INFO ForEachDStream: metadataCleanupDelay = 3600
14/05/13 14:19:35 INFO MappedDStream: metadataCleanupDelay = 3600
14/05/13 14:19:35 INFO FileInputDStream: metadataCleanupDelay = 3600
14/05/13 14:19:35 INFO FileInputDStream: Slide time = 5000 ms
14/05/13 14:19:35 INFO FileInputDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:19:35 INFO FileInputDStream: Checkpoint interval = null
14/05/13 14:19:35 INFO FileInputDStream: Remember duration = 5000 ms
14/05/13 14:19:35 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@4ec35eb5
14/05/13 14:19:35 INFO MappedDStream: Slide time = 5000 ms
14/05/13 14:19:35 INFO MappedDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:19:35 INFO MappedDStream: Checkpoint interval = null
14/05/13 14:19:35 INFO MappedDStream: Remember duration = 5000 ms
14/05/13 14:19:35 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@7c7ee578
14/05/13 14:19:35 INFO ForEachDStream: Slide time = 5000 ms
14/05/13 14:19:35 INFO ForEachDStream: Storage level = StorageLevel(false, false, false, 1)
14/05/13 14:19:35 INFO ForEachDStream: Checkpoint interval = null
14/05/13 14:19:35 INFO ForEachDStream: Remember duration = 5000 ms
14/05/13 14:19:35 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@6f0b6922
14/05/13 14:19:35 INFO JobGenerator: JobGenerator started at 1399970980000 ms
14/05/13 14:19:35 INFO JobScheduler: JobScheduler started
14/05/13 14:19:40 INFO FileInputDStream: Finding new files took 97 ms
14/05/13 14:19:40 INFO FileInputDStream: New files at time 1399970980000 ms:
file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log
14/05/13 14:19:40 INFO MemoryStore: ensureFreeSpace(33264) called with curMem=0, maxMem=671298355
14/05/13 14:19:40 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.5 KB, free 640.2 MB)
14/05/13 14:19:40 INFO FileInputFormat: Total input paths to process : 1
14/05/13 14:19:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/05/13 14:19:40 WARN LoadSnappy: Snappy native library not loaded
14/05/13 14:19:40 INFO JobScheduler: Added jobs for time 1399970980000 ms
14/05/13 14:19:40 INFO JobScheduler: Starting job streaming job 1399970980000 ms.0 from job set of time 1399970980000 ms
14/05/13 14:19:40 INFO SparkContext: Starting job: take at DStream.scala:586
14/05/13 14:19:40 INFO DAGScheduler: Got job 0 (take at DStream.scala:586) with 1 output partitions (allowLocal=true)
14/05/13 14:19:40 INFO DAGScheduler: Final stage: Stage 0 (take at DStream.scala:586)
14/05/13 14:19:40 INFO DAGScheduler: Parents of final stage: List()
14/05/13 14:19:40 INFO DAGScheduler: Missing parents: List()
14/05/13 14:19:40 INFO DAGScheduler: Computing the requested partition locally
14/05/13 14:19:40 INFO NewHadoopRDD: Input split: file:/home/saumya_space/Downloads/sam/SparkTwitterAnalysis-0.1.0/logs/SparkOut.log:0+187296
14/05/13 14:19:40 INFO SparkContext: Job finished: take at DStream.scala:586, took 0.062080792 s
14/05/13 14:19:40 INFO JobScheduler: Finished job streaming job 1399970980000 ms.0 from job set of time 1399970980000 ms
14/05/13 14:19:40 INFO JobScheduler: Total delay: 0.426 s for time 1399970980000 ms (execution: 0.090 s)
14/05/13 14:19:40 INFO FileInputDStream: Cleared 0 old files that were older than 1399970975000 ms: 
14/05/13 14:19:45 INFO FileInputDStream: Finding new files took 2 ms
14/05/13 14:19:45 INFO FileInputDStream: New files at time 1399970985000 ms:

14/05/13 14:19:45 INFO JobScheduler: Added jobs for time 1399970985000 ms
14/05/13 14:19:45 INFO JobScheduler: Starting job streaming job 1399970985000 ms.0 from job set of time 1399970985000 ms
14/05/13 14:19:45 INFO JobScheduler: Finished job streaming job 1399970985000 ms.0 from job set of time 1399970985000 ms
14/05/13 14:19:45 INFO FileInputDStream: Cleared 0 old files that were older than 1399970980000 ms: 
14/05/13 14:19:45 INFO JobScheduler: Total delay: 0.014 s for time 1399970985000 ms (execution: 0.001 s)
14/05/13 14:19:50 INFO FileInputDStream: Finding new files took 1 ms
14/05/13 14:19:50 INFO FileInputDStream: New files at time 1399970990000 ms:

14/05/13 14:19:50 INFO JobScheduler: Added jobs for time 1399970990000 ms
14/05/13 14:19:50 INFO JobScheduler: Starting job streaming job 1399970990000 ms.0 from job set of time 1399970990000 ms
14/05/13 14:19:50 INFO JobScheduler: Finished job streaming job 1399970990000 ms.0 from job set of time 1399970990000 ms
14/05/13 14:19:50 INFO JobScheduler: Total delay: 0.011 s for time 1399970990000 ms (execution: 0.001 s)
14/05/13 14:19:50 INFO FileInputDStream: Cleared 1 old files that were older than 1399970985000 ms: 1399970980000 ms
